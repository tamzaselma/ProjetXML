<?xml version="1.0" encoding="utf-8"?>
<raweb xmlns:xlink="http://www.w3.org/1999/xlink" xml:lang="en" year="2016">
  <identification id="titane" isproject="true">
    <shortname>TITANE</shortname>
    <projectName>Geometric Modeling of 3D Environments</projectName>
    <theme-de-recherche>Interaction and visualization</theme-de-recherche>
    <domaine-de-recherche>Perception, Cognition and Interaction</domaine-de-recherche>
    <urlTeam>http://team.inria.fr/titane</urlTeam>
    <header_dates_team>Creation of the Team: 2013 January 01, updated into Project-Team: 2014 January 01</header_dates_team>
    <LeTypeProjet>Project-Team</LeTypeProjet>
    <keywordsSdN>
      <term>5.3. - Image processing and analysis</term>
      <term>5.4.4. - 3D and spatio-temporal reconstruction</term>
      <term>5.5.1. - Geometrical modeling</term>
      <term>7.5. - Geometry, Topology</term>
    </keywordsSdN>
    <keywordsSecteurs>
      <term>3.3. - Geosciences</term>
      <term>5. - Industry of the future</term>
      <term>8. - Smart Cities and Territories</term>
    </keywordsSecteurs>
    <UR name="Sophia"/>
  </identification>
  <team id="uid1">
    <person key="titane-2014-idm30672">
      <firstname>Pierre</firstname>
      <lastname>Alliez</lastname>
      <categoryPro>Chercheur</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>Team leader, Inria, Senior Researcher</moreinfo>
      <hdr>oui</hdr>
    </person>
    <person key="titane-2014-idm27920">
      <firstname>Florent</firstname>
      <lastname>Lafarge</lastname>
      <categoryPro>Chercheur</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>Inria, Researcher</moreinfo>
      <hdr>oui</hdr>
    </person>
    <person key="ayin-2014-idp63848">
      <firstname>Yuliya</firstname>
      <lastname>Tarabalka</lastname>
      <categoryPro>Chercheur</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>Inria, Researcher</moreinfo>
    </person>
    <person key="galaad2-2014-idp65952">
      <firstname>Nicolas</firstname>
      <lastname>Douillet</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>Inria, until Oct 2016</moreinfo>
    </person>
    <person key="titane-2016-idp116368">
      <firstname>Come</firstname>
      <lastname>Le Breton</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>Inria, since Apr 2016</moreinfo>
    </person>
    <person key="titane-2014-idp74264">
      <firstname>Sven</firstname>
      <lastname>Oesau</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>Inria, until Fev 2016, funded by CSTB</moreinfo>
    </person>
    <person key="titane-2016-idp121344">
      <firstname>Cédric</firstname>
      <lastname>Portaneri</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>Inria, since Dec 2016</moreinfo>
    </person>
    <person key="titane-2015-idp66032">
      <firstname>Maxim</firstname>
      <lastname>Torgonskiy</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>Inria, until Feb 2016</moreinfo>
    </person>
    <person key="titane-2016-idp126304">
      <firstname>Jean-Philippe</firstname>
      <lastname>Bauchet</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>Luxcarta, since Sep 2016, funded by CIFRE</moreinfo>
    </person>
    <person key="titane-2014-idp69312">
      <firstname>Liuyun</firstname>
      <lastname>Duan</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>Geoimage, until Sep 2016, funded by CIFRE, then thesis relay from Oct 2016</moreinfo>
    </person>
    <person key="titane-2016-idp131264">
      <firstname>Oussama</firstname>
      <lastname>Ennafii</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>IGN, from Oct 2016, funded by IGN</moreinfo>
    </person>
    <person key="titane-2015-idp82392">
      <firstname>Hao</firstname>
      <lastname>Fang</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>Inria, since Feb, funded by CIFRE CSTB</moreinfo>
    </person>
    <person key="titane-2014-idp70536">
      <firstname>Jean-Dominique</firstname>
      <lastname>Favreau</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>UNS</moreinfo>
    </person>
    <person key="titane-2014-idp73016">
      <firstname>Manish</firstname>
      <lastname>Mandad</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>RWTH Aachen, thesis relay until Dec 2016</moreinfo>
    </person>
    <person key="ayin-2014-idp84096">
      <firstname>Emmanuel</firstname>
      <lastname>Maggiori</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>Inria</moreinfo>
    </person>
    <person key="morpheo-2014-idp114840">
      <firstname>Mohammad</firstname>
      <lastname>Rouhani</lastname>
      <categoryPro>PostDoc</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>Inria, until Apr 2016</moreinfo>
    </person>
    <person key="titane-2014-idp85608">
      <firstname>Jingjing</firstname>
      <lastname>Shen</lastname>
      <categoryPro>Visiteur</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>Fitzwilliam College, from May to Jun 2016</moreinfo>
    </person>
    <person key="titane-2014-idm29192">
      <firstname>David</firstname>
      <lastname>Bommes</lastname>
      <categoryPro>Visiteur</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>RWTH Aachen, Research professor, Sep 2016</moreinfo>
    </person>
    <person key="titane-2016-idp150992">
      <firstname>Martin</firstname>
      <lastname>Heistermann</lastname>
      <categoryPro>Visiteur</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>RWTH Aachen, PhD student, Sep 2016</moreinfo>
    </person>
    <person key="abs-2014-idm26016">
      <firstname>Florence</firstname>
      <lastname>Barbara</lastname>
      <categoryPro>Assistant</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>Inria</moreinfo>
    </person>
    <person key="titane-2014-idp80456">
      <firstname>Mathieu</firstname>
      <lastname>Desbrun</lastname>
      <categoryPro>AutreCategorie</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>Inria, International Chair from Aug. to Nov. 2016 - Associate Researcher from Caltech</moreinfo>
    </person>
    <person key="titane-2016-idp158464">
      <firstname>Chunlin</firstname>
      <lastname>Xiao</lastname>
      <categoryPro>AutreCategorie</categoryPro>
      <research-centre>Sophia</research-centre>
      <moreinfo>Inria, Master intern from UNS, from Mar to Sep 2016, funded by CNES</moreinfo>
    </person>
  </team>
  <presentation id="uid2">
    <bodyTitle>Overall Objectives</bodyTitle>
    <subsection id="uid3" level="1">
      <bodyTitle>General Presentation</bodyTitle>
      <p>Our overall objective is the computerized geometric modeling of complex scenes from physical measurements. On the geometric modeling and processing pipeline, this objective corresponds to steps required for conversion from physical to effective digital representations: <i>analysis</i>, <i>reconstruction</i> and <i>approximation</i>. Another longer term objective is the <i>synthesis</i> of complex scenes. This objective is related to analysis as we assume that the main sources of data are measurements, and synthesis is assumed to be carried out from samples.</p>
      <p>The related scientific challenges include i) being resilient to defect-laden data due to the uncertainty in the measurement processes and imperfect algorithms along the pipeline, ii) being resilient to heterogeneous data, both in type and in scale, iii) dealing with massive data, and iv) recovering or preserving the structure of complex scenes. We define the quality of a computerized representation by its i) geometric accuracy, or faithfulness to the physical scene, ii) complexity, iii) structure accuracy and control, and iv) amenability to effective processing and high level scene understanding.
</p>
    </subsection>
  </presentation>
  <fondements id="uid4">
    <bodyTitle>Research Program</bodyTitle>
    <subsection id="uid5" level="1">
      <bodyTitle>Context</bodyTitle>
      <p>Geometric modeling and processing revolve around three main end goals: a computerized shape representation that can be visualized (creating a realistic or artistic depiction), simulated (anticipating the real) or realized (manufacturing a conceptual or engineering design). Aside from the mere editing of geometry, central research themes in geometric modeling involve conversions between physical (real), discrete (digital), and mathematical (abstract) representations. Going from physical to digital is referred to as shape acquisition and reconstruction; going from mathematical to discrete is referred to as shape approximation and mesh generation; going from discrete to physical is referred to as shape rationalization.</p>
      <p>Geometric modeling has become an indispensable component for computational and reverse engineering. Simulations are now routinely performed on complex shapes issued not only from computer-aided design but also from an increasing amount of available measurements. The scale of acquired data is quickly growing: we no longer deal exclusively with individual shapes, but with entire <i>scenes</i>, possibly at the scale of entire cities, with many objects defined as structured shapes. We are witnessing a rapid evolution of the acquisition paradigms with an increasing variety of sensors and the development of community data, as well as disseminated data.</p>
      <p>In recent years, the evolution of acquisition technologies and methods has translated in an increasing overlap of algorithms and data in the computer vision, image processing, and computer graphics communities. Beyond the rapid increase of resolution through technological advances of sensors and methods for mosaicing images, the line between laser scan data and photos is getting thinner. Combining, e.g., laser scanners with panoramic cameras leads to massive 3D point sets with color attributes. In addition, it is now possible to generate dense point sets not just from laser scanners but also from photogrammetry techniques when using a well-designed acquisition protocol. Depth cameras are getting increasingly common, and beyond retrieving depth information we can enrich the main acquisition systems with additional hardware to measure geometric information about the sensor and improve data registration: e.g., accelerometers or <span class="smallcap" align="left">gps</span> for geographic location, and compasses or gyrometers for orientation. Finally, complex scenes can be observed at different scales ranging from satellite to pedestrian through aerial levels.</p>
      <p>These evolutions allow practitioners to measure urban scenes at resolutions that were until now possible only at the scale of individual shapes. The related scientific challenge is however more than just dealing with massive data sets coming from increase of resolution, as complex scenes are composed of multiple objects with structural relationships. The latter relate i) to the way the individual shapes are grouped to form objects, object classes or hierarchies, ii) to geometry when dealing with similarity, regularity, parallelism or symmetry, and iii) to domain-specific semantic considerations. Beyond reconstruction and approximation, consolidation and synthesis of complex scenes require rich structural relationships.</p>
      <p>The problems arising from these evolutions suggest that the strengths of geometry and images may be combined in the form of new methodological solutions such as photo-consistent reconstruction. In addition, the process of measuring the geometry of sensors (through gyrometers and accelerometers) often requires both geometry process and image analysis for improved accuracy and robustness. Modeling urban scenes from measurements illustrates this growing synergy, and it has become a central concern for a variety of applications ranging from urban planning to simulation through rendering and special effects.</p>
    </subsection>
    <subsection id="uid6" level="1">
      <bodyTitle>Analysis</bodyTitle>
      <p>Complex scenes are usually composed of a large number of objects which may significantly differ in terms of complexity, diversity, and density. These objects must be identified and their structural relationships must be recovered in order to model the scenes with improved robustness, low complexity, variable levels of details and ultimately, semantization (automated process of increasing degree of semantic content).</p>
      <p><i>Object classification</i> is an ill-posed task in which the objects composing a scene are detected and recognized with respect to predefined classes, the objective going beyond scene segmentation. The high variability in each class may explain the success of the stochastic approach which is able to model widely variable classes. As it requires a priori knowledge this process is often domain-specific such as for urban scenes where we wish to distinguish between instances as ground, vegetation and buildings. Additional challenges arise when each class must be refined, such as roof super-structures for urban reconstruction.</p>
      <p><i>Structure extraction</i> consists in recovering structural relationships between objects or parts of object. The structure may be related to adjacencies between objects, hierarchical decomposition, singularities or canonical geometric relationships. It is crucial for effective geometric modeling through levels of details or hierarchical multiresolution modeling. Ideally we wish to learn the structural rules that govern the physical scene manufacturing. Understanding the main canonical geometric relationships between object parts involves detecting regular structures and equivalences under certain transformations such as parallelism, orthogonality and symmetry. Identifying structural and geometric repetitions or symmetries is relevant for dealing with missing data during data consolidation.</p>
      <p><i>Data consolidation</i> is a problem of growing interest for practitioners, with the increase of heterogeneous and defect-laden data. To be exploitable, such defect-laden data must be consolidated by improving the data sampling quality and by reinforcing the geometrical and structural relations sub-tending the observed scenes. Enforcing canonical geometric relationships such as local coplanarity or orthogonality is relevant for registration of heterogeneous or redundant data, as well as for improving the robustness of the reconstruction process.</p>
    </subsection>
    <subsection id="uid7" level="1">
      <bodyTitle>Approximation</bodyTitle>
      <p>Our objective is to explore the approximation of complex shapes and scenes with surface and volume meshes, as well as on surface and domain tiling. A general way to state the shape approximation problem is to say that we search for the shape discretization (possibly with several levels of detail) that realizes the best complexity / distortion trade-off. Such a problem statement requires defining a discretization model, an error metric to measure distortion as well as a way to measure complexity. The latter is most commonly expressed in number of polygon primitives, but other measures closer to information theory lead to measurements such as number of bits or minimum description length.</p>
      <p>For surface meshes we intend to conceive methods which provide control and guarantees both over the global approximation error and over the validity of the embedding. In addition, we seek for resilience to heterogeneous data, and robustness to noise and outliers. This would allow repairing and simplifying triangle soups with cracks, self-intersections and gaps. Another exploratory objective is to deal generically with different error metrics such as the symmetric Hausdorff distance, or a Sobolev norm which mixes errors in geometry and normals.</p>
      <p>For surface and domain tiling the term meshing is substituted for tiling to stress the fact that tiles may be not just simple elements, but can model complex smooth shapes such as bilinear quadrangles. Quadrangle surface tiling is central for the so-called <i>resurfacing</i> problem in reverse engineering: the goal is to tile an input raw surface geometry such that the union of the tiles approximates the input well and such that each tile matches certain properties related to its shape or its size. In addition, we may require parameterization domains with a simple structure. Our goal is to devise surface tiling algorithms that are both reliable and resilient to defect-laden inputs, effective from the shape approximation point of view, and with flexible control upon the structure of the tiling.</p>
    </subsection>
    <subsection id="uid8" level="1">
      <bodyTitle>Reconstruction</bodyTitle>
      <p>Assuming a geometric dataset made out of points or slices, the process of shape reconstruction amounts to recovering a surface or a solid that matches these samples. This problem is inherently ill-posed as infinitely-many shapes may fit the data. One must thus regularize the problem and add priors such as simplicity or smoothness of the inferred shape.</p>
      <p>The concept of geometric simplicity has led to a number of interpolating techniques commonly based upon the Delaunay triangulation. The concept of smoothness has led to a number of approximating techniques that commonly compute an implicit function such that one of its isosurfaces approximates the inferred surface. Reconstruction algorithms can also use an explicit set of prior shapes for inference by assuming that the observed data can be described by these predefined prior shapes. One key lesson learned in the shape problem is that there is probably not a single solution which can solve all cases, each of them coming with its own distinctive features. In addition, some data sets such as point sets acquired on urban scenes are very domain-specific and require a dedicated line of research.</p>
      <p>In recent years the <i>smooth, closed case</i> (i.e., shapes without sharp features nor boundaries) has received considerable attention. However, the state-of-the-art methods have several shortcomings: in addition to being in general not robust to outliers and not sufficiently robust to noise, they often require additional attributes as input, such as lines of sight or oriented normals. We wish to devise shape reconstruction methods which are both geometrically and topologically accurate without requiring additional attributes, while exhibiting resilience to defect-laden inputs. Resilience formally translates into stability with respect to noise and outliers. Correctness of the reconstruction translates into convergence in geometry and (stable parts of) topology of the reconstruction with respect to the inferred shape known through measurements.</p>
      <p>Moving from the smooth, closed case to the <i>piecewise smooth case</i> (possibly with boundaries) is considerably harder as the ill-posedness of the problem applies to each sub-feature of the inferred shape. Further, very few approaches tackle the combined issue of robustness (to sampling defects, noise and outliers) and feature reconstruction.
</p>
    </subsection>
  </fondements>
  <domaine id="uid9">
    <bodyTitle>Application Domains</bodyTitle>
    <subsection id="uid10" level="1">
      <bodyTitle>Applications</bodyTitle>
      <p>In addition to tackling enduring scientific challenges, our research on geometric modeling and processing is motivated by applications to computational engineering, reverse engineering, digital mapping and urban planning.
The main deliverable of our research will be algorithms with theoretical foundations. Ultimately we wish to contribute making geometry modeling and processing routine for practitioners who deal with real-world data. Our contributions may also be used as a sound basis for future software and technology developments.</p>
      <p>Our first ambition for technology transfer is to consolidate the components of our research experiments in the form of new software components for the CGAL (Computational Geometry Algorithms Library) library. Through CGAL we wish to contribute to the “standard geometric toolbox”, so as to provide a generic answer to application needs instead of fragmenting our contributions. We already cooperate with the Inria spin-off company Geometry Factory, which commercializes CGAL, maintains it and provide technical support.</p>
      <p>Our second ambition is to increase the research momentum of companies through advising Cifre Ph.D. theses and postdoctoral fellows on topics that match our research program.</p>
    </subsection>
  </domaine>
  <highlights id="uid11">
    <bodyTitle>Highlights of the Year</bodyTitle>
    <subsection id="uid12" level="1">
      <bodyTitle>Highlights of the Year</bodyTitle>
      <subsection id="uid13" level="2">
        <bodyTitle>Awards</bodyTitle>
        <p>We obtained a Proof of Concept grant from the European Research Council, entitled TITANIUM (Software Components for Robust Geometry Processing). The TITANIUM project aims to develop a software demonstrator for geometry processing and 3D urban modeling, in order to facilitate the pre-commercialization of novel software components for the Computational Geometry Algorithms Library. The demonstrator will include novel approaches resulting from the ERC-funded IRON project.</p>
        <best>
          <ref xlink:href="#titane-2016-bid0" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>
        </best>
        <p>.</p>
      </subsection>
    </subsection>
  </highlights>
  <logiciels id="uid14">
    <bodyTitle>New Software and Platforms</bodyTitle>
    <subsection id="uid15" level="1">
      <bodyTitle>CGAL Barycentric_coordinates_2</bodyTitle>
      <p>This CGAL software component offers an efficient and robust implementation of two-dimensional closed-form generalized barycentric coordinates defined for simple two-dimensional polygons.</p>
      <simplelist>
        <li id="uid16">
          <p noindent="true">Participants: Pierre Alliez</p>
        </li>
        <li id="uid17">
          <p noindent="true">Contact: Pierre Alliez</p>
        </li>
        <li id="uid18">
          <p noindent="true">URL: <ref xlink:href="http://doc.cgal.org/latest/Barycentric_coordinates_2/index.html#Chapter_2D_Generalized_Barycentric_Coordinates" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>doc.<allowbreak/>cgal.<allowbreak/>org/<allowbreak/>latest/<allowbreak/>Barycentric_coordinates_2/<allowbreak/>index.<allowbreak/>html#Chapter_2D_Generalized_Barycentric_Coordinates</ref></p>
        </li>
      </simplelist>
    </subsection>
    <subsection id="uid19" level="1">
      <bodyTitle>MeshMantics</bodyTitle>
      <p>This software component implements an approach that reconstructs 3D urban scenes in the form of levels of detail (LODs). Starting from raw data sets such as surface meshes generated by multi-view stereo systems, the algorithm proceeds in three main steps: classification, abstraction and reconstruction. From geometric attributes and a set of semantic rules combined with a Markov random field, we classify the scene into four meaningful classes. The abstraction step detects and regularizes planar structures on buildings, fits icons on trees, roofs and facades, and performs filtering and simplification for LOD generation. The abstracted data are then provided as input to the reconstruction step which generates watertight buildings through a min-cut formulation on a set of 3D arrangements.</p>
      <simplelist>
        <li id="uid20">
          <p noindent="true">Participants: Florent Lafarge and Pierre Alliez</p>
        </li>
        <li id="uid21">
          <p noindent="true">Contact: Pierre Alliez</p>
        </li>
        <li id="uid22">
          <p noindent="true">URL: <ref xlink:href="https://bil.inria.fr" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>bil.<allowbreak/>inria.<allowbreak/>fr</ref></p>
        </li>
      </simplelist>
    </subsection>
    <subsection id="uid23" level="1">
      <bodyTitle>Module CGAL : Point Set Processing</bodyTitle>
      <p>This CGAL component implements methods to analyze and process unorganized point sets. The input is an unorganized point set, possibly with normal attributes (unoriented or oriented). The point set can be analyzed to measure its average spacing, and processed through functions devoted to the simplification, outlier removal, smoothing, normal estimation, normal orientation and feature edges estimation.</p>
      <simplelist>
        <li id="uid24">
          <p noindent="true">Participants: Pierre Alliez and Clément Jamin</p>
        </li>
        <li id="uid25">
          <p noindent="true">Contact: Pierre Alliez</p>
        </li>
        <li id="uid26">
          <p noindent="true">URL: <ref xlink:href="http://doc.cgal.org/latest/Point_set_processing_3/index.html#Chapter_Point_Set_Processing" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>doc.<allowbreak/>cgal.<allowbreak/>org/<allowbreak/>latest/<allowbreak/>Point_set_processing_3/<allowbreak/>index.<allowbreak/>html#Chapter_Point_Set_Processing</ref></p>
        </li>
      </simplelist>
    </subsection>
    <subsection id="uid27" level="1">
      <bodyTitle>Module CGAL : Scale space surface reconstruction</bodyTitle>
      <p>This method allows to reconstruct a surface that interpolates a set of 3D points. This method provides an efficient alternative to the Poisson surface reconstruction method. The main difference in output is that this method reconstructs a surface that interpolates the point set (as opposed to approximating the point set). How the surface connects the points depends on a scale variable, which can be estimated semi-automatically.</p>
      <simplelist>
        <li id="uid28">
          <p noindent="true">Participants: Pierre Alliez</p>
        </li>
        <li id="uid29">
          <p noindent="true">Contact: Pierre Alliez</p>
        </li>
        <li id="uid30">
          <p noindent="true">URL: <ref xlink:href="http://doc.cgal.org/latest/Scale_space_reconstruction_3/index.html#Chapter_Scale_space_reconstruction" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>doc.<allowbreak/>cgal.<allowbreak/>org/<allowbreak/>latest/<allowbreak/>Scale_space_reconstruction_3/<allowbreak/>index.<allowbreak/>html#Chapter_Scale_space_reconstruction</ref></p>
        </li>
      </simplelist>
    </subsection>
    <subsection id="uid31" level="1">
      <bodyTitle>Skeleton-Blockers</bodyTitle>
      <p>Skeleton-Blockers is a compact, efficient and generic data-structure that can represent any simplicial complex. The implementation is in C++11.</p>
      <simplelist>
        <li id="uid32">
          <p noindent="true">Participant: David Salinas</p>
        </li>
        <li id="uid33">
          <p noindent="true">Contact: David Salinas</p>
        </li>
        <li id="uid34">
          <p noindent="true">URL: <ref xlink:href="https://project.inria.fr/gudhi/software/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>project.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>gudhi/<allowbreak/>software/</ref></p>
        </li>
      </simplelist>
    </subsection>
    <subsection id="uid35" level="1">
      <bodyTitle>APP Deposits</bodyTitle>
      <p>WALLEMME is a software for classifying large-scale urban areas from dense textured 3D meshes in a supervised manner.</p>
      <simplelist>
        <li id="uid36">
          <p noindent="true">Participants: Mohammad Rouhani, Florent Lafarge and Pierre Alliez.</p>
        </li>
      </simplelist>
      <p>DIMUVIC is a software for reconstructing in 3D a polyline-sketch using contextual knowledge contained in multiview stereo images.</p>
      <simplelist>
        <li id="uid37">
          <p noindent="true">Participants: Jean-Dominique Favreau, Florent Lafarge and Adrien Bousseau.</p>
        </li>
      </simplelist>
      <p>ROOFEXTRACTOR is a software for reconstructing roofs from dense defect-laden meshes as compact piecewise-planar surface representations.</p>
      <simplelist>
        <li id="uid38">
          <p noindent="true">Participants: Sven Oesau and Florent Lafarge.</p>
        </li>
      </simplelist>
    </subsection>
  </logiciels>
  <resultats id="uid39">
    <bodyTitle>New Results</bodyTitle>
    <subsection id="uid40" level="1">
      <bodyTitle>Analysis</bodyTitle>
      <subsection id="uid41" level="2">
        <bodyTitle>Object Classification via Planar Abstraction</bodyTitle>
        <participants>
          <person key="titane-2014-idp74264">
            <firstname>Sven</firstname>
            <lastname>Oesau</lastname>
          </person>
          <person key="titane-2014-idm27920">
            <firstname>Florent</firstname>
            <lastname>Lafarge</lastname>
          </person>
          <person key="titane-2014-idm30672">
            <firstname>Pierre</firstname>
            <lastname>Alliez</lastname>
          </person>
        </participants>
        <moreinfo>
          <p>In collaboration with EADS ASTRIUM</p>
        </moreinfo>
        <p>We contributed a supervised machine learning approach for classification of objects from sampled point data. The main idea consists in first abstracting the input object into planar parts at several scales, then discriminate between the different classes of objects solely through features derived from these planar shapes. Abstracting into planar shapes provides a means to both reduce the computational complexity and improve robustness to defects inherent to the acquisition process. Measuring statistical properties and relationships between planar shapes offers invariance to scale and orientation. A random forest is then used for solving the multiclass classification problem. We demonstrate the potential of our approach on a set of indoor objects from the Princeton shape benchmark and on objects acquired from indoor scenes and compare the performance of our method with other point-based shape descriptors <ref xlink:href="#titane-2016-bid1" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. This work was published in the proceedings of ISPRS.</p>
      </subsection>
      <subsection id="uid42" level="2">
        <bodyTitle>Fidelity vs. Simplicity: a Global Approach to Line Drawing Vectorization</bodyTitle>
        <participants>
          <person key="titane-2014-idp70536">
            <firstname>Jean-Dominique</firstname>
            <lastname>Favreau</lastname>
          </person>
          <person key="titane-2014-idm27920">
            <firstname>Florent</firstname>
            <lastname>Lafarge</lastname>
          </person>
        </participants>
        <moreinfo>
          <p>In collaboration with Adrien Bousseau (GraphDeco Inria team)</p>
        </moreinfo>
        <p>Vector drawing is a popular representation in graphic design because of the precision, compactness and editability offered by parametric curves. However, prior work on line drawing vectorization focused solely on faithfully capturing input bitmaps, and largely overlooked the problem of producing a compact and editable curve network. As a result, existing algorithms tend to produce overly-complex drawings composed of many short curves and control points, especially in the presence of thick or sketchy lines that yield spurious curves at junctions. We propose the first vectorization algorithm that explicitly balances fidelity to the input bitmap with simplicity of the output, as measured by the number of curves and their degree. By casting this trade-off as a global optimization, our algorithm generates few yet accurate curves, and also disambiguates curve topology at junctions by favoring the simplest interpretations overall. We demonstrate the robustness of our algorithm on a variety of drawings, sketchy cartoons and rough design sketches (See Figure <ref xlink:href="#uid43" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>). This work was published at ACM SIGGRAPH 2016 <ref xlink:href="#titane-2016-bid2" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        <object id="uid43">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/siggraph16.png" type="float" width="298.8987pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>Line Drawing Vectorization. Rough sketches often contain overlapping strokes (left). Since existing algorithms analyze junctions locally, they cannot recover the proper topology of these seemingly similar line configurations. By adopting a global formulation that optimizes for both fidelity to the input sketch and simplicity of the output curve network, our algorithm recovers proper topology while significantly reducing the overall number of curves and control points (right). Design sketch after Sori Yanagi Butterfly stool.</caption>
        </object>
      </subsection>
      <subsection id="uid44" level="2">
        <bodyTitle>High-Resolution Semantic Labeling with Convolutional Neural Networks</bodyTitle>
        <participants>
          <person key="ayin-2014-idp84096">
            <firstname>Emmanuel</firstname>
            <lastname>Maggiori</lastname>
          </person>
          <person key="ayin-2014-idp63848">
            <firstname>Yuliya</firstname>
            <lastname>Tarabalka</lastname>
          </person>
          <person key="titane-2014-idm30672">
            <firstname>Pierre</firstname>
            <lastname>Alliez</lastname>
          </person>
        </participants>
        <moreinfo>
          <p>In collaboration with Guillaume Charpiat (Inria TAO team)</p>
        </moreinfo>
        <p>Convolutional neural networks (CNNs) were initially conceived for image categorization, i.e., the problem of assigning a semantic label to an entire input image. We have address the problem of dense semantic labeling, which consists in assigning a semantic label to <i>every</i> pixel in an image. Since this requires a high spatial accuracy to determine <i>where</i> labels are assigned, categorization CNNs, intended to be highly robust to local deformations, are not directly applicable.
By adapting categorization networks, many semantic labeling CNNs have been recently proposed. Our first contribution is an in-depth analysis of these architectures. We establish the desired properties of an ideal semantic labeling CNN, and assess how those methods stand with regard to these properties. We observe that even though they provide competitive results, these CNNs often do not leverage properties of semantic labeling that could lead to more effective and efficient architectures.
Out of these observations, we then derive a CNN framework specifically adapted to the semantic labeling problem <ref xlink:href="#titane-2016-bid3" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. In addition to learning features at different resolutions, it learns how to combine these features. By integrating local and global information in an efficient and flexible manner, it outperforms previous techniques. We evaluate the proposed framework and compare it with state-of-the-art architectures on public benchmarks of high-resolution aerial image labeling.</p>
        <object id="uid45">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/highres.png" type="float" width="298.8987pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>Our MLP network architecture (left) learns features at different resolutions and also learns how to combine those features. The technique was evaluated on the ISPRS 2D Semantic Segmentation Contest (right), providing competitive results.</caption>
        </object>
      </subsection>
      <subsection id="uid46" level="2">
        <bodyTitle>Learning Iterative Processes with Recurrent Neural Networks to Correct Satellite Image Classification Maps</bodyTitle>
        <participants>
          <person key="ayin-2014-idp84096">
            <firstname>Emmanuel</firstname>
            <lastname>Maggiori</lastname>
          </person>
          <person key="ayin-2014-idp63848">
            <firstname>Yuliya</firstname>
            <lastname>Tarabalka</lastname>
          </person>
          <person key="titane-2014-idm30672">
            <firstname>Pierre</firstname>
            <lastname>Alliez</lastname>
          </person>
        </participants>
        <moreinfo>
          <p>In collaboration with Guillaume Charpiat (Inria TAO team)</p>
        </moreinfo>
        <p>While initially devised for image categorization, convolutional neural networks (CNNs) are being increasingly used for the pixelwise semantic labeling of images. However, the proper nature of the most common CNN architectures makes them good at recognizing but poor at localizing objects precisely. This problem is magnified in the context of aerial and satellite image labeling, where a spatially fine object outlining is of paramount importance.</p>
        <p>Different iterative enhancement algorithms have been presented in the literature to progressively improve the coarse CNN outputs, seeking to sharpen object boundaries around real image edges. However, one must carefully design, choose and tune such algorithms. Instead, our goal is to directly learn the iterative process itself. For this, we formulate a generic iterative enhancement process inspired from partial differential equations, and observe that it can be expressed as a recurrent neural network (RNN). Consequently, we train such a network from manually labeled data for our enhancement task. In a series of experiments we show that our RNN effectively learns an iterative process that significantly improves the quality of satellite image classification maps <ref xlink:href="#titane-2016-bid4" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        <object id="uid47">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/rnn.png" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>A recurrent neural network (RNN) learns an algorithm to iteratively correct the output of a coarse classification map. As a result, the satellite image classification maps become finer and better aligned to the real objects.</caption>
        </object>
      </subsection>
      <subsection id="uid48" level="2">
        <bodyTitle>Convolutional Neural Networks for Large-Scale Remote-Sensing Image Classification</bodyTitle>
        <participants>
          <person key="ayin-2014-idp84096">
            <firstname>Emmanuel</firstname>
            <lastname>Maggiori</lastname>
          </person>
          <person key="ayin-2014-idp63848">
            <firstname>Yuliya</firstname>
            <lastname>Tarabalka</lastname>
          </person>
          <person key="titane-2014-idm30672">
            <firstname>Pierre</firstname>
            <lastname>Alliez</lastname>
          </person>
        </participants>
        <moreinfo>
          <p>In collaboration with Guillaume Charpiat (Inria TAO team)</p>
        </moreinfo>
        <p>We propose an end-to-end framework for the dense, pixelwise classification of satellite imagery with convolutional neural networks (CNNs). In our framework, CNNs are directly trained to produce classification maps out of the input images. We first devise a <i>fully convolutional</i> architecture and demonstrate its relevance to the dense classification problem. We then address the issue of imperfect training data through a two-step training approach: CNNs are first initialized by using a large amount of possibly inaccurate reference data, then refined on a small amount of accurately labeled data. To complete our framework we design a multi-scale neuron module that alleviates the common trade-off between recognition and precise localization. A series of experiments show that our networks take into account a large amount of context to provide fine-grained classification maps. This work was published in IEEE Transactions on Geoscience and Remote Sensing (TGRS) <ref xlink:href="#titane-2016-bid5" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        <object id="uid49">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/tgrs.png" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>We train in a two-step scheme: first we train a fully convolutional network on large amounts of imperfect training data, to capture the generalities of the problem, which leads to coarse classification maps (1). In a second stage we fine-tune the network for few iterations on a precise manually labeled dataset, outputting fine classification maps as a results (2). The overall system is efficient and scalable.</caption>
        </object>
      </subsection>
      <subsection id="uid50" level="2">
        <bodyTitle>Fully Convolutional Neural Networks for Remote Sensing Image Classification</bodyTitle>
        <participants>
          <person key="ayin-2014-idp84096">
            <firstname>Emmanuel</firstname>
            <lastname>Maggiori</lastname>
          </person>
          <person key="ayin-2014-idp63848">
            <firstname>Yuliya</firstname>
            <lastname>Tarabalka</lastname>
          </person>
          <person key="titane-2014-idm30672">
            <firstname>Pierre</firstname>
            <lastname>Alliez</lastname>
          </person>
        </participants>
        <moreinfo>
          <p>In collaboration with Guillaume Charpiat (Inria TAO team)</p>
        </moreinfo>
        <p>We propose a convolutional neural network (CNN) model for remote sensing image classification, i.e. the assignment of a class to every pixel in an image. Using CNNs provides us with a means of learning contextual features for large-scale image labeling. Our network consists of four stacked convolutional layers that downsample the image and extract relevant features. On top of these, a deconvolutional layer upsamples the data back to the initial resolution, producing a final dense image labeling. Contrary to previous frameworks, our architecture is a fully convolutional network (FCN), contains only convolution and deconvolution operations and no fully connected layers as in previous work. The fact of being fully convolutional removes the artifacts present in previous work by construction and is considerably more efficient. Experiments on aerial images show that our network produces more accurate classifications in lower computational time. This work was published in the proceedings of the IEEE International Geoscience and Remote Sensing Symposium (IGARSS) <ref xlink:href="#titane-2016-bid6" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        <object id="uid51">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/igarss.png" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>Our fully convolutional network (FCN) provides a better accuracy compared to a previous method (the “patch-based” network), as observed by the evolution of the accuracy through the training iterations (a) and the final precision/recall curve (b). We can also observe, visually, that our FCN network removes the artifacts at the border of patches (c). Besides the improved performance, the architecture drastically reduces the number of trainable parameters, being 10 times faster to run compared to the patch-based counterpart.</caption>
        </object>
      </subsection>
      <subsection id="uid52" level="2">
        <bodyTitle>Large-scale Remote Sensing Image Segmentation and Classification</bodyTitle>
        <participants>
          <person key="titane-2016-idp158464">
            <firstname>Chunlin</firstname>
            <lastname>Xiao</lastname>
          </person>
          <person key="ayin-2014-idp84096">
            <firstname>Emmanuel</firstname>
            <lastname>Maggiori</lastname>
          </person>
          <person key="ayin-2014-idp63848">
            <firstname>Yuliya</firstname>
            <lastname>Tarabalka</lastname>
          </person>
        </participants>
        <moreinfo>
          <p>In collaboration with Guillaume Charpiat (Inria TAO team)</p>
        </moreinfo>
        <p>The representation of images with binary partition trees (BPTs) has proven to be very efficient for multiscale analysis, object detection and classification of high-resolution images. We propose a new framework for multi-class image segmentation using a binary partition tree. The region model is composed of three components : color component, probability component and shape component, some of which can be used or omitted depending on the information available and the application itself. The problem to extract a segmentation is formulated as the minimization of an energy function which can be solved with dynamical programming efficiently. However, BPT represents a hierarchy of the image regions at different scales. For large-scale images such representation can be demanding in terms of both memory and computation resources. We propose a tile-based scheme to extend the framework for processing arbitrarily large images. Experiments (see Fig. <ref xlink:href="#uid53" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>) prove that the algorithm can segment large images efficiently while ensuring quite similar results with respect to processing the whole image at once. This work has not been published yet.</p>
        <object id="uid53">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/ls.png" type="float" width="341.6013pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>Results of (left) unsupervised segmentation and (right) supervised segmentation of the image into building (red) and non-building (green) regions, using 4 <formula type="inline"><math xmlns="http://www.w3.org/1998/Math/MathML" overflow="scroll"><mo>×</mo></math></formula> 4 tiling scheme.</caption>
        </object>
      </subsection>
    </subsection>
    <subsection id="uid54" level="1">
      <bodyTitle>Reconstruction</bodyTitle>
      <subsection id="uid55" level="2">
        <bodyTitle>Towards Large-scale City Reconstruction from Satellites</bodyTitle>
        <participants>
          <person key="titane-2014-idp69312">
            <firstname>Liuyun</firstname>
            <lastname>Duan</lastname>
          </person>
          <person key="titane-2014-idm27920">
            <firstname>Florent</firstname>
            <lastname>Lafarge</lastname>
          </person>
        </participants>
        <moreinfo>
          <p>In collaboration with Geoimage.</p>
        </moreinfo>
        <p>Automatic city modeling from satellite imagery is one of the biggest challenges in urban reconstruction. Existing methods produce at best rough and dense Digital Surface Models. Inspired by recent works on semantic 3D reconstruction and region-based stereovision, we propose a method for producing compact, semantic-aware and geometrically accurate 3D city models from stereo pair of satellite images <ref xlink:href="#titane-2016-bid7" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. Our approach relies on two key ingredients. First, geometry and semantics are retrieved simultaneously bringing robustness to occlusions and to low image quality. Second, we operate at the scale of geometric atomic region which allows the shape of urban objects to be well preserved, and a gain in scalability and efficiency. We demonstrate the potential of our algorithm by reconstructing different cities around the world in a few minutes (See Figure <ref xlink:href="#uid56" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>). This work has been published in the proceedings of the European Conference on Computer Vision (ECCV).</p>
        <object id="uid56">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/eccv.png" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>City reconstruction from satellites. Starting from a stereo pair of satellite images (left), our algorithm produces a compact and semantic-aware 3D model (right) in a few minutes.</caption>
        </object>
      </subsection>
      <subsection id="uid57" level="2">
        <bodyTitle>A Survey of Surface Reconstruction from Point Clouds</bodyTitle>
        <participants>
          <person key="titane-2014-idm30672">
            <firstname>Pierre</firstname>
            <lastname>Alliez</lastname>
          </person>
        </participants>
        <moreinfo>
          <p>In collaboration with Matthew Berger, Andrea Tagliasacchi, Lee Seversky, Gael Guennebaud (Inria MANAO), Joshua Levine, Andrei Sharf and Claudio Silva.</p>
        </moreinfo>
        <p>The area of surface reconstruction has seen substantial progress in the past two decades. The traditional problem addressed by surface reconstruction is to recover the digital representation of a physical shape that has been scanned, where the scanned data contains a wide variety of defects. While much of the earlier work has been focused on reconstructing a piece-wise smooth representation of the original shape, recent work has taken on more specialized priors to address significantly challenging data imperfections, where the reconstruction can take on different representations – not necessarily the explicit geometry. We survey the field of surface reconstruction, and provide a categorization with respect to priors, data imperfections, and reconstruction output. By considering a holistic view of surface reconstruction, we show a detailed characterization of the field, highlight similarities between diverse reconstruction techniques, and provide directions for future work in surface reconstruction. This survey was published in Computer Graphics Forum <ref xlink:href="#titane-2016-bid8" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
      </subsection>
    </subsection>
    <subsection id="uid58" level="1">
      <bodyTitle>Approximation</bodyTitle>
      <subsection id="uid59" level="2">
        <bodyTitle>A Line/Trimmed NURBS Surface Intersection Algorithm Using Matrix Representations</bodyTitle>
        <participants>
          <person key="titane-2014-idm30672">
            <firstname>Pierre</firstname>
            <lastname>Alliez</lastname>
          </person>
        </participants>
        <moreinfo>
          <p>In collaboration with Laurent Busé from Inria AROMATH, and Jingjing Shen and Neil Dodgson from Cambridge University (UK).</p>
        </moreinfo>
        <p>We contribute a reliable line/surface intersection method for trimmed NURBS surfaces, based on a novel matrix-based implicit representation and numerical methods in linear algebra such as singular value decomposition and the computation of generalized eigenvalues and eigenvectors. A careful treatment of degenerate cases makes our approach robust to intersection points with multiple pre-images. We then apply our intersection algorithm to seamlessly mesh NURBS surfaces through Delaunay refinement (see Figure <ref xlink:href="#uid60" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>). We demonstrate the added value of our approach in terms of accuracy and treatment of degenerate cases, by providing comparisons with other intersection approaches as well as a variety of meshing experiments. This work was published in Computer Aided Geometric Design <ref xlink:href="#titane-2016-bid9" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        <object id="uid60">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/cagd.png" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>Seamless meshing. Top: meshing with two mesh sizing values. The initial point set is generated by sampling along the open boundary.
Bottom: meshing across smooth edges (red). The initial point set is generated by sampling along the boundary edge (blue). Meshes generated with two sizing values (side and front view).</caption>
        </object>
      </subsection>
      <subsection id="uid61" level="2">
        <bodyTitle>Optimal Voronoi Tessellations with Hessian-based Anisotropy</bodyTitle>
        <participants>
          <person key="titane-2014-idm30672">
            <firstname>Pierre</firstname>
            <lastname>Alliez</lastname>
          </person>
          <person key="titane-2014-idp80456">
            <firstname>Mathieu</firstname>
            <lastname>Desbrun</lastname>
          </person>
        </participants>
        <moreinfo>
          <p>In collaboration with Max Budninskiy and Beibei Liu from Caltech, Fernando de Goes from Pixar and Yiying Tong from Michigan State University.</p>
        </moreinfo>
        <p>We contribute a variational method to generate cell complexes with local anisotropy conforming to the Hessian of any given convex function and for any given local mesh density. Our formulation builds upon approximation theory to offer an anisotropic extension of Centroidal Voronoi Tessellations which can be seen as a dual form of Optimal Delaunay Triangulation. We thus refer to the resulting anisotropic polytopal meshes as Optimal Voronoi Tessellations. Our approach sharply contrasts with previous anisotropic versions of Voronoi diagrams as it employs first-type Bregman diagrams, a generalization of power diagrams where sites are augmented with not only a scalar-valued weight but also a vector-valued shift. As such, our OVT meshes contain only convex cells with straight edges (Figure <ref xlink:href="#uid62" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>), and admit an embedded dual triangulation that is combinatorially-regular. We show the effectiveness of our technique using off-the-shelf computational geometry libraries. This work was published at ACM SIGGRAPH Asia <ref xlink:href="#titane-2016-bid10" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        <object id="uid62">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/sigasia.png" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>Optimal Voronoi Tessellations with Hessian-based Anisotropy. We show that the construction of an optimal piecewise-linear approximation of a function over a cell complex (left) extends the isotropic notion of Centroidal Voronoi Tessellations (CVT, top) to an anisotropic variant (middle and bottom) we call Optimal Voronoi Tessellation (OVT), to stress its duality to Optimal Delaunay Triangulation (ODT). Cell anisotropy (indicated by tightest ellipses) and density are independently controlled, and the dual triangulation based on cell barycenters is embedded and combinatorially-regular.</caption>
        </object>
      </subsection>
      <subsection id="uid63" level="2">
        <bodyTitle>Symmetry and Orbit Detection via Lie-Algebra Voting</bodyTitle>
        <participants>
          <person key="titane-2014-idm30672">
            <firstname>Pierre</firstname>
            <lastname>Alliez</lastname>
          </person>
          <person key="titane-2014-idp80456">
            <firstname>Mathieu</firstname>
            <lastname>Desbrun</lastname>
          </person>
        </participants>
        <moreinfo>
          <p>In collaboration with Zeyun Shi, Hujun Bao and Jin Huang from Zhejiang University.</p>
        </moreinfo>
        <p>We formulate an automatic approach to the detection of partial, local, and global symmetries and orbits in arbitrary 3D datasets. We improve upon existing voting-based symmetry detection techniques by leveraging the Lie group structure of geometric transformations. In particular, we introduce a logarithmic mapping that ensures that orbits are mapped to linear subspaces, hence unifying and extending many existing mappings in a single Lie-algebra voting formulation (Figure <ref xlink:href="#uid64" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>). Compared to previous work, our resulting method offers significantly improved robustness as it guarantees that our symmetry detection of an input model is frame, scale, and reflection invariant. As a consequence, we demonstrate that our approach efficiently and reliably discovers symmetries and orbits of geometric datasets without requiring heavy parameter tuning. This work was published in the proceedings of the EUROGRAPHICS Symposium on Geometry Processing <ref xlink:href="#titane-2016-bid0" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        <object id="uid64">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/sgp.png" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>Our Lie algebra voting approach to symmetry and orbit detection maps SE(3) transformations into points in a logarithmic space composed of a rotation part and a translation part. The rotational orbit of the church and the translational orbit of the side railing (a) are mapped into collinear blue and red spheres respectively (a few transformations within these two orbits are marked with circled numbers to enhance comprehension). When the scene is centered, the two lines are orthogonal to each other and easy to distinguish (b). However, after a rigid translation of the scene, the rotational orbit now has translation-values near the translation orbit points, making it impossible to automatically distinguish these two orbits using a Euclidean distance (d), while our adjoint invariant distance for orbit shows no discernible difference in results as evidenced by a binning of detected orbit sizes for both situations (e).</caption>
        </object>
      </subsection>
    </subsection>
  </resultats>
  <contrats id="uid65">
    <bodyTitle>Bilateral Contracts and Grants with Industry</bodyTitle>
    <subsection id="uid66" level="1">
      <bodyTitle>Bilateral Contracts with Industry</bodyTitle>
      <subsection id="uid67" level="2">
        <bodyTitle>Geoimage</bodyTitle>
        <participants>
          <person key="titane-2014-idp69312">
            <firstname>Liuyun</firstname>
            <lastname>Duan</lastname>
          </person>
          <person key="titane-2014-idm27920">
            <firstname>Florent</firstname>
            <lastname>Lafarge</lastname>
          </person>
        </participants>
        <p>The aim of this collaboration is to devise a new type of 2.5D representation from satellite multi-view stereo images which is more accurate, compact and meaningful than the conventional digital elevation models (DEMs). A key direction consists in incorporating semantic information directly during the image matching process. This semantic is related to the type of components of the scene, such as vegetation, roofs, building edges, roads and land.</p>
        <p>- Starting date: November 2013
- Duration: 4 years</p>
      </subsection>
      <subsection id="uid68" level="2">
        <bodyTitle>CSTB 1</bodyTitle>
        <participants>
          <person key="titane-2014-idp74264">
            <firstname>Sven</firstname>
            <lastname>Oesau</lastname>
          </person>
          <person key="titane-2014-idm27920">
            <firstname>Florent</firstname>
            <lastname>Lafarge</lastname>
          </person>
        </participants>
        <p>The goal of this collaboration was to consolidate and integrate research codes developed in Titane on urban semantization and reconstruction into the CSTB reconstruction platform.</p>
        <p>- Starting date: September 2015
- Duration: 6 months</p>
      </subsection>
      <subsection id="uid69" level="2">
        <bodyTitle>CSTB 2</bodyTitle>
        <participants>
          <person key="titane-2015-idp82392">
            <firstname>Hao</firstname>
            <lastname>Fang</lastname>
          </person>
          <person key="titane-2014-idm27920">
            <firstname>Florent</firstname>
            <lastname>Lafarge</lastname>
          </person>
        </participants>
        <p>The goal of this recent collaboration is to develop methods for analyzing and exploring scale-spaces into urban 3D data.</p>
        <p>- Starting date: March 2016
- Duration: 3 years</p>
      </subsection>
      <subsection id="uid70" level="2">
        <bodyTitle>Luxcarta</bodyTitle>
        <participants>
          <person key="titane-2016-idp126304">
            <firstname>Jean-Philippe</firstname>
            <lastname>Bauchet</lastname>
          </person>
          <person key="titane-2014-idm27920">
            <firstname>Florent</firstname>
            <lastname>Lafarge</lastname>
          </person>
        </participants>
        <p>The goal of this recent collaboration is to design automatics approaches for producing LOD2 city models from the last generation of satellites.</p>
        <p>- Starting date: October 2016
- Duration: 3 years</p>
      </subsection>
    </subsection>
    <subsection id="uid71" level="1">
      <bodyTitle>Bilateral Grants with Industry</bodyTitle>
      <subsection id="idp4093216" level="2">
        <bodyTitle>CNES Toulouse</bodyTitle>
        <participants>
          <person key="ayin-2014-idp84096">
            <firstname>Emmanuel</firstname>
            <lastname>Maggiori</lastname>
          </person>
          <person key="ayin-2014-idp63848">
            <firstname>Yuliya</firstname>
            <lastname>Tarabalka</lastname>
            <moreinfo>PI</moreinfo>
          </person>
        </participants>
        <p>Hierarchical approaches for object-oriented classification of multi-source images. Contract 150490/00.</p>
        <p>- Starting date: November 2015</p>
        <p noindent="true">- Duration: 2 years</p>
      </subsection>
    </subsection>
  </contrats>
  <partenariat id="uid72">
    <bodyTitle>Partnerships and Cooperations</bodyTitle>
    <subsection id="uid73" level="1">
      <bodyTitle>European Initiatives</bodyTitle>
      <subsection id="uid74" level="2">
        <bodyTitle>FP7 &amp; H2020 Projects</bodyTitle>
        <subsection id="uid75" level="3">
          <bodyTitle>TITANIUM - Software Components for Robust Geometry Processing</bodyTitle>
          <sanspuceslist>
            <li id="uid76">
              <p noindent="true">Type: IDEAS</p>
            </li>
            <li id="uid77">
              <p noindent="true">Instrument: ERC Proof of concept</p>
            </li>
            <li id="uid78">
              <p noindent="true">Duration: 18 months</p>
            </li>
            <li id="uid79">
              <p noindent="true">Coordinator: Pierre Alliez</p>
            </li>
            <li id="uid80">
              <p noindent="true">Inria contact: Pierre Alliez</p>
            </li>
            <li id="uid81">
              <p noindent="true">Abstract: The TITANIUM project aims to develop a software demonstrator for geometry processing and 3D urban modeling, in order to facilitate the pre-commercialization of novel software components for the Computational Geometry Algorithms Library. The demonstrator will include novel approaches resulting from the ERC-funded IRON project (Robust Geometry Processing, StG-2010-257474), which are illustrated by publications presented at premier conferences in our field and a patent submitted in 2015. The expected outcomes of TITANIUM will be versatile methods for 3D reconstruction and simplification of data gathered from geometric measurements, as well as related methods specifically tailored to urban modeling. These methods represent a significant step forward by offering unrivaled levels of robustness, and automated generation of levels of detail that are semantically meaningful. The acronym TITANIUM, a robust and lightweight material, conveys our wish to streamline the geometric modeling pipeline through robust algorithms and lightweight representations. This Proof of Concept project will also implement the steps required for pre-commercialization. In view of this goal, we have included an industrial partner, GeometryFactory, a spinoff from Inria. We have already established preliminary contacts in the fields of metrology and geographic information systems. These contacts will provide real-world industrial case studies.</p>
            </li>
          </sanspuceslist>
        </subsection>
      </subsection>
    </subsection>
    <subsection id="uid82" level="1">
      <bodyTitle>International Initiatives</bodyTitle>
      <subsection id="uid83" level="2">
        <bodyTitle>Inria International Partners</bodyTitle>
        <subsection id="uid84" level="3">
          <bodyTitle>Declared Inria International Partners</bodyTitle>
          <p>We have a long standing collaboration with Prof. Mathieu Desbrun from Caltech.</p>
        </subsection>
        <subsection id="uid85" level="3">
          <bodyTitle>Informal International Partners</bodyTitle>
          <p>We collaborate with researchers from RWTH Aachen.</p>
        </subsection>
      </subsection>
    </subsection>
    <subsection id="uid86" level="1">
      <bodyTitle>International Research Visitors</bodyTitle>
      <subsection id="uid87" level="2">
        <bodyTitle>Visits of International Scientists</bodyTitle>
        <p>Prof. Mathieu Desbrun visited us for 3 months between August and November, within the framework of the Inria international chair.</p>
        <subsection id="uid88" level="3">
          <bodyTitle>Internships</bodyTitle>
          <p>Chunlin Xiao (University of Nice Sophia-Antipolis and University of L'Aquila): large-scale remote sensing image segmentation and classification.</p>
        </subsection>
      </subsection>
    </subsection>
  </partenariat>
  <diffusion id="uid89">
    <bodyTitle>Dissemination</bodyTitle>
    <subsection id="uid90" level="1">
      <bodyTitle>Promoting Scientific Activities</bodyTitle>
      <subsection id="uid91" level="2">
        <bodyTitle>Scientific Events Organisation</bodyTitle>
        <subsection id="uid92" level="3">
          <bodyTitle>General Chair, Scientific Chair</bodyTitle>
          <p>Florent Lafarge was co-chair of the ISPRS working group on point cloud processing.</p>
        </subsection>
        <subsection id="uid93" level="3">
          <bodyTitle>Member of the Organizing Committees</bodyTitle>
          <p>Pierre Alliez is a member of the Steering Board of the EUROGRAPHICS Workshop on Graphics and Cultural Heritage.</p>
          <p>Yuliya Tarabalka chaired a session “Classification of Hyperspectral Image” at IEEE IGARSS 2016.</p>
        </subsection>
      </subsection>
      <subsection id="uid94" level="2">
        <bodyTitle>Scientific Events Selection</bodyTitle>
        <subsection id="uid95" level="3">
          <bodyTitle>Member of the Conference Program Committees</bodyTitle>
          <p>Pierre Alliez was a program committee member of ACM SIGGRAPH, EUROGRAPHICS annual conference, EUROGRAPHICS Symposium on Geometry Processing, Geometric Modeling and Processing, Shape Modeling International and EUROGRAPHICS Workshop on Graphics and Cultural Heritage.</p>
          <p noindent="true">Florent Lafarge was a program committee member for the ISPRS congress in 2016.</p>
          <p noindent="true">Yuliya Tarabalka was a program committee member for ACIVS 2016, Lecce, Italy.</p>
        </subsection>
        <subsection id="uid96" level="3">
          <bodyTitle>Reviewer</bodyTitle>
          <p>Pierre Alliez was a reviewer for the conferences listed above, and for around 25 additional papers in several journals ranging from geometric modeling to computer vision.
Florent Lafarge was a reviewer for JPRS.</p>
          <p noindent="true">Yuliya Tarabalka was a reviewer for the conferences IEEE IGARSS (student competition selection committee) and ACIVS 2016.</p>
        </subsection>
      </subsection>
      <subsection id="uid97" level="2">
        <bodyTitle>Journal</bodyTitle>
        <subsection id="uid98" level="3">
          <bodyTitle>Member of the Editorial Boards</bodyTitle>
          <p>Pierre Alliez is an associate editor of ACM Transactions on Graphics, Elsevier Graphical Models, Computer Aided Geometric Design and Visual Informatics (since 2016).
He is also a member of the editorial board of the CGAL open source project.</p>
          <p>Florent Lafarge is an associate editor of The Visual Computer since 2015.</p>
          <p>Yuliya Tarabalka was a co-editor of the special issue “Hyperspectral Imaging and Image Processing” of the Springer journal Sensing and Imaging.</p>
        </subsection>
        <subsection id="uid99" level="3">
          <bodyTitle>Reviewer - Reviewing Activities</bodyTitle>
          <p>Florent Lafarge was a reviewer for CVPR, ECCV, and SIGGRAPH.</p>
          <p noindent="true">Yuliya Tarabalka was a reviewer for the journals IEEE TGRS and IEEE JSTARS.</p>
        </subsection>
      </subsection>
      <subsection id="uid100" level="2">
        <bodyTitle>Invited Talks</bodyTitle>
        <p noindent="true">Pierre Alliez gave an invited talk at the CVPR Workshop on Large Scale 3D Data: Acquisition, Modelling and Analysis. The talk was entitled: <i>Shape Reconstruction and Approximation: Robustness and Guarantees</i>. See <ref xlink:href="http://www.multimediauts.org/3DWorkshop_CVPR2016/Program.html" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>www.<allowbreak/>multimediauts.<allowbreak/>org/<allowbreak/>3DWorkshop_CVPR2016/<allowbreak/>Program.<allowbreak/>html</ref>.</p>
        <p noindent="true">He also gave a keynote at STAG 2016: Smart Tools and Apps in computer Graphics, organized October 3-4, in Genova, Italy. The talk was entitled: <i>Low Distortion Inter-surface Mapping via Optimal Mass Transport</i>.
He also gave a course at ACM SIGGRAPH on the CGAL library, in collaboration with Andreas Fabri from GeometryFactory.</p>
      </subsection>
      <subsection id="uid101" level="2">
        <bodyTitle>Scientific Expertise</bodyTitle>
        <p>Pierre Alliez was an evaluator and reviewer for the H2020, EuroSTARS and ERC programmes from the European commission.
He participated to the Scientific Commissions of Belgium FNRS (Fund for Scientific Research).
He was a member of the panel GEV 01 (mathematics and computer science) of ANVUR (Italian research evaluation agency). We evaluated the period 2011-2014 through bibliometry and peer-review.
He was also a reviewer for PRIN projects (fundamental research projects) for the MIUR (the Italian Ministry for Education, University and Research).</p>
        <p>Yuliya Tarabalka was an expert evaluator for an ANR project submission in May 2016. She is since November 2016 a member of the expert panel SBWT (signal processing) of the FWO (Belgian research funding foundation).</p>
      </subsection>
      <subsection id="uid102" level="2">
        <bodyTitle>Research Administration</bodyTitle>
        <p>Pierre Alliez: member of the BCP (bureau du CP) since 2015, comité MASTIC (popularization), and comité espace immersif.</p>
        <p>Florent Lafarge was an elected member of the Comité de Centre from 2013 to 2016, and a member of the CSD (Commission de Suivi Doctorale) from 2011 to 2016.</p>
        <p>Yuliya Tarabalka is an elected member of the Comité de Centre since 2016.</p>
      </subsection>
    </subsection>
    <subsection id="uid103" level="1">
      <bodyTitle>Teaching - Supervision - Juries</bodyTitle>
      <subsection id="uid104" level="2">
        <bodyTitle>Teaching</bodyTitle>
        <sanspuceslist>
          <li id="uid105">
            <p noindent="true">Master: Pierre Alliez and Florent Lafarge, Ingeniérie 3D, 21h, M2, university Nice Sophia Antipolis, France.</p>
          </li>
          <li id="uid106">
            <p noindent="true">Master: Pierre Alliez and Florent Lafarge, 3D Meshes and Applications, 32h, M2, Ecole des Ponts ParisTech, France.</p>
          </li>
          <li id="uid107">
            <p noindent="true">Master: Pierre Alliez, Mathématiques pour la géométrie, 24h, M2, EFREI, France.</p>
          </li>
          <li id="uid108">
            <p noindent="true">Master: Florent Lafarge, Traitement d'images numériques, 9h, M2, university Nice Sophia Antipolis, France.</p>
          </li>
          <li id="uid109">
            <p noindent="true">Master: Yuliya Tarabalka, Mathematical methods, 25h, MSc in data sciences and business analytics ESSEC-CS, CentraleSupelec, France.</p>
          </li>
          <li id="uid110">
            <p noindent="true">L2: Yuliya Tarabalka, Advanced algorithms, 28.5h, L2 Networks and Telecoms, IUT Nice Cote d'Azur, Sophia-Antipolis, France.</p>
          </li>
        </sanspuceslist>
      </subsection>
      <subsection id="uid111" level="2">
        <bodyTitle>Supervision</bodyTitle>
        <sanspuceslist>
          <li id="uid112">
            <p noindent="true">PhD defended November 29th: Manish Mandad, Shape approximation with guarantees, since October 2012, Pierre Alliez.</p>
          </li>
          <li id="uid113">
            <p noindent="true">PhD in progress: Dorothy Duan, Semantized Elevation Maps, since October 2013, Florent Lafarge.</p>
          </li>
          <li id="uid114">
            <p noindent="true">PhD in progress: Jean-Dominique Favreau, Sketch-based modeling in multi-view context, since October 2014, Florent Lafarge and Adrien Bousseau.</p>
          </li>
          <li id="uid115">
            <p noindent="true">PhD in progress: Hao Fang, Scale-space understanding in urban scenes, since March 2016, Florent Lafarge.</p>
          </li>
          <li id="uid116">
            <p noindent="true">PhD in progress: Jean-Philippe Bauchet, City modelling from high resolution satellite images, since October 2016, Florent Lafarge.</p>
          </li>
          <li id="uid117">
            <p noindent="true">PhD in progress: Emmanuel Maggiori, Representation and Analysis of Multisensor Remote Sensing Images with Partition Trees, University of Nice-Sophia Antipolis, since January 2015, Yuliya Tarabalka and Pierre Alliez.</p>
          </li>
        </sanspuceslist>
      </subsection>
      <subsection id="uid118" level="2">
        <bodyTitle>Juries</bodyTitle>
        <p>Pierre Alliez:</p>
        <simplelist>
          <li id="uid119">
            <p noindent="true">Thesis reviewer: Ludovic Blache (CReSTIC-SIC Reims).</p>
          </li>
          <li id="uid120">
            <p noindent="true">Thesis reviewer: Ruqi Huang (Inria Saclay).</p>
          </li>
          <li id="uid121">
            <p noindent="true">Thesis examiner: Mael Rouxel-Labbé (Inria Sophia Antipolis)</p>
          </li>
        </simplelist>
        <p>Florent Lafarge:</p>
        <simplelist>
          <li id="uid122">
            <p noindent="true">Thesis examiner: Remi Cura (University Paris Est).</p>
          </li>
        </simplelist>
        <p>Yuliya Tarabalka:</p>
        <simplelist>
          <li id="uid123">
            <p noindent="true">Monitoring committee for the thesis of Amine Bohi, Southern University of Toulon-Var in October 2016.</p>
          </li>
        </simplelist>
      </subsection>
    </subsection>
    <subsection id="uid124" level="1">
      <bodyTitle>Popularization</bodyTitle>
      <p>Pierre Alliez participated to the "Fête de la science" in Juan-les-Pins, October 22 and 23. He also gave two talks in high schools: April 28 in Celony, and February 25th in Aix Valabre, and organized a workshop for MathC2+ in June.</p>
    </subsection>
  </diffusion>
  <biblio id="bibliography" html="bibliography" numero="10" titre="Bibliography">
    
    <biblStruct id="titane-2016-bid11" type="phdthesis" rend="year" n="cite:mandad:tel-01396443">
      <identifiant type="hal" value="tel-01396443"/>
      <monogr>
        <title level="m">Robust Shape Approximation and Mapping between Surfaces</title>
        <author>
          <persName key="titane-2014-idp73016">
            <foreName>Manish</foreName>
            <surname>Mandad</surname>
            <initial>M.</initial>
          </persName>
        </author>
        <imprint>
          <publisher>
            <orgName type="school">Université de Nice-Sophia Antipolis</orgName>
          </publisher>
          <dateStruct>
            <month>November</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/tel-01396443" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>tel-01396443</ref>
        </imprint>
      </monogr>
      <note type="typdoc">Theses</note>
    </biblStruct>
    
    <biblStruct id="titane-2016-bid8" type="article" rend="year" n="cite:berger:hal-01348404">
      <identifiant type="doi" value="10.1111/cgf.12802"/>
      <identifiant type="hal" value="hal-01348404"/>
      <analytic>
        <title level="a">A Survey of Surface Reconstruction from Point Clouds</title>
        <author>
          <persName>
            <foreName>Matthew</foreName>
            <surname>Berger</surname>
            <initial>M.</initial>
          </persName>
          <persName>
            <foreName>Andrea</foreName>
            <surname>Tagliasacchi</surname>
            <initial>A.</initial>
          </persName>
          <persName>
            <foreName>Lee</foreName>
            <surname>Seversky</surname>
            <initial>L.</initial>
          </persName>
          <persName key="titane-2014-idm30672">
            <foreName>Pierre</foreName>
            <surname>Alliez</surname>
            <initial>P.</initial>
          </persName>
          <persName key="manao-2014-idp104864">
            <foreName>Gael</foreName>
            <surname>Guennebaud</surname>
            <initial>G.</initial>
          </persName>
          <persName>
            <foreName>Joshua</foreName>
            <surname>Levine</surname>
            <initial>J.</initial>
          </persName>
          <persName>
            <foreName>Andrei</foreName>
            <surname>Sharf</surname>
            <initial>A.</initial>
          </persName>
          <persName>
            <foreName>Claudio</foreName>
            <surname>Silva</surname>
            <initial>C.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00391">
        <idno type="issn">0167-7055</idno>
        <title level="j">Computer Graphics Forum</title>
        <imprint>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">27</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01348404" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01348404</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="titane-2016-bid10" type="article" rend="year" n="cite:budninskiy:hal-01376243">
      <identifiant type="hal" value="hal-01376243"/>
      <analytic>
        <title level="a">Optimal Voronoi Tessellations with Hessian-based Anisotropy</title>
        <author>
          <persName key="titane-2015-idp84976">
            <foreName>Max</foreName>
            <surname>Budninskiy</surname>
            <initial>M.</initial>
          </persName>
          <persName>
            <foreName>Beibei</foreName>
            <surname>Liu</surname>
            <initial>B.</initial>
          </persName>
          <persName>
            <foreName>Fernando</foreName>
            <surname>De Goes</surname>
            <initial>F.</initial>
          </persName>
          <persName>
            <foreName>Yiying</foreName>
            <surname>Tong</surname>
            <initial>Y.</initial>
          </persName>
          <persName key="titane-2014-idm30672">
            <foreName>Pierre</foreName>
            <surname>Alliez</surname>
            <initial>P.</initial>
          </persName>
          <persName key="titane-2014-idp80456">
            <foreName>Mathieu</foreName>
            <surname>Desbrun</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00024">
        <idno type="issn">0730-0301</idno>
        <title level="j">ACM Transactions on Graphics</title>
        <imprint>
          <dateStruct>
            <month>December</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">12</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01376243" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01376243</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="titane-2016-bid2" type="article" rend="year" n="cite:favreau:hal-01309271">
      <identifiant type="doi" value="10.1145/2897824.2925946"/>
      <identifiant type="hal" value="hal-01309271"/>
      <analytic>
        <title level="a">Fidelity vs. Simplicity: a Global Approach to Line Drawing Vectorization</title>
        <author>
          <persName key="titane-2014-idp70536">
            <foreName>Jean-Dominique</foreName>
            <surname>Favreau</surname>
            <initial>J.-D.</initial>
          </persName>
          <persName key="titane-2014-idm27920">
            <foreName>Florent</foreName>
            <surname>Lafarge</surname>
            <initial>F.</initial>
          </persName>
          <persName key="reves-2014-idm27888">
            <foreName>Adrien</foreName>
            <surname>Bousseau</surname>
            <initial>A.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00024">
        <idno type="issn">0730-0301</idno>
        <title level="j">ACM Transactions on Graphics</title>
        <imprint>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01309271" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01309271</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="titane-2016-bid5" type="article" rend="year" n="cite:maggiori:hal-01369906">
      <identifiant type="hal" value="hal-01369906"/>
      <analytic>
        <title level="a">Convolutional Neural Networks for Large-Scale Remote Sensing Image Classification</title>
        <author>
          <persName key="ayin-2014-idp84096">
            <foreName>Emmanuel</foreName>
            <surname>Maggiori</surname>
            <initial>E.</initial>
          </persName>
          <persName key="ayin-2014-idp63848">
            <foreName>Yuliya</foreName>
            <surname>Tarabalka</surname>
            <initial>Y.</initial>
          </persName>
          <persName key="stars-2014-idp61536">
            <foreName>Guillaume</foreName>
            <surname>Charpiat</surname>
            <initial>G.</initial>
          </persName>
          <persName key="titane-2014-idm30672">
            <foreName>Pierre</foreName>
            <surname>Alliez</surname>
            <initial>P.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00727">
        <idno type="issn">0196-2892</idno>
        <title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
        <imprint>
          <dateStruct>
            <month>September</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01369906" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01369906</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="titane-2016-bid9" type="article" rend="year" n="cite:shen:hal-01268109">
      <identifiant type="doi" value="10.1016/j.cagd.2016.07.002"/>
      <identifiant type="hal" value="hal-01268109"/>
      <analytic>
        <title level="a">A Line/Trimmed NURBS Surface Intersection Algorithm Using Matrix Representations</title>
        <author>
          <persName key="titane-2014-idp85608">
            <foreName>Jingjing</foreName>
            <surname>Shen</surname>
            <initial>J.</initial>
          </persName>
          <persName key="galaad2-2014-idm29072">
            <foreName>Laurent</foreName>
            <surname>Busé</surname>
            <initial>L.</initial>
          </persName>
          <persName key="titane-2014-idm30672">
            <foreName>Pierre</foreName>
            <surname>Alliez</surname>
            <initial>P.</initial>
          </persName>
          <persName>
            <foreName>Neil</foreName>
            <surname>Dodgson</surname>
            <initial>N.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00386">
        <idno type="issn">0167-8396</idno>
        <title level="j">Computer Aided Geometric Design</title>
        <imprint>
          <biblScope type="volume">48</biblScope>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">1-16</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01268109" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01268109</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="titane-2016-bid0" type="article" rend="best" n="cite:shi:hal-01344293">
      <identifiant type="hal" value="hal-01344293"/>
      <analytic>
        <title level="a">Symmetry and Orbit Detection via Lie-Algebra Voting</title>
        <author>
          <persName>
            <foreName>Zeyun</foreName>
            <surname>Shi</surname>
            <initial>Z.</initial>
          </persName>
          <persName key="titane-2014-idm30672">
            <foreName>Pierre</foreName>
            <surname>Alliez</surname>
            <initial>P.</initial>
          </persName>
          <persName key="titane-2014-idp80456">
            <foreName>Mathieu</foreName>
            <surname>Desbrun</surname>
            <initial>M.</initial>
          </persName>
          <persName>
            <foreName>Hujun</foreName>
            <surname>Bao</surname>
            <initial>H.</initial>
          </persName>
          <persName>
            <foreName>Jin</foreName>
            <surname>Huang</surname>
            <initial>J.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00391">
        <idno type="issn">0167-7055</idno>
        <title level="j">Computer Graphics Forum</title>
        <imprint>
          <dateStruct>
            <month>June</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">12</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01344293" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01344293</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="titane-2016-bid7" type="inproceedings" rend="year" n="cite:duan:hal-01352466">
      <identifiant type="hal" value="hal-01352466"/>
      <analytic>
        <title level="a">Towards large-scale city reconstruction from satellites</title>
        <author>
          <persName key="titane-2014-idp69312">
            <foreName>Liuyun</foreName>
            <surname>Duan</surname>
            <initial>L.</initial>
          </persName>
          <persName key="titane-2014-idm27920">
            <foreName>Florent</foreName>
            <surname>Lafarge</surname>
            <initial>F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">European Conference on Computer Vision (ECCV)</title>
        <loc>Amsterdam, Netherlands</loc>
        <imprint>
          <dateStruct>
            <month>October</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01352466" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01352466</ref>
        </imprint>
        <meeting id="cid66293">
          <title>European Conference on Computer Vision</title>
          <num>11</num>
          <abbr type="sigle">ECCV</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="titane-2016-bid6" type="inproceedings" rend="year" n="cite:maggiori:hal-01350706">
      <identifiant type="hal" value="hal-01350706"/>
      <analytic>
        <title level="a">Fully Convolutional Neural Networks For Remote Sensing Image Classification</title>
        <author>
          <persName key="ayin-2014-idp84096">
            <foreName>Emmanuel</foreName>
            <surname>Maggiori</surname>
            <initial>E.</initial>
          </persName>
          <persName key="ayin-2014-idp63848">
            <foreName>Yuliya</foreName>
            <surname>Tarabalka</surname>
            <initial>Y.</initial>
          </persName>
          <persName key="stars-2014-idp61536">
            <foreName>Guillaume</foreName>
            <surname>Charpiat</surname>
            <initial>G.</initial>
          </persName>
          <persName key="titane-2014-idm30672">
            <foreName>Pierre</foreName>
            <surname>Alliez</surname>
            <initial>P.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">IEEE International Geoscience and Remote Sensing Symposium</title>
        <loc>Beijing, China</loc>
        <title level="s">Proc. IEEE International Geoscience and Remote Sensing Symposium (IGARSS)</title>
        <imprint>
          <publisher>
            <orgName>IEEE</orgName>
          </publisher>
          <publisher>
            <orgName type="organisation">IEEE GRSS</orgName>
          </publisher>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">5071-5074</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01350706" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01350706</ref>
        </imprint>
        <meeting id="cid87408">
          <title>IEEE International Geoscience and Remote Sensing Symposium</title>
          <num>2010</num>
          <abbr type="sigle">IGARSS</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="titane-2016-bid1" type="inproceedings" rend="year" n="cite:oesau:hal-01318637">
      <identifiant type="hal" value="hal-01318637"/>
      <analytic>
        <title level="a">Object classification via planar abstraction</title>
        <author>
          <persName key="titane-2014-idp74264">
            <foreName>Sven</foreName>
            <surname>Oesau</surname>
            <initial>S.</initial>
          </persName>
          <persName key="titane-2014-idm27920">
            <foreName>Florent</foreName>
            <surname>Lafarge</surname>
            <initial>F.</initial>
          </persName>
          <persName key="titane-2014-idm30672">
            <foreName>Pierre</foreName>
            <surname>Alliez</surname>
            <initial>P.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">ISPRS congress</title>
        <loc>Prague, Czech Republic</loc>
        <imprint>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01318637" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01318637</ref>
        </imprint>
        <meeting id="cid53981">
          <title>Congress of the International Society for Photogrammetry and Remote Sensing</title>
          <num>2016</num>
          <abbr type="sigle">ISPRS</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="titane-2016-bid12" type="unpublished" rend="year" n="cite:jeong:hal-01414864">
      <identifiant type="hal" value="hal-01414864"/>
      <monogr>
        <title level="m">Progressive Tree-like Curvilinear Structure Reconstruction with Structured Ranking Learning and Graph Algorithm</title>
        <author>
          <persName key="ayin-2014-idp67600">
            <foreName>Seong-Gyun</foreName>
            <surname>Jeong</surname>
            <initial>S.-G.</initial>
          </persName>
          <persName key="ayin-2014-idp63848">
            <foreName>Yuliya</foreName>
            <surname>Tarabalka</surname>
            <initial>Y.</initial>
          </persName>
          <persName key="coati-2014-idp68264">
            <foreName>Nicolas</foreName>
            <surname>Nisse</surname>
            <initial>N.</initial>
          </persName>
          <persName key="ayin-2014-idp59640">
            <foreName>Josiane</foreName>
            <surname>Zerubia</surname>
            <initial>J.</initial>
          </persName>
        </author>
        <imprint>
          <dateStruct>
            <month>December</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01414864" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01414864</ref>
        </imprint>
      </monogr>
      <note type="bnote">working paper or preprint</note>
    </biblStruct>
    
    <biblStruct id="titane-2016-bid4" type="unpublished" rend="year" n="cite:maggiori:hal-01388551">
      <identifiant type="hal" value="hal-01388551"/>
      <monogr>
        <title level="m">Learning Iterative Processes with Recurrent Neural Networks to Correct Satellite Image Classification Maps</title>
        <author>
          <persName key="ayin-2014-idp84096">
            <foreName>Emmanuel</foreName>
            <surname>Maggiori</surname>
            <initial>E.</initial>
          </persName>
          <persName key="stars-2014-idp61536">
            <foreName>Guillaume</foreName>
            <surname>Charpiat</surname>
            <initial>G.</initial>
          </persName>
          <persName key="ayin-2014-idp63848">
            <foreName>Yuliya</foreName>
            <surname>Tarabalka</surname>
            <initial>Y.</initial>
          </persName>
          <persName key="titane-2014-idm30672">
            <foreName>Pierre</foreName>
            <surname>Alliez</surname>
            <initial>P.</initial>
          </persName>
        </author>
        <imprint>
          <dateStruct>
            <month>October</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01388551" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01388551</ref>
        </imprint>
      </monogr>
      <note type="bnote">working paper or preprint</note>
    </biblStruct>
    
    <biblStruct id="titane-2016-bid3" type="unpublished" rend="year" n="cite:maggiori:hal-01393279">
      <identifiant type="hal" value="hal-01393279"/>
      <monogr>
        <title level="m">High-Resolution Semantic Labeling with Convolutional Neural Networks</title>
        <author>
          <persName key="ayin-2014-idp84096">
            <foreName>Emmanuel</foreName>
            <surname>Maggiori</surname>
            <initial>E.</initial>
          </persName>
          <persName key="ayin-2014-idp63848">
            <foreName>Yuliya</foreName>
            <surname>Tarabalka</surname>
            <initial>Y.</initial>
          </persName>
          <persName key="stars-2014-idp61536">
            <foreName>Guillaume</foreName>
            <surname>Charpiat</surname>
            <initial>G.</initial>
          </persName>
          <persName key="titane-2014-idm30672">
            <foreName>Pierre</foreName>
            <surname>Alliez</surname>
            <initial>P.</initial>
          </persName>
        </author>
        <imprint>
          <dateStruct>
            <month>November</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01393279" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01393279</ref>
        </imprint>
      </monogr>
      <note type="bnote">working paper or preprint</note>
    </biblStruct>
  </biblio>
</raweb>
