<?xml version="1.0" encoding="utf-8"?>
<raweb xmlns:xlink="http://www.w3.org/1999/xlink" xml:lang="en" year="2016">
  <identification id="mimetic" isproject="true">
    <shortname>MIMETIC</shortname>
    <projectName>Analysis-Synthesis Approach for Virtual Human Simulation</projectName>
    <theme-de-recherche>Interaction and visualization</theme-de-recherche>
    <domaine-de-recherche>Perception, Cognition and Interaction</domaine-de-recherche>
    <structure_exterieure type="Labs">
      <libelle>Institut de recherche en informatique et systèmes aléatoires (IRISA)</libelle>
    </structure_exterieure>
    <structure_exterieure type="Organism">
      <libelle>Université Haute Bretagne (Rennes 2)</libelle>
    </structure_exterieure>
    <structure_exterieure type="Organism">
      <libelle>Université Rennes 1</libelle>
    </structure_exterieure>
    <structure_exterieure type="Organism">
      <libelle>École normale supérieure de Rennes</libelle>
    </structure_exterieure>
    <header_dates_team>Creation of the Team: 2011 January 01, updated into Project-Team: 2014 January 01</header_dates_team>
    <LeTypeProjet>Project-Team</LeTypeProjet>
    <keywordsSdN>
      <term>5.1.5. - Body-based interfaces</term>
      <term>5.4.2. - Activity recognition</term>
      <term>5.5.4. - Animation</term>
      <term>5.6. - Virtual reality, augmented reality</term>
    </keywordsSdN>
    <keywordsSecteurs>
      <term>1.3.2. - Cognitive science</term>
      <term>2.5. - Handicap and personal assistances</term>
      <term>2.8. - Sports, performance, motor skills</term>
      <term>5.1. - Factory of the future</term>
      <term>5.8. - Learning and training</term>
      <term>7.1.1. - Pedestrian traffic and crowds</term>
      <term>9.2.2. - Cinema, Television</term>
      <term>9.2.3. - Video games</term>
      <term>9.3. - Sports</term>
    </keywordsSecteurs>
    <UR name="Rennes"/>
  </identification>
  <team id="uid1">
    <person key="mimetic-2014-idm27032">
      <firstname>Franck</firstname>
      <lastname>Multon</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Team leader, Univ. Rennes II, Professor</moreinfo>
      <hdr>oui</hdr>
    </person>
    <person key="mimetic-2015-idm26392">
      <firstname>Ludovic</firstname>
      <lastname>Hoyet</lastname>
      <categoryPro>Chercheur</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Inria, Researcher</moreinfo>
    </person>
    <person key="mimetic-2014-idm25552">
      <firstname>Julien</firstname>
      <lastname>Pettré</lastname>
      <categoryPro>Chercheur</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Inria, Researcher, in MimeTIC until Feb 2016</moreinfo>
      <hdr>oui</hdr>
    </person>
    <person key="mimetic-2014-idp65960">
      <firstname>Benoit</firstname>
      <lastname>Bideau</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes II, Professor</moreinfo>
      <hdr>oui</hdr>
    </person>
    <person key="mimetic-2014-idp67352">
      <firstname>Nicolas</firstname>
      <lastname>Bideau</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes II, Associate Professor</moreinfo>
    </person>
    <person key="mimetic-2014-idp68552">
      <firstname>Marc</firstname>
      <lastname>Christie</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes I, Associate Professor</moreinfo>
    </person>
    <person key="mimetic-2014-idp69792">
      <firstname>Armel</firstname>
      <lastname>Crétual</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes II, Associate Professor</moreinfo>
      <hdr>oui</hdr>
    </person>
    <person key="mimetic-2014-idp71256">
      <firstname>Georges</firstname>
      <lastname>Dumont</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>ENS Rennes, Professor</moreinfo>
      <hdr>oui</hdr>
    </person>
    <person key="mimetic-2014-idp73992">
      <firstname>Richard</firstname>
      <lastname>Kulpa</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes II, Associate Professor</moreinfo>
      <hdr>oui</hdr>
    </person>
    <person key="mimetic-2014-idp75448">
      <firstname>Fabrice</firstname>
      <lastname>Lamarche</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes I, Associate Professor</moreinfo>
    </person>
    <person key="genscale-2014-idp67832">
      <firstname>Antonio</firstname>
      <lastname>Mucherino</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes I, Associate Professor, in MimeTIC since Sept 2016</moreinfo>
    </person>
    <person key="mimetic-2014-idp76704">
      <firstname>Guillaume</firstname>
      <lastname>Nicolas</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes II, Associate Professor</moreinfo>
    </person>
    <person key="mimetic-2014-idp77968">
      <firstname>Anne-Hélène</firstname>
      <lastname>Olivier</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes II, Associate Professor</moreinfo>
    </person>
    <person key="mimetic-2014-idp79256">
      <firstname>Charles</firstname>
      <lastname>Pontonnier</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>ENS Rennes, Associate Professor</moreinfo>
    </person>
    <person key="mimetic-2016-idp182624">
      <firstname>Camille</firstname>
      <lastname>Pouliquen</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes II, Associate Professor, since Sept. 2016</moreinfo>
    </person>
    <person key="mimetic-2014-idp110528">
      <firstname>Hui-Yin</firstname>
      <lastname>Wu</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes I, Associate Professor, since Sept. 2016</moreinfo>
    </person>
    <person key="hybrid-2016-idp152560">
      <firstname>Ronan</firstname>
      <lastname>Gaugne</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes I, SED Research Engineer, involved in MimeTIC at 15%</moreinfo>
    </person>
    <person key="imagine-2014-idp148824">
      <firstname>Christophe</firstname>
      <lastname>Lino</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Inria</moreinfo>
    </person>
    <person key="mimetic-2014-idp85504">
      <firstname>Anthony</firstname>
      <lastname>Sorel</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes II</moreinfo>
    </person>
    <person key="mimetic-2014-idp109304">
      <firstname>David</firstname>
      <lastname>Wolinski</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Inria, until Nov 2016, granted by ANR PERCOLATION project</moreinfo>
    </person>
    <person key="mimetic-2016-idp197536">
      <firstname>Yacine</firstname>
      <lastname>Boulahia</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>INSA Rennes</moreinfo>
    </person>
    <person key="phoenix-2014-idp112224">
      <firstname>Julien</firstname>
      <lastname>Bruneau</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes I</moreinfo>
    </person>
    <person key="mimetic-2014-idp98224">
      <firstname>Ana Lucia</firstname>
      <lastname>Cruz Ruiz</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Inria, until Nov 2016, granted by ANR ENTRACTE project</moreinfo>
    </person>
    <person key="mimetic-2016-idp204864">
      <firstname>Charles</firstname>
      <lastname>Faure</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes II</moreinfo>
    </person>
    <person key="mimetic-2015-idp92992">
      <firstname>Sean</firstname>
      <lastname>Lynch</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes II</moreinfo>
    </person>
    <person key="mimetic-2016-idp209728">
      <firstname>Marion</firstname>
      <lastname>Morel</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes II, UPMC</moreinfo>
    </person>
    <person key="mimetic-2014-idp103120">
      <firstname>Antoine</firstname>
      <lastname>Muller</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>ENS Rennes</moreinfo>
    </person>
    <person key="mimetic-2014-idp104376">
      <firstname>Pierre</firstname>
      <lastname>Plantard</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Faurecia, until Oct 2016</moreinfo>
    </person>
    <person key="mimetic-2016-idp182624">
      <firstname>Camille</firstname>
      <lastname>Pouliquen</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes II, Until Aug. 2016</moreinfo>
    </person>
    <person key="mimetic-2016-idp219488">
      <firstname>Pierre</firstname>
      <lastname>Touzard</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes II</moreinfo>
    </person>
    <person key="mimetic-2014-idp110528">
      <firstname>Hui-Yin</firstname>
      <lastname>Wu</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Univ. Rennes I, until Aug 2016</moreinfo>
    </person>
    <person key="mimetic-2014-idp86848">
      <firstname>Panayiotis</firstname>
      <lastname>Charalambous</lastname>
      <categoryPro>PostDoc</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Inria, until May 2016</moreinfo>
    </person>
    <person key="mimetic-2015-idp102880">
      <firstname>Diane</firstname>
      <lastname>Haering</lastname>
      <categoryPro>PostDoc</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Inria</moreinfo>
    </person>
    <person key="mimetic-2016-idp229264">
      <firstname>Zhiguang</firstname>
      <lastname>Liu</lastname>
      <categoryPro>PostDoc</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Inria, from Nov 2016</moreinfo>
    </person>
    <person key="mimetic-2016-idp231696">
      <firstname>Laurentius</firstname>
      <lastname>Meerhoff</lastname>
      <categoryPro>PostDoc</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Inria, from May 2016</moreinfo>
    </person>
    <person key="mimetic-2016-idp234160">
      <firstname>Yijun</firstname>
      <lastname>Shen</lastname>
      <categoryPro>Visiteur</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Northumbria University, from Sep 2016</moreinfo>
    </person>
    <person key="hybrid-2014-idp83880">
      <firstname>Nathalie</firstname>
      <lastname>Denis</lastname>
      <categoryPro>Assistant</categoryPro>
      <research-centre>Rennes</research-centre>
      <moreinfo>Inria</moreinfo>
    </person>
  </team>
  <presentation id="uid2">
    <bodyTitle>Overall Objectives</bodyTitle>
    <subsection id="uid3" level="1">
      <bodyTitle>Presentation</bodyTitle>
      <p>MimeTIC is a multidisciplinary team whose aim is to better understand and model human activity in order to simulate realistic autonomous virtual humans: realistic behaviors, realistic motions and realistic interactions with other characters and users. It leads to modeling the complexity of a human body, as well as of his environment where he can pick-up information and he can act on it. A specific focus is dedicated to human physical activity and sports as it raises the highest constraints and the highest complexity when addressing these problems. Thus, MimeTIC is composed of experts in computer science whose research interests are computer animation, behavioral simulation, motion simulation, crowds and interaction between real and virtual humans. MimeTIC is also composed of experts in sports science, motion analysis, motion sensing, biomechanics and motion control. Hence, the scientific foundations of MimeTIC are motion sciences (biomechanics, motion control, perception-action coupling, motion analysis), computational geometry (modeling of the 3D environment, motion planning, path planning) and design of protocols in immersive environments (use of virtual reality facilities to analyze human activity).</p>
      <p>Thanks to these skills, we wish to reach the following objectives: to make virtual humans behave, move and interact in a natural manner in order to increase immersion and to improve knowledge on human motion control. In real situations (see Figure <ref xlink:href="#uid4" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>), people have to deal with their physiological, biomechanical and neurophysiological capabilities in order to reach a complex goal. Hence MimeTIC addresses the problem of modeling the anatomical, biomechanical and physiological properties of human beings. Moreover these characters have to deal with their environment. Firstly they have to perceive this environment and pick-up relevant information. MimeTIC thus addresses the problem of modeling the environment including its geometry and associated semantic information. Secondly, they have to act on this environment to reach their goals. It leads to cognitive processes, motion planning, joint coordination and force production in order to act on this environment.</p>
      <object id="uid4">
        <table>
          <tr>
            <td>
              <ressource xlink:href="IMG/objectives.jpg" type="float" width="277.5474pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
          </tr>
        </table>
        <caption>Main objective of MimeTIC: to better understand human activity in order to improve virtual human simulations. It involves modeling the complexity of human bodies, as well as of environments where to pick-up information and act upon.</caption>
      </object>
      <p>In order to reach the above objectives, MimeTIC has to address three main challenges:</p>
      <simplelist>
        <li id="uid5">
          <p noindent="true">dealing with the intrinsic complexity of human beings, especially when addressing the problem of interactions between people for which it is impossible to predict and model all the possible states of the system,</p>
        </li>
        <li id="uid6">
          <p noindent="true">making the different components of human activity control (such as the biomechanical and physical, the reactive, cognitive, rational and social layers) interact while each of them is modeled with completely different states and time sampling,</p>
        </li>
        <li id="uid7">
          <p noindent="true">and being able to measure human activity while balancing between ecological and controllable protocols, and to be able to extract relevant information in wide databases of information.</p>
        </li>
      </simplelist>
      <p>Contrary to many classical approaches in computer simulation, which mostly propose simulation without trying to understand how real people do, the team promotes a coupling between human activity analysis and synthesis, as shown in Figure <ref xlink:href="#uid8" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
      <object id="uid8">
        <table>
          <tr>
            <td>
              <ressource xlink:href="IMG/researchpath.jpg" type="float" width="298.8987pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
          </tr>
        </table>
        <caption>Research path of MimeTIC: coupling analysis and synthesis of human activity enables us to create more realistic autonomous characters and to evaluate assumptions about human motion control.</caption>
      </object>
      <p>In this research path, <b>improving knowledge on human activity</b> enables us to highlight fundamental assumptions about natural control of human activities. These contributions can be promoted in e.g. biomechanics, motion sciences, neurosciences. According to these assumptions we propose new algorithms for controlling <b>autonomous virtual humans</b>. The virtual humans can perceive their environment and decide of the most natural action to reach a given goal. This work is promoted in computer animation, virtual reality and has some applications in robotics through collaborations. Once autonomous virtual humans have the ability to act as real humans would in the same situation, it is possible to make them <b>interact with others</b>, i.e., autonomous characters (for crowds or group simulations) as well as real users. The key idea here is to analyze to what extent the assumptions proposed at the first stage lead to natural interactions with real users. This process enables the validation of both our assumptions and our models.</p>
      <p>Among all the problems and challenges described above, MimeTIC focuses on the following domains of research:</p>
      <simplelist>
        <li id="uid9">
          <p noindent="true">motion sensing which is a key issue to extract information from raw motion capture systems and thus to propose assumptions on how people control their activity,</p>
        </li>
        <li id="uid10">
          <p noindent="true">human activity &amp; virtual reality, which is explored through sports application in MimeTIC. This domain enables the design of new methods for analyzing the perception-action coupling in human activity, and to validate whether the autonomous characters lead to natural interactions with users,</p>
        </li>
        <li id="uid11">
          <p noindent="true">interactions in small and large groups of individuals, to understand and model interactions with lot of individual variability such as in crowds,</p>
        </li>
        <li id="uid12">
          <p noindent="true">virtual storytelling which enables us to design and simulate complex scenarios involving several humans who have to satisfy numerous complex constraints (such as adapting to the real-time environment in order to play an imposed scenario), and to design the coupling with the camera scenario to provide the user with a real cinematographic experience,</p>
        </li>
        <li id="uid13">
          <p noindent="true">biomechanics which is essential to offer autonomous virtual humans who can react to physical constraints in order to reach high-level goals, such as maintaining balance in dynamic situations or selecting a natural motor behavior among the whole theoretical solution space for a given task,</p>
        </li>
        <li id="uid14">
          <p noindent="true">and autonomous characters which is a transversal domain that can reuse the results of all the other domains to make these heterogeneous assumptions and models provide the character with natural behaviors and autonomy.</p>
        </li>
      </simplelist>
    </subsection>
  </presentation>
  <fondements id="uid15">
    <bodyTitle>Research Program</bodyTitle>
    <subsection id="uid16" level="1">
      <bodyTitle>Biomechanics and Motion Control</bodyTitle>
      <p>Human motion control is a very complex phenomenon that involves several layered systems, as shown in Figure <ref xlink:href="#uid17" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. Each layer of this controller is responsible for dealing with perceptual stimuli in order to decide the actions that should be applied to the human body and his environment. Due to the intrinsic complexity of the information (internal representation of the body and mental state, external representation of the environment) used to perform this task, it is almost impossible to model all the possible states of the system. Even for simple problems, there generally exists an infinity of solutions. For example, from the biomechanical point of view, there are much more actuators (i.e. muscles) than degrees of freedom leading to an infinity of muscle activation patterns for a unique joint rotation. From the reactive point of view there exists an infinity of paths to avoid a given obstacle in navigation tasks. At each layer, the key problem is to understand how people select one solution among these infinite state spaces. Several scientific domains have addressed this problem with specific points of view, such as physiology, biomechanics, neurosciences and psychology.</p>
      <object id="uid17">
        <table>
          <tr>
            <td>
              <ressource xlink:href="IMG/motionControl2.png" type="float" width="298.8987pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
          </tr>
        </table>
        <caption>Layers of the motion control natural system in humans.</caption>
      </object>
      <p>In biomechanics and physiology, researchers have proposed hypotheses based on accurate joint modeling (to identify the real anatomical rotational axes), energy minimization, force and torques minimization, comfort maximization (i.e. avoiding joint limits), and physiological limitations in muscle force production. All these constraints have been used in optimal controllers to simulate natural motions. The main problem is thus to define how these constraints are composed altogether such as searching the weights used to linearly combine these criteria in order to generate a natural motion. Musculoskeletal models are stereotyped examples for which there exists an infinity of muscle activation patterns, especially when dealing with antagonist muscles. An unresolved problem is to define how to use the above criteria to retrieve the actual activation patterns, while optimization approaches still leads to unrealistic ones. It is still an open problem that will require multidisciplinary skills including computer simulation, constraint solving, biomechanics, optimal control, physiology and neurosciences.</p>
      <p>In neurosciences, researchers have proposed other theories, such as coordination patterns between joints driven by simplifications of the variables used to control the motion. The key idea is to assume that instead of controlling all the degrees of freedom, people control higher level variables which correspond to combinations of joint angles. In walking, data reduction techniques such as Principal Component Analysis have shown that lower-limb joint angles are generally projected on a unique plane whose angle in the state space is associated with energy expenditure. Although knowledge exists for specific motions, such as locomotion or grasping, this type of approach is still difficult to generalize. The key problem is that many variables are coupled and it is very difficult to objectively study the behavior of a unique variable in various motor tasks. Computer simulation is a promising method to evaluate such type of assumptions as it enables to accurately control all the variables and to check if it leads to natural movements.</p>
      <p>Neurosciences also address the problem of coupling perception and action by providing control laws based on visual cues (or any other senses), such as determining how the optical flow is used to control direction in navigation tasks, while dealing with collision avoidance or interception. Coupling of the control variables is enhanced in this case as the state of the body is enriched by the large amount of external information that the subject can use. Virtual environments inhabited with autonomous characters whose behavior is driven by motion control assumptions is a promising approach to solve this problem. For example, an interesting problem in this field is navigation in an environment inhabited with other people. Typically, avoiding static obstacles together with other people displacing into the environment is a combinatory problem that strongly relies on the coupling between perception and action.</p>
      <p>One of the main objectives of MimeTIC is to enhance knowledge on human motion control by developing innovative experiments based on computer simulation and immersive environments. To this end, designing experimental protocols is a key point and some of the researchers in MimeTIC have developed this skill in biomechanics and perception-action coupling. Associating these researchers to experts in virtual human simulation, computational geometry and constraints solving enable us to contribute to enhance fundamental knowledge in human motion control.
</p>
    </subsection>
    <subsection id="uid18" level="1">
      <bodyTitle>Experiments in Virtual Reality</bodyTitle>
      <p>Understanding interactions between humans is very challenging because it addresses many complex phenomena including perception, decision-making, cognition and social behaviors. Moreover, all these phenomena are difficult to isolate in real situations, and it is therefore very complex to understand their individual influence on these human interactions. It is then necessary to find an alternative solution that can standardize the experiments and that allows the modification of only one parameter at a time. Video was first used since the displayed experiment is perfectly repeatable and cut-offs (stop the video at a specific time before its end) allow having temporal information. Nevertheless, the absence of adapted viewpoint and stereoscopic vision does not provide depth information that are very meaningful. Moreover, during video recording session, the real human is acting in front of a camera and not of an opponent. The interaction is then not a real interaction between humans.</p>
      <p>Virtual Reality (VR) systems allow full standardization of the experimental situations and the complete control of the virtual environment. It is then possible to modify only one parameter at a time and to observe its influence on the perception of the immersed subject. VR can then be used to understand what information is picked up to make a decision. Moreover, cut-offs can also be used to obtain temporal information about when information is picked up. When the subject can moreover react as in a real situation, his movement (captured in real time) provides information about his reactions to the modified parameter. Not only is the perception studied, but the complete perception-action loop. Perception and action are indeed coupled and influence each other as suggested by Gibson in 1979.</p>
      <p>Finally, VR allows the validation of the virtual human models. Some models are indeed based on the interaction between the virtual character and the other humans, such as a walking model. In that case, there are two ways to validate it. First, they can be compared to real data (e.g. real trajectories of pedestrians). But such data are not always available and are difficult to get. The alternative solution is then to use VR. The validation of the realism of the model is then done by immersing a real subject in a virtual environment in which a virtual character is controlled by the model. Its evaluation is then deduced from how the immersed subject reacts when interacting with the model and how realistic he feels the virtual character is.</p>
    </subsection>
    <subsection id="uid19" level="1">
      <bodyTitle>Computational Geometry</bodyTitle>
      <p>Computational geometry is a branch of computer science devoted to the study of algorithms which can be stated in terms of geometry. It aims at studying algorithms for combinatorial, topological and metric problems concerning sets of points in Euclidian spaces. Combinatorial computational geometry focuses on three main problem classes: static problems, geometric query problems and dynamic problems.</p>
      <p>In static problems, some inputs are given and the corresponding outputs need to be constructed or found. Such problems include linear programming, Delaunay triangulations, and Euclidian shortest paths for instance. In geometric query problems, commonly known as geometric search problems, the input consists of two parts: the search space part and the query part, which varies over the problem instances. The search space typically needs to be preprocessed, in a way that multiple queries can be answered efficiently. Some typical problems are range searching, point location in a portioned space, or nearest neighbor queries. In dynamic problems, the goal is to find an efficient algorithm for finding a solution repeatedly after each incremental modification of the input data (addition, deletion or motion of input geometric elements). Algorithms for problems of this type typically involve dynamic data structures. Both of previous problem types can be converted into a dynamic problem, for instance, maintaining a Delaunay triangulation between moving points.</p>
      <p>In this context, distance geometry relies solely on distances, instead of points and lines, as in classical geometry. Various applications lead to the definition of problems that can be formulated as a distance geometry, including sensor network localization, robot coordination, the identification of molecular conformations, or as in the context of MimeTIC relations between objects in virtual scenes (e.g., distances between body segments, agents, or cameras). In recent years, scientific research has been oriented to the assumptions allowing for discretizing the search space of a given distance geometry problem. The discretization (which is exact in some situations) allows to conceive ad-hoc and efficient algorithms, and for enumerating the entire solution set of a given instance.</p>
      <p>The Mimetic team works on problems such as crowd simulation, spatial analysis, path and motion planning in static and dynamic environments, camera planning with visibility constraints for instance. The core of those problems, by nature, relies on problems and techniques belonging to computational geometry. Proposed models pay attention to algorithms complexity to be compatible with performance constraints imposed by interactive applications.</p>
    </subsection>
  </fondements>
  <domaine id="uid20">
    <bodyTitle>Application Domains</bodyTitle>
    <subsection id="uid21" level="1">
      <bodyTitle>Autonomous Characters</bodyTitle>
      <p>Autonomous characters are becoming more and more popular as they are used in an increasing number of application domains. In the field of special effects, virtual characters are used to replace secondary actors and generate highly populated scenes that would be hard and costly to produce with real actors. In video games and virtual storytelling, autonomous characters play the role of actors that are driven by a scenario. Their autonomy allows them to react to unpredictable user interactions and adapt their behavior accordingly. In the field of simulation, autonomous characters are used to simulate the behavior of humans in different kind of situations. They enable to study new situations and their possible outcomes.</p>
      <p>One of the main challenges in the field of autonomous characters is to provide a unified architecture for the modeling of their behavior. This architecture includes perception, action and decisional parts. This decisional part needs to mix different kinds of models, acting at different time scale and working with different nature of data, ranging from numerical (motion control, reactive behaviors) to symbolic (goal oriented behaviors, reasoning about actions and changes).</p>
      <p>In the MimeTIC team, we focus on autonomous virtual humans. Our problem is not to reproduce the human intelligence but to propose an architecture making it possible to model credible behaviors of anthropomorphic virtual actors evolving/moving in real time in virtual worlds. The latter can represent particular situations studied by psychologists of the behavior or to correspond to an imaginary universe described by a scenario writer. The proposed architecture should mimic all the human intellectual and physical functions.
</p>
    </subsection>
    <subsection id="uid22" level="1">
      <bodyTitle>Biomechanics and Motion Analysis</bodyTitle>
      <p>Biomechanics is obviously a very large domain. This large set can be divided regarding to the scale at which the analysis is performed going from microscopic evaluation of biological tissues’ mechanical properties to macroscopic analysis and modeling of whole body motion. Our topics in the domain of biomechanics mainly lie within this last scope. In order to obtain a better understanding of human motion, MimeTIC addresses three main situations: everyday motions of a lambda subject, locomotion of pathological subjects and sports gestures.</p>
      <p>In the first situation, MimeTIC is interested in studying how subjects maintain their balance in highly dynamic conditions. Until now, balance have nearly always been considered in static or quasi-static conditions. The knowledge of much more dynamic cases still has to be improved. Our approach has demonstrated that, first of all, the question of the parameter that will allow to do this is still open.
We have also largely contributed to gaining a better understanding of collision avoidance between pedestrians. This topic includes the research of the parameters that are interactively controlled and the study of each one’s role within this interaction.</p>
      <p>The second situation focuses on locomotion of pathological subjects. When patients cannot walk efficiently, in particular those suffering from central nervous system affections, it becomes very useful for practitioners to benefit from an objective evaluation of their capacities. To facilitate such evaluations, we have developed two complementary indices, one based on kinematics and the other one on muscle activations. One major point of our research is that such indices are usually only developed for children whereas adults with these affections are much more numerous.</p>
      <p>Finally, in sports, where gesture can be considered, in some way, as abnormal, the goal is more precisely to understand the determinants of performance. This could then be used to improve training programs or devices. Two different sports have been studied: a) the tennis serve, where the goal was to understand the contribution of each segment of the body on the speed of the ball and b) the influence of the mechanical characteristics of the fin in fin swimming.</p>
      <p>After having improved the knowledge of these different gestures a second goal is then to propose modeling solutions that can be used in VR environments for other research topics within MimeTIC. This has been the case, for example, for collision avoidance.
</p>
    </subsection>
    <subsection id="uid23" level="1">
      <bodyTitle>Interactions between walkers</bodyTitle>
      <p>Modeling and simulating the interactions between walkers is a very active, complex and competitive domain, interesting various disciplines such as Mathematics, Cognitive Sciences, Physics, Computer Graphics, etc. Interactions between walkers are by definition at the very core of our society since they represent the basic synergies of our daily life. When walking in the street, we take information about our surrounding environment in order to interact with people, move without collision, alone or in a group, intercept, meet or escape to somebody. Large groups of walkers can be first seen as a complex system: numerous local interactions occur between its elements and result into macroscopic emergent phenomena. Interactions are of various nature (e.g., collision avoidance, following) and are undergoing various factors as well. Physical factors are crucial as a group gathers by definition numerous moving people with a certain level of density. But sociological, cultural and psychological factors are important as well, since people’s behavior is deeply changed from country to country, or depending on the considered situations. On the computational point of view, simulating the movements of large groups of walkers (i.e., crowds) pushes traditional simulation algorithms to their limit. As an element of a crowd is subject to interact with any other element belonging the same crowd, a naïve simulation algorithm has a quadratic complexity. Specific strategies are set to face such a difficulty: level-of-detail techniques enable scaling large crowd simulation and reach real-time solutions.</p>
      <p>MimeTIC is an international key contributor in the domain of understanding and simulating interactions between walkers, in particular for virtual crowds. Our approach is specific and based on three axes. First, our modeling approach is based on human movement science: we conduct challenging experiments focusing on the perception as well as on the motion involved in local interactions between walkers both using real and virtual set-ups. Second: we develop high-performance solutions for crowd simulation. Third, we develop solutions for realistic navigation in virtual world to enable interaction with crowds in Virtual Reality.</p>
    </subsection>
    <subsection id="uid24" level="1">
      <bodyTitle>Motion Sensing of Human Activity</bodyTitle>
      <p>Recording human activity is a key point of many applications and fundamental works. Numerous sensors and systems have been proposed to measure positions, angles or accelerations of the user’s body parts. Whatever the system is, one of the main problems is to be able to automatically recognize and analyze the user’s performance according to poor and noisy signals. Human activity and motion are subject to variability: intra-variability due to space and time variations of a given motion, but also inter-variability due to different styles and anthropometric dimensions. MimeTIC has addressed the above problems in two main directions.</p>
      <p>Firstly, we have studied how to recognize and quantify motions performed by a user when using accurate systems such as Vicon (product of Oxford Metrics) or Optitrack (product of Natural Point) motion capture systems. These systems provide large vectors of accurate information. Due to the size of the state vector (all the degrees of freedom) the challenge is to find the compact information (named features) that enables the automatic system to recognize the performance of the user. Whatever the method used, finding these relevant features that are not sensitive to intra-individual and inter-individual variability is a challenge. Some researchers have proposed to manually edit these features (such as a Boolean value stating if the arm is moving forward or backward) so that the expertise of the designer is directly linked with the success ratio. Many proposals for generic features have been proposed, such as using Laban notation which was introduced to encode dancing motions. Other approaches tend to use machine learning to automatically extract these features. However most of the proposed approaches were used to seek a database for motions which properties correspond to the features of the user’s performance (named motion retrieval approaches). This does not ensure the retrieval of the exact performance of the user but a set of motions with similar properties.</p>
      <p>Secondly, we wish to find alternatives to the above approach which is based on analyzing accurate and complete knowledge on joint angles and positions. Hence new sensors, such as depth-cameras (Kinect, product of Microsoft) provide us with very noisy joint information but also with the surface of the user. Classical approaches would try to fit a skeleton into the surface in order to compute joint angles which, again, lead to large state vectors. An alternative would be to extract relevant information directly from the raw data, such as the surface provided by depth cameras. The key problem is that the nature of these data may be very different from classical representation of human performance. In MimeTIC, we try to address this problem in specific application domains that require picking specific information, such as gait asymmetry or regularity for clinical analysis of human walking.</p>
    </subsection>
    <subsection id="uid25" level="1">
      <bodyTitle>VR and Sports</bodyTitle>
      <p>Sport is characterized by complex displacements and motions. These motions are dependent on visual information that the athlete can pick up in his environment, including the opponent’s actions. Perception is thus fundamental to the performance. Indeed, a sportive action, as unique, complex and often limited in time, requires a selective gathering of information. This perception is often seen as a prerogative for action, it then takes the role of a passive collector of information. However, as mentioned by Gibson in 1979, the perception-action relationship should not be considered sequential but rather as a coupling: we perceive to act but we must act to perceive. There would thus be laws of coupling between the informational variables available in the environment and the motor responses of a subject. In other words, athletes have the ability to directly perceive the opportunities of action directly from the environment. Whichever school of thought considered, VR offers new perspectives to address these concepts by complementary using real time motion capture of the immersed athlete.</p>
      <p>In addition to better understanding sports and interactions between athletes, VR can also be used as a training environment as it can provide complementary tools to coaches. It is indeed possible to add visual or auditory information to better train an athlete. The knowledge found in perceptual experiments can be for example used to highlight the body parts that are important to look at to correctly anticipate the opponent’s action.
</p>
    </subsection>
    <subsection id="uid26" level="1">
      <bodyTitle>Interactive Digital Storytelling</bodyTitle>
      <p>Interactive digital storytelling, including novel forms of edutainment and serious games, provides access to social and human themes through stories which can take various forms and contains opportunities for massively enhancing the possibilities of interactive entertainment, computer games and digital applications. It provides chances for redefining the experience of narrative through interactive simulations of computer-generated story worlds and opens many challenging questions at the overlap between computational narratives, autonomous behaviours, interactive control, content generation and authoring tools.</p>
      <p>Of particular interest for the MimeTIC research team, virtual storytelling triggers challenging opportunities in providing effective models for enforcing autonomous behaviours for characters in complex 3D environments. Offering both low-level capacities to characters such as perceiving the environments, interacting with the environment and reacting to changes in the topology, on which to build higher-levels such as modelling abstract representations for efficient reasoning, planning paths and activities, modelling cognitive states and behaviours requires the provision of expressive, multi-level and efficient computational models. Furthermore virtual storytelling requires the seamless control of the balance between the autonomy of characters and the unfolding of the story through the narrative discourse. Virtual storytelling also raises challenging questions on the conveyance of a narrative through interactive or automated control of the cinematography (how to stage the characters, the lights and the cameras). For example, estimating visibility of key subjects, or performing motion planning for cameras and lights are central issues for which have not received satisfactory answers in the literature.</p>
    </subsection>
    <subsection id="uid27" level="1">
      <bodyTitle>VR and Ergonomics</bodyTitle>
      <p>The design of workstations nowadays tends to include assessment steps in a Virtual Environment (VE) to evaluate ergonomic features. This approach is more cost-effective and convenient since working directly on the Digital Mock-Up (DMU) in a VE is preferable to constructing a real physical mock-up in a Real Environment (RE). This is substantiated by the fact that a Virtual Reality (VR) set-up can be easily modified, enabling quick adjustments of the workstation design. Indeed, the aim of integrating ergonomics evaluation tools in VEs is to facilitate the design process, enhance the design efficiency, and reduce the costs.</p>
      <p>The development of such platforms asks for several improvements in the field of motion analysis and VR. First, interactions have to be as natural as possible to properly mimic the motions performed in real environments. Second, the fidelity of the simulator also needs to be correctly evaluated. Finally, motion analysis tools have to be able to provide in real-time biomechanics quantities usable by ergonomists to analyse and improve the working conditions.
</p>
    </subsection>
  </domaine>
  <highlights id="uid28">
    <bodyTitle>Highlights of the Year</bodyTitle>
    <subsection id="uid29" level="1">
      <bodyTitle>Highlights of the Year</bodyTitle>
      <p>This year, we feature four of the team's research results as specific highlights, in particular due to their high publication impacts.</p>
      <p>Our work entitled “Validation of an ergonomic assessment method using Kinect data in real workplace conditions“ (<ref xlink:href="#mimetic-2016-bid0" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/> by Pierre Plantard, Hubert PH Shum, Anne-Sophie Le Pierres and Franck Multon) has been accepted in the journal Applied Ergonomics. This publication is very important for future works in ergonomics as it demonstrates the relevance of the Kinect data correction for in-site (on a real workstation in factories) in an ergonomic purpose.</p>
      <p>A State of the art paper, “Muscle-Based Control For Character Animation” has been published in Computer Graphics Forum (<ref xlink:href="#mimetic-2016-bid1" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/> by Ana Lucia Cruz Ruiz, Charles Pontonnier, Nicolas Pronost and Georges Dumont). It presents an organized review of over a decade of research in muscle-based control for character animation, its fundamental concepts and future directions for development. The core of this review contains a classification of control methods, tables summarizing their key aspects, and popular neuromuscular functions used within these controllers.</p>
      <p>Our work entitled “Perceptual Effect of Shoulder Motions on Crowd Animations” (<ref xlink:href="#mimetic-2016-bid2" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/> by Ludovic Hoyet, Anne-Hélène Olivier, Richard Kulpa and Julien Pettré ) has been accepted and presented in SIGGRAPH 2016, the premier and most selective computer graphics scientific event, and published in ACM Transaction on Graphics. It explores how local interactions between walkers are perceived by users when secondary shoulder motions are displayed, and demonstrates the benefits of such secondary animations in large-scale crowd scenarios.</p>
      <p>Two papers exploring the effects of the avatar's representation on users' sense of “virtual embodiment” (i.e., the extent to which we accept an avatar to be our representation in the virtual environment) were published in Frontiers in Robotics and AI <ref xlink:href="#mimetic-2016-bid3" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/> and in IEEE VR <ref xlink:href="#mimetic-2016-bid4" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>, resulting from a collaboration between Ludovic Hoyet (MimeTIC), and Ferran Argelaguet and Anatole Lécuyer (Hybrid). This work paves the way to further collaborations on understanding how we accept virtual characters as our own representation in virtual environments.</p>
      <subsection id="uid30" level="2">
        <bodyTitle>Awards</bodyTitle>
        <p>This year, the ANR Entracte leaded by CNRS/LAAS received the best price for ANR Project in November 2016 in Paris (“Grand prix du Numérique des 10ans de l'ANR”, <ref xlink:href="http://www.rencontres-numerique-anr.fr/index.php?option=com_content&amp;view=category&amp;id=19&amp;Itemid=116&amp;lang=fr" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">link</ref>).</p>
        <p>The ANR Jeune Chercheur project Cinecitta, led by Marc Christie, has also been awarded one of the 10 “iconic” projects (<i>projets emblématiques</i>) for the 10 years of the ANR, and will be presented at the 10 years celebration of the ANR in December 2016.</p>
      </subsection>
    </subsection>
  </highlights>
  <logiciels id="uid31">
    <bodyTitle>New Software and Platforms</bodyTitle>
    <subsection id="uid32" level="1">
      <bodyTitle>AsymGait</bodyTitle>
      <p>Asymmetry index for clinical gait analysis based on depth images</p>
      <p noindent="true"><span class="smallcap" align="left">Keywords:</span> Motion analysis - Kinect - Clinical analysis</p>
      <p noindent="true">
        <span class="smallcap" align="left">Scientific Description</span>
      </p>
      <p>The system uses depth images delivered by the Microsoft Kinect to retrieve gait cycles. To this end it is based on analyzing the knee trajectories instead of the feet to obtain more robust gait event detection. Based on these cycles, the system computes a mean gait cycle model to decrease the effect of noise of the system. Asymmetry is then computed at each frame of the gait cycle as the spatial difference between the left and right parts of the body.</p>
      <p noindent="true">
        <span class="smallcap" align="left">Functional Description</span>
      </p>
      <p>AsymGait is a software package that works with Microsoft Kinect data, especially depth images, in order to carry-out clinical gait analysis. First is identifies the main gait events using the depth information (footstrike, toe-off) to isolate gait cycles. Then it computes a continuous asymmetry index within the gait cycle. Asymmetry is viewed as a spatial difference between the two sides of the body.</p>
      <simplelist>
        <li id="uid33">
          <p noindent="true">Participants: Franck Multon and Edouard Auvinet</p>
        </li>
        <li id="uid34">
          <p noindent="true">Contact: Franck Multon</p>
        </li>
      </simplelist>
    </subsection>
    <subsection id="uid35" level="1">
      <bodyTitle>Cinematic Viewpoint Generator</bodyTitle>
      <p><span class="smallcap" align="left">Keywords:</span> Virtual Cinematography - Intelligent Gallery</p>
      <p noindent="true">
        <span class="smallcap" align="left">Functional Description</span>
      </p>
      <p>The software, developed as an API, provides a mean to automatically compute a collection of viewpoints over one or two specified geometric entities, in a given 3D scene, at a given time. These viewpoints satisfy classical cinematographic framing conventions and guidelines including different shot scales (from extreme long shot to extreme close-up), different shot angles (internal, external, parallel, apex), and different screen compositions (thirds, fifths, symmetric of di-symmetric). The viewpoints allow to cover the range of possible framings for the specified entities. The computation of such viewpoints relies on a database of framings that are dynamically adapted to the 3D scene by using a manifold parametric representation and guarantee the visibility of the specified entities. The set of viewpoints is also automatically annotated with cinematographic tags such as shot scales, angles, compositions, relative placement of entities, line of interest.</p>
      <simplelist>
        <li id="uid36">
          <p noindent="true">Participants: Emmanuel Badier, Christophe Lino and Marc Christie</p>
        </li>
        <li id="uid37">
          <p noindent="true">Partners: Université d'Udine - Université de Nantes - William Bares</p>
        </li>
        <li id="uid38">
          <p noindent="true">Contact: Marc Christie</p>
        </li>
      </simplelist>
    </subsection>
    <subsection id="uid39" level="1">
      <bodyTitle>Directors Lens Motion Builder</bodyTitle>
      <p><span class="smallcap" align="left">Keywords:</span> Previzualisation - Virtual cinematography - 3D animation</p>
      <p noindent="true">
        <span class="smallcap" align="left">Functional Description</span>
      </p>
      <p>Directors Lens Motion Builder is a software plugin for Autodesk's Motion Builder animation tool. This plugin features a novel workflow to rapidly prototype cinematographic sequences in a 3D scene, and is dedicated to the 3D animation and movie previsualization industries. The workflow integrates the automated computation of viewpoints (using the Cinematic Viewpoint Generator) to interactively explore different framings of the scene, proposes means to interactively control framings in the image space, and proposes a technique to automatically retarget a camera trajectory from one scene to another while enforcing visual properties. The tool also proposes to edit the cinematographic sequence and export the animation. The software can be linked to different virtual camera systems available on the market.</p>
      <simplelist>
        <li id="uid40">
          <p noindent="true">Participants: Emmanuel Badier, Christophe Lino and Marc Christie</p>
        </li>
        <li id="uid41">
          <p noindent="true">Partner: Université de Rennes 1</p>
        </li>
        <li id="uid42">
          <p noindent="true">Contact: Marc Christie</p>
        </li>
      </simplelist>
    </subsection>
    <subsection id="uid43" level="1">
      <bodyTitle>Kimea</bodyTitle>
      <p>Kinect IMprovement for Egronomics Assessment</p>
      <p noindent="true"><span class="smallcap" align="left">Keywords:</span> Biomechanics - Motion analysis - Kinect</p>
      <p noindent="true">
        <span class="smallcap" align="left">Scientific Description</span>
      </p>
      <p>Kimea consists in correcting skeleton data delivered by a Microsoft Kinect for ergonomics purposes. Kimea is able to manage most of the occultations that can occur on workstations (real working situations). To this end, Kimea relies on a database of examples/poses organized as a graph, in order to replace unreliable body segment reconstructions by poses that have already been measured on real subjects. The potential pose candidates are used in an optimization framework.</p>
      <p noindent="true">
        <span class="smallcap" align="left">Functional Description</span>
      </p>
      <p>Kimea gets Kinect data as input data (skeleton data) and correct most of measurement errors to carry-out ergonomic assessment at workstation.</p>
      <simplelist>
        <li id="uid44">
          <p noindent="true">Participants: Franck Multon, Pierre Plantard and Hubert Shum</p>
        </li>
        <li id="uid45">
          <p noindent="true">Partner: Faurecia</p>
        </li>
        <li id="uid46">
          <p noindent="true">Contact: Franck Multon</p>
        </li>
      </simplelist>
    </subsection>
    <subsection id="uid47" level="1">
      <bodyTitle>Populate</bodyTitle>
      <p><span class="smallcap" align="left">Keywords:</span> Behavioral animation - Virtual cities</p>
      <p noindent="true">
        <span class="smallcap" align="left">Scientific Description</span>
      </p>
      <p>Populate is a toolkit dedicated to task scheduling under time and space constraints in the field of behavioral animation. It is currently used to populate virtual cities with pedestrians performing different kind of activities implying travels between different locations. However the generic aspect of the algorithm and underlying representations enables its use in a wide range of applications that need to link activity, time and space. The main scheduling algorithm relies on the following inputs: an informed environment description, an activity an agent needs to perform and individual characteristics of this agent. The algorithm produces a valid task schedule compatible with time and spatial constraints imposed by the activity description and the environment. In this task schedule, time intervals relating to travel and task fulfilment are identified and locations where tasks should be performed are automatically selected.</p>
      <p noindent="true">With a good configuration of agents characteristics (based on statistics), we demonstrated that tasks schedules produced by Populate are representative of human ones. In conjunction with TopoPlan, it has been used to populate a district of Paris as well as imaginary cities with several thousands of pedestrians navigating in real time.</p>
      <p noindent="true">
        <span class="smallcap" align="left">Functional Description</span>
      </p>
      <p>The software provides the following functionalities:</p>
      <simplelist>
        <li id="uid48">
          <p noindent="true">A high level XML dialect that is dedicated to the description of agents activities in terms of tasks and sub activities that can be combined with different kind of operators: sequential, without order, interlaced. This dialect also enables the description of time and location constraints associated to tasks.</p>
        </li>
        <li id="uid49">
          <p noindent="true">An XML dialect that enables the description of agent's personal characteristics.</p>
        </li>
        <li id="uid50">
          <p noindent="true">An informed graph describes the topology of the environment as well as the locations where tasks can be performed. A bridge between TopoPlan and Populate has also been designed. It provides an automatic analysis of an informed 3D environment that is used to generate an informed graph compatible with Populate.</p>
        </li>
        <li id="uid51">
          <p noindent="true">The generation of a valid task schedule based on the previously mentioned descriptions.</p>
        </li>
      </simplelist>
      <simplelist>
        <li id="uid52">
          <p noindent="true">Participants: Fabrice Lamarche and Carl-Johan Jorgensen</p>
        </li>
        <li id="uid53">
          <p noindent="true">Contact: Fabrice Lamarche</p>
        </li>
      </simplelist>
    </subsection>
    <subsection id="uid54" level="1">
      <bodyTitle>The Theater</bodyTitle>
      <p><span class="smallcap" align="left">Keywords:</span> Interactive Scenarios - 3D animation - Storytelling</p>
      <p noindent="true">
        <span class="smallcap" align="left">Scientific Description</span>
      </p>
      <p>The Theater is a software framework to develop interactive scenarios in virtual 3D environments. The framework provides means to author and orchestrate 3D character behaviors and simulate them in real-time. The tools provide a basis to build a range of 3D applications, from simple simulations with reactive behaviors, to complex storytelling applications including narrative mechanisms such as flashbacks.</p>
      <p>
        <span class="smallcap" align="left">Functional Description</span>
      </p>
      <p>The Theater is Unity 3D application. XML descriptions are used to specify characters behaviors.</p>
      <simplelist>
        <li id="uid55">
          <p noindent="true">Contact: Marc Christie</p>
        </li>
      </simplelist>
    </subsection>
    <subsection id="uid56" level="1">
      <bodyTitle>Immerstar Platform</bodyTitle>
      <participants>
        <person key="mimetic-2014-idp71256">
          <firstname>Georges</firstname>
          <lastname>Dumont</lastname>
          <moreinfo>contact</moreinfo>
        </person>
        <person key="hybrid-2016-idp152560">
          <firstname>Ronan</firstname>
          <lastname>Gaugne</lastname>
        </person>
        <person key="mimetic-2014-idp85504">
          <firstname>Anthony</firstname>
          <lastname>Sorel</lastname>
        </person>
        <person key="mimetic-2014-idm27032">
          <firstname>Franck</firstname>
          <lastname>Multon</lastname>
        </person>
      </participants>
      <p>With the two platforms of virtual reality, Immersia and Immermove, grouped under the name Immerstar, the team has access to high level scientific facilities. This equipment benefits the research teams of the center and has allowed them to extend their local, national and international collaborations. The Immerstar platform is granted by a Inria CPER funding for 2015-2019 that enables important evolutions of the equipment. In 2016, the first technical evolutions have been decided, with, for Immermove, the addition of a third face to the immersive space, and the extension of the Vicon tracking system, and for Immersia, the installation of WQXGA laser projectors and of a new tracking system.</p>
    </subsection>
  </logiciels>
  <resultats id="uid57">
    <bodyTitle>New Results</bodyTitle>
    <subsection id="uid58" level="1">
      <bodyTitle>Outline</bodyTitle>
      <p>In 2016, MimeTIC pursued its efforts in improving virtual human simulation by initiating new projects in this domain, such as the Inria PRE with CAIRN team, and recruiting Antonio Mucherino in Inria half-delegation. Our main goal is to provide more natural human motion in real-time applications, which is a transversal requirement in many of MimeTIC's research domains.</p>
      <simplelist>
        <li id="uid59">
          <p noindent="true">In Biomechanics, being able to rapidly simulate plausible human motion enables to explore new approaches to provide real-time feedback to users in many application domains, such a rehabilitation, sports training, ergonomics and industrial training.</p>
        </li>
        <li id="uid60">
          <p noindent="true">In computer graphics, simulating natural motion either relies on heavy mechanical simulation and optimal control or adapting motion capture data. We wish to push dynamic simulation a step forward to propose new biomechanically-based simulation, such as actuating the virtual human with muscles instead of rotating servos. We also wish to simplify the process of retargeting motion capture data, which is a process still difficult to automatize. In both cases, we also promote the idea of understanding how human perception behaves when facing inaccurate simulation, in order to provide accurate simulations only when necessary.</p>
        </li>
        <li id="uid61">
          <p noindent="true">In virtual reality, real-time motion capture and simulation are essential when using head mounted display devices as users cannot perceive their own body during immersive experiences. Hence, simulating natural avatar motion and reacting efficiently to the user's actions are key points to ensure good Presence and Embodiment. MimeTIC is collaborating with other teams in VR, such as Hybrid, to address this complex pluridisciplinary question.</p>
        </li>
        <li id="uid62">
          <p noindent="true">In digital storytelling, interactive autonomous virtual characters lever the potentiality of proposing complex stories on social and human themes. More stories are now created with the goal of proposing several interactive storylines, which massively enhances the possibilities of interactive entertainment, computer games and digital applications. Projects in MimeTIC explore for instance how to provide a seamless control of the balance between the autonomy of characters and the unfolding of the story through the narrative discourse.</p>
        </li>
      </simplelist>
      <p>Hence, the organization of the results is reflecting these main challenges in motion analysis, virtual human simulation, interaction in VR, and digital storytelling.</p>
    </subsection>
    <subsection id="uid63" level="1">
      <bodyTitle>Motion Analysis</bodyTitle>
      <p>In motion analysis, we continued designing new approaches to measure human performance in specific applications, such as clinical gait assessment, ergonomics and sports. We also developed an original approach to concurrently analyze and simulate human motion, by addressing the problem of redundancy in musculoskeletal models.</p>
      <subsection id="uid64" level="2">
        <bodyTitle>Clinical gait assessment based on Kinect data</bodyTitle>
        <participants>
          <person key="mimetic-2014-idm27032">
            <firstname>Franck</firstname>
            <lastname>Multon</lastname>
          </person>
        </participants>
        <p>In clinical gait analysis, we proposed a method to overcome the main limitations imposed by the low accuracy of the Kinect measurements in real medical exams. Indeed, inaccuracies in the 3D depth images lead to badly reconstructed poses and inaccurate gait event detection. In the latter case, confusion between the foot and the ground leads to inaccuracies in the foot-strike and toe-off event detection, which are essential information to get in a clinical exam. To tackle this problem we assumed that heel strike events could be indirectly estimated by searching for the extreme values of the distance between the knee joints along the walking longitudinal axis. As Kinect sensor may not accurately locate the knee joint, we used anthropometrical data to select a body point located at a constant height where the knee should be in the reference posture. Compared to previous works using a Kinect, heel strike events and gait cycles are more accurately estimated, which could improve global clinical gait analysis frameworks with such a sensor. Once these events are correctly detected, it is possible to define indexes that enable the clinician to have a rapid state of the quality of the gait. We therefore proposed a new method to assess gait asymmetry based on depth images, to decrease the impact of errors in the Kinect joint tracking system. It is based on the longitudinal spatial difference between lower-limb movements during the gait cycle. The movement of artificially impaired gaits was recorded using both a Kinect placed in front of the subject and a motion capture system. The proposed longitudinal index distinguished asymmetrical gait, while other symmetry indices based on spatiotemporal gait parameters failed using such Kinect skeleton measurements. This gait asymmetry index measured with a Kinect is low cost, easy to use and is a promising development for clinical gait analysis.</p>
        <p>This method has been challenged with other classical approaches to assess gait asymmetry using either cheap Kinect data or Vicon data. We demonstrate the superiority of the approach when using Kinect data for which traditional approaches failed to accurately detect gait asymmetry. It has been validated on healthy subjects who were forced to walk with a 5cm sole placed below each foot alternatively <ref xlink:href="#mimetic-2016-bid5" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        <p>This work has been done in collaboration with the MsKLab from Imperial College London, to design new gait asymmetry indexes that could be used in daily clinical analysis.</p>
      </subsection>
      <subsection id="uid65" level="2">
        <bodyTitle>New automatic methods to assess motion in industrial contexts based on Kinect</bodyTitle>
        <participants>
          <person key="mimetic-2014-idm27032">
            <firstname>Franck</firstname>
            <lastname>Multon</lastname>
          </person>
          <person key="mimetic-2014-idp104376">
            <firstname>Pierre</firstname>
            <lastname>Plantard</lastname>
          </person>
        </participants>
        <p>Recording human activity is a key point of many applications and fundamental works. Numerous sensors and systems have been proposed to measure positions, angles or accelerations of the user’s body parts. Whatever the system is, one of the main challenge is to be able to automatically recognize and analyze the user’s performance according to poor and noisy signals. Hence, recognizing and measuring human performance are important scientific challenges especially when using low-cost and noisy motion capture systems. MimeTIC has addressed the above problems in two main application domains. In this section, we detail the ergonomics application of such an approach.</p>
        <p>Firstly, in ergonomics, we explored the use of low-cost motion capture systems (i.e., a Microsoft Kinect) to measure the 3D pose of a subject in natural environments, such as on a workstation, with many occlusions and inappropriate sensor placements. Predicting the potential accuracy of the measurement for such complex 3D poses and sensor placements is challenging with classical experimental setups. After having evaluated the actual accuracy of the pose reconstruction method delivered by the Kinect, we have identified that occlusions were a very important problem to solve in order to obtain reliable ergonomic assessments in real cluttered environments. To this end, we extended previous correction methods proposed by Hubert Shum (Northumbria University) which consist in identifying the reliable and unreliable parts of the Kinect skeleton data, and to replace unreliable ones by prior knowledge recorded in a database. In collaboration with Hubert Shum, we extended this approach to deal with long occlusions that occur in real manufacturing conditions. To this end we proposed a new data structure named Filtered Pose Graph to speed-up the process, and select example poses that improve the quality of the correction, especially ensuring continuity. We have demonstrated a significant increase of the quality of the correction, especially when large tracking errors occur with the Kinect system <ref xlink:href="#mimetic-2016-bid6" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        <p>This method has been applied to a complete ergonomic process outputting RULA scores based on the reconstructed and corrected poses. We also demonstrated that it delivers new ergonomic information compared to traditional approaches based on isolated pictures: it provides time spent above a given RULA score which is a valuable information to support decision in ergonomics <ref xlink:href="#mimetic-2016-bid0" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. We also challenged this method with a reference motion capture system in laboratory conditions. In order to evaluate the actual use in ergonomics, we also compared the ergonomic scores obtained with this automatic method to two experts' scores in real factories. The results show very good agreements between automatic and manual assessments, and have been published in Applied Ergonomics journal <ref xlink:href="#mimetic-2016-bid7" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        <p>This work was partially funded by the Faurecia company through a Cifre convention.</p>
      </subsection>
      <subsection id="uid66" level="2">
        <bodyTitle>Evaluation and analysis of sports gestures: application to tennis serve</bodyTitle>
        <participants>
          <person key="mimetic-2014-idp73992">
            <firstname>Richard</firstname>
            <lastname>Kulpa</lastname>
          </person>
          <person key="mimetic-2016-idp209728">
            <firstname>Marion</firstname>
            <lastname>Morel</lastname>
          </person>
          <person key="mimetic-2014-idp65960">
            <firstname>Benoit</firstname>
            <lastname>Bideau</lastname>
          </person>
          <person key="mimetic-2016-idp219488">
            <firstname>Pierre</firstname>
            <lastname>Touzard</lastname>
          </person>
        </participants>
        <p>Following the previous studies we made on tennis serve, we were able to evaluate the link between performance and risk of injuries. To go further, we made new experiments to quantify the influence of fatigue on the performance of tennis serve, that is to say the kinematic, kinetic and performance changes that occur in the serve throughout a prolonged tennis match play <ref xlink:href="#mimetic-2016-bid8" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>, <ref xlink:href="#mimetic-2016-bid9" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. To this end, we recorded serves of several advanced tennis players with a motion capture system before, at mid-match, and after a 3-hour tennis match. Before and after each match, we also recorded electromyographic data of 8 upper limb muscles obtained during isometric maximal voluntary contraction. These experiments showed a decrease in mean power frequency values for several upper limb muscles that is an indicator of local muscular fatigue. Decreases in serve ball speed, ball impact height, maximal angular velocities and an increase in rating of perceived exertion were also observed between beginning and end of match. However, no change in timing of maximal angular velocities was observed. The consistency in timing of maximal angular velocities suggests that advanced tennis players are able to maintain the temporal pattern of their serve technique, in spite of the muscular fatigue development <ref xlink:href="#mimetic-2016-bid8" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. Moreover, we showed that passive shoulder internal rotation and total range of motion are significantly decreased during a 3-hour tennis match that is identified as an injury risk factor among tennis players <ref xlink:href="#mimetic-2016-bid9" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        <p>Overall, automatically evaluating and quantifying the performance of a player is a complex task since the important motion features to analyze depend on the type of performed action. But above all, this complexity is due to the variability of morphologies and styles of both novices and experts (who perform the reference motions). Only based on a database of experts’ motions and no additional knowledge, we propose an innovative 2-level DTW (Dynamic Time Warping) approach to temporally and spatially align the motions and extract the imperfections of the novice’s performance for each joint. We applied our method on tennis serves and karate katas <ref xlink:href="#mimetic-2016-bid10" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
      </subsection>
      <subsection id="uid67" level="2">
        <bodyTitle>Interactions between walkers</bodyTitle>
        <participants>
          <person key="mimetic-2014-idp77968">
            <firstname>Anne-Hélène</firstname>
            <lastname>Olivier</lastname>
          </person>
          <person key="mimetic-2014-idp69792">
            <firstname>Armel</firstname>
            <lastname>Crétual</lastname>
          </person>
          <person key="phoenix-2014-idp112224">
            <firstname>Julien</firstname>
            <lastname>Bruneau</lastname>
          </person>
          <person key="mimetic-2014-idp73992">
            <firstname>Richard</firstname>
            <lastname>Kulpa</lastname>
          </person>
          <person key="mimetic-2015-idp92992">
            <firstname>Sean</firstname>
            <lastname>Lynch</lastname>
          </person>
          <person key="mimetic-2016-idp231696">
            <firstname>Laurentius</firstname>
            <lastname>Meerhoff</lastname>
          </person>
          <person key="mimetic-2014-idm25552">
            <firstname>Julien</firstname>
            <lastname>Pettré</lastname>
          </person>
        </participants>
        <object id="uid68">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/interactionsWalkers.png" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>Experiments performed to investigate interactions between walkers.</caption>
        </object>
        <p>Interaction between people, and especially local interaction between walkers, is a main research topic of MimeTIC. We propose experimental approaches using both real and virtual environments to study both perception and action aspects of the interaction. This year, we developed new experiments in our immersive platform. In the context of Sean Lynch's PhD on the visual perception of human motion during interactions in locomotor tasks, we designed a study to investigate whether local limb motion is required to successfully avoid a single dynamic obstacle or if global motion alone provides sufficient information (Figures <ref xlink:href="#uid68" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.a and <ref xlink:href="#uid68" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.b). Sixteen healthy subjects were immersed in a virtual environment that required navigating towards a target, whilst an obstacle crossed its path. Within the virtual environment, four occluding walls prevented the subject observing the complete environment at the initiation of movement, ensuring steady state was reached prior to obstacle interaction. The velocity and heading of the obstacle were programmed to result in a range of future crossing distance (varying from 0.1 to 1.2m) in front and behind the subject. The velocity and heading of the obstacle were fixed, and the subject used a joystick to control its orientation to avoid collision. Five obstacle appearances were presented in a randomized order; a full body (control condition), trunk- or legs- only (i.e., local motion only), and a cylinder or sphere representing the center of gravity (COG) (i.e., global motion only). No significant difference for obstacle appearance was found on number of collisions. However, in both global motion only conditions, subjects adopted alternative collision avoidance strategies compared to the full body control condition. Distance regulation and collision avoidance within daily activities may be principally regulated by global rather than local motion. Underlying mechanisms may differ accordingly to shape and size, however there is no impediment for successful completion of collision avoidance.</p>
        <p>Second, we provide lot of efforts to investigate the complex case of multiple interactions while in previous studies we mainly focused on pairwise interactions. We developed a new experiment using an eye tracker to provide insight about the selection process of the interactions (Figures <ref xlink:href="#uid68" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.c and <ref xlink:href="#uid68" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.d). We proposed to study the human gaze during a navigation task in a crowded virtual environment. The characteristics of each virtual agent was known and controlled. Then, by recording the gaze activity, we are able to highlight the characteristics of each agent the participant was looking at. Results first showed a strong link between the fixated agents and the trajectory adaptations of the participants which means that participants looked at agents they are interacting with, which is an important result to validate the use of the eye tracker in such a situation. Concerning the characteristics of the fixated agents, results showed that human gaze, during navigation, is attracted by dangerous individuals: they were the ones presenting the higher risk of future collision with the participants. Future work is needed to evaluate the influence of other factors such as walking speed or the nature of agents trajectories. This year, we also performed an important experimental campaign including 80 participants to investigate collective behavior (Figure <ref xlink:href="#uid68" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.e). When people walk together in the street, they have to coordinate their own motion with the ones of their neighbors. From these local interactions, group motion emerges. The objective of this study was to understand how a collective behavior can emerge from these local interactions between individuals. Especially, the study aimed at identifying what is the neighborhood of a walker in a group from a perceptual point of view (who influences your motion). This work was performed in collaboration with William Warren (Brown University, Providence) and Cécile Appert-Rolland (CNRS, Orsay). Data analysis is still in process but from these results we hope to develop new knowledge on pedestrian behavior. These new results will help us to design new or improve existing crowd simulators based on local interactions. These simulators have important economic and societal roles. For example, they allow to validate the design of public places/building, which aims at hosting dense levels of public in perfectly safe conditions. The study of multiple interactions was also strengthened with the arrival of Laurentius Meerhoff as a post-doctoral student with a regional SAD funding in May 2016. Experiments involving 3 walkers were conducted (Figure <ref xlink:href="#uid68" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.f). We investigated how collision is avoided in small groups of people and whether people can successfully interact with the whole environment, or whether under some circumstance agents had to resort to sequential treatment. We proposed a method to detect whether the treatment was sequential or simultaneous and we showed the initial relative position between walkers strongly affects how interaction is engaged with.</p>
        <p>Third, we started working on the interaction between a walker and a person on a motorized wheelchair (Figure <ref xlink:href="#uid68" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.g). This work was performed in collaboration with the Inria Lagadic team. The main objective was to design a control law that allows the wheelchair to automatically navigate in a crowded place without any collision. This is important for people who have difficulties to drive their wheelchair because of cognitive impairments. However, before reaching this objective, some steps are required to understand how walkers and persons on a wheelchair interact together. To this end, we developed a study where we recorded the trajectory of walkers and a person on a wheelchair in a collision avoidance and reaching scenario. Results will help to model such a control law for natural interactions.</p>
        <p>Finally, we continue working on the interaction between a walker and a moving robot. This work was performed in collaboration with Philippe Souères and Christian Vassallo (LAAS, Toulouse). The development of Robotics accelerated these recent years, it is clear that robots and humans will share the same environment in a near future. In this context, understanding local interactions between humans and robots during locomotion tasks is important to steer robots among humans in a safe manner. Our work is a first step in this direction. Our goal is to describe how, during locomotion, humans avoid collision with a moving robot. We just published in Gait and Posture our results on collision avoidance between participants and a non-reactive robot (we wanted to avoid the effect of a complex loop by a robot reacting to participants’ motion). Our objective was to determine whether the main characteristics of such interaction preserve the ones previously observed: accurate estimation of collision risk, anticipated and efficient adaptations. We observed that collision avoidance between a human and a robot has similarities with human-human interactions (estimation of collision risk, anticipation) but also leads to major differences <ref xlink:href="#mimetic-2016-bid11" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. Humans preferentially give way to the robot, even if this choice is not optimal with regard to motion adaptation to avoid the collision. In this new study, we considered the situation where the robot was reactive to the walker's motion (Figure <ref xlink:href="#uid68" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.h). First of all, it results that humans have a good understanding of the robot behavior and their reaction are smoother and faster with respect to the case with a non-collaborative robot. Second, humans adapt similarly to human-human study and the crossing order is respected in almost all cases. These results have strong similarities with the ones observed with two humans crossing each other.</p>
      </subsection>
      <subsection id="uid69" level="2">
        <bodyTitle>Biomechanics for motion analysis-synthesis</bodyTitle>
        <participants>
          <person key="mimetic-2014-idp79256">
            <firstname>Charles</firstname>
            <lastname>Pontonnier</lastname>
          </person>
          <person key="mimetic-2014-idp71256">
            <firstname>Georges</firstname>
            <lastname>Dumont</lastname>
          </person>
          <person key="mimetic-2014-idp98224">
            <firstname>Ana Lucia</firstname>
            <lastname>Cruz Ruiz</lastname>
          </person>
          <person key="mimetic-2014-idp103120">
            <firstname>Antoine</firstname>
            <lastname>Muller</lastname>
          </person>
          <person key="mimetic-2015-idp102880">
            <firstname>Diane</firstname>
            <lastname>Haering</lastname>
          </person>
        </participants>
        <p>In the context of Ana Lucia Cruz Ruiz's PhD, whose goal is to define and evaluate muscle-based controllers for avatar animation, we developed an original control approach to reduce the redundancy of the musculoskeletal system for motion synthesis, based on the muscle synergy theory. For this purpose we ran an experimental campaign of overhead throwing motions. We recorded the muscle activity of 10 muscles of the arm and the motion of the subjects. Thanks to a synergy extraction algorithm, we extracted a reduced set of activation signals corresponding to the so called muscle synergies and used them as an input in a forward dynamics pipeline. Thanks to a two stage optimization method, we adapted the model's muscle parameters and the synergy signals to be as close as possible of the recorded motion. The results are compelling and ask for further developments <ref xlink:href="#mimetic-2016-bid12" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. We also proposed a classification about muscle-based controllers for animation that has been published in Computer Graphics Forum <ref xlink:href="#mimetic-2016-bid1" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. Ana Lucia defended her thesis on December 2nd, 2016.</p>
        <p>We are also developing an analysis pipeline thanks to the work of Antoine Muller. This pipeline aims at using a modular and multiscale description of the human body to let users be able to analyse human motion. For now, the pipeline is able to assemble different biomechanical models in a convenient descriptive graph, to calibrate these models thanks to experimental data and to compute inverse dynamics to get joint torques from experimental motion capture data. We also investigated the capacity of motion-based methods to calibrate body segment inertial parameters in characterizing the part of the residuals due to the kinematical error into the dynamical one <ref xlink:href="#mimetic-2016-bid13" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        <p>We also begin to work on the determination of maximal torque envelopes of the elbow thanks to the work of Diane Haering, Inria Post-doctoral fellow at MimeTIC. These results have a great potential of application i) to quantify the articular load during work tasks and ii) to help calibrating muscle parameters for musculoskeletal simulations. Preliminary results have been presented to an international biomechanics conference <ref xlink:href="#mimetic-2016-bid14" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        <p>Finally, in collaboration with the CERAH (Centre d'étude et d'appareillage des handicapés, institut des invalides, Créteil, France), we proposed an identification-based method for knee prosthesis characteristics. The method is based on a forward dynamics framework enabling a matching between experimental data and model behavior <ref xlink:href="#mimetic-2016-bid15" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
      </subsection>
    </subsection>
    <subsection id="uid70" level="1">
      <bodyTitle>Virtual Human Simulation</bodyTitle>
      <p>In addition to this last contribution on biomechanically-inspired character simulation, at the crossroad between motion analysis and simulation, we also explored two main directions for virtual human simulation in 2016. Firstly, with the arrival of Antonio Mucherino in the team, we pushed the idea of extending the idea of interaction meshes (introduced in 2010 by Taku Komura in Edinburgh) to model the constraints intrinsically associated with the motion. This approach requires developing new distance geometry algorithms in order to take time and rigid body constraints into account. Secondly, we continued to push the idea of using perceptual studies to efficiently adapt simulation in order to save computation time for less important details.</p>
      <p>Julien Pettré moved to the Lagadic Inria team in March 2016. However we continue collaborating with him on crowd simulation problems, e.g., developing models related to interactions between pedestrians and designing perceptual studies to improve the realism of simulations.</p>
      <subsection id="uid71" level="2">
        <bodyTitle>Recent advances in discretizable distance geometry</bodyTitle>
        <participants>
          <person key="genscale-2014-idp67832">
            <firstname>Antonio</firstname>
            <lastname>Mucherino</lastname>
          </person>
          <person key="mimetic-2015-idm26392">
            <firstname>Ludovic</firstname>
            <lastname>Hoyet</lastname>
          </person>
          <person key="mimetic-2014-idm27032">
            <firstname>Franck</firstname>
            <lastname>Multon</lastname>
          </person>
        </participants>
        <p>Since September 2016, Antonio Mucherino has a half-time Inria detachment in the MimeTIC team, in order to collaborate on exploring distance geometry-based problems in representing and editing human motion. In collaboration with various French and international partners, he has been working on the different facets of the discretization of the distance geometry. In 2016, he has mainly focused on the two following points. Firstly, since the discretization assumptions require the existence of a vertex ordering on the graph <formula type="inline"><math xmlns="http://www.w3.org/1998/Math/MathML" overflow="scroll"><mi>G</mi></math></formula> which is used for representing a problem instance, he presented a new algorithm for the automatic detection of vertex orders that are also able to optimize a given set of objectives <ref xlink:href="#mimetic-2016-bid16" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. With the aim of making its exploration more efficient, the idea is to reduce in size the search space obtained with the discretization, while keeping in its interior the entire solution set. Secondly, he has started to investigate the possibility to extend the distance geometry (and its discretization) to a wider range of applications, by studying the overlaps between two different geometrical applications, arising in two different domains <ref xlink:href="#mimetic-2016-bid17" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        <p>More related to the integration with the work in MimeTIC, we are currently exploring applying distance geometry approaches to other applications of interest for virtual human simulations, such as human motion editing and retargeting, and crowd simulations.</p>
      </subsection>
      <subsection id="uid72" level="2">
        <bodyTitle>Perception of Secondary Motions in Crowd Scenarios</bodyTitle>
        <participants>
          <person key="mimetic-2015-idm26392">
            <firstname>Ludovic</firstname>
            <lastname>Hoyet</lastname>
          </person>
          <person key="mimetic-2014-idp77968">
            <firstname>Anne-Hélène</firstname>
            <lastname>Olivier</lastname>
          </person>
          <person key="mimetic-2014-idp73992">
            <firstname>Richard</firstname>
            <lastname>Kulpa</lastname>
          </person>
          <person key="mimetic-2014-idm25552">
            <firstname>Julien</firstname>
            <lastname>Pettré</lastname>
          </person>
        </participants>
        <p>Creating plausible virtual character animations is of importance in topics researched in MimeTIC, especially for interactive applications where balancing realism and computational load is a requisite. Recently, we investigated how to improve realism of virtual crowd animations by exploring the effects of introducing secondary shoulder motions at the animation level. Typically, a crowd engine pipeline animates numerous moving characters according to a two-step process. First, a crowd simulator generates the characters’ global 2D displacement trajectories in the environment, then an animation engine transforms these global trajectories into full body motions. This two-step decomposition is interesting for computational reasons, as crowd simulators raise quadratic complexity issues by nature. For the sake of simplicity, simulation models are often limited to 2D moving circles with 3 degrees of freedom (DoF), i.e., two translations and a rotation. The complete set of internal trajectories (30 to 60 DoF per character) is then considered at the animation step only, where characters are processed independently. This two-step process avoids combining the complexity of crowd simulators with the dimensionality of character kinematic models. However, it also leads to the notion of interactions between characters to be considered only at the simulation level, and to be lost at the animation level. Body animations are therefore not influenced by the presence of neighbours, only global trajectories are. Final animations therefore often lead to residual collisions and/or characters walking as if they were alone, showing no sign to the influence of others.</p>
        <p>In this work, we investigated the value of adding secondary motions on the perceived visual quality of crowd animations (i.e., perceived residual collisions and animation naturalness). We focused on adding shoulder motions to characters passing at close distances, and explored this question through two perceptual experiments. To understand the effects of shoulder motions on walking interactions, we first focused on understanding how these secondary motions affect how viewers perceive local interactions between two characters. We found that shoulder motions have strong positive effects on the visual quality of two-character animations, where such animations are perceived to be significantly more natural, and residual collisions become significantly less perceptible. Then we evaluated the benefits of displaying shoulder motions in the situation of crowded scenes, where shoulder motions are diluted into much more visually complex animations, and demonstrated positive effects on the animation naturalness. This increase of visual quality is obtained at a very low computational overhead, which demonstrates the relevance of the direction explored by our work. Our general conclusion is that adding secondary motions in character interactions has a significant impact on the visual quality of crowd animations, with a very light impact on the computational cost of the whole animation pipeline. Our results advance crowd animation techniques by enhancing the simulation of complex interactions between crowd characters with simple secondary motion triggering techniques.</p>
        <p>These results were accepted and presented in SIGGRAPH 2016, the premier and most selective computer graphics scientific event, and published in ACM Transaction on Graphics <ref xlink:href="#mimetic-2016-bid2" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
      </subsection>
    </subsection>
    <subsection id="uid73" level="1">
      <bodyTitle>Human Motions in VR</bodyTitle>
      <p>To carry-out natural and efficient interactions with a digital world, it is firstly necessary to recognize and evaluate the action of the user. We consequently initiated a collaboration with the Intuidoc IRISA team to adapt methods previously used in 2D gesture recognition to 3D motion. With the increasing use of head mounted display devices (especially cheap devices recently spread in the large public), the problem of avatar simulation and embodiment has become an important challenge. In this context, we initiated collaborative works with Hybrid to better understand embodiment and consequently imagine the future generation of avatars. Concurrently, we continued to explore the use of such technology in various application domains where human performance is a key point, such as ergonomics.</p>
      <subsection id="uid74" level="2">
        <bodyTitle>Motion recognition and classification</bodyTitle>
        <participants>
          <person key="mimetic-2014-idm27032">
            <firstname>Franck</firstname>
            <lastname>Multon</lastname>
          </person>
          <person key="mimetic-2014-idp73992">
            <firstname>Richard</firstname>
            <lastname>Kulpa</lastname>
          </person>
          <person key="mimetic-2016-idp197536">
            <firstname>Yacine</firstname>
            <lastname>Boulahia</lastname>
          </person>
        </participants>
        <p>Action recognition based on human skeleton structure represents nowadays a prospering research ﬁeld. This is mainly due to the recent advances in terms of capture technologies and skeleton extraction algorithms. In this context, we observed that 3D skeleton-based actions share several properties with handwritten symbols since they both result from a human performance. We accordingly hypothesize that the action recognition problem can take advantage of trial and error approaches already carried out on handwritten patterns. Therefore, inspired by one of the most efﬁcient and compact handwriting feature-set, we proposed a skeleton descriptor referred to as Handwriting-Inspired Features <ref xlink:href="#mimetic-2016-bid18" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. First of all, joint trajectories are preprocessed in order to handle the variability among actor’s morphologies. Then we extract the HIF3D features from the processed joint locations according to a time partitioning scheme so as to additionally encode the temporal information over the sequence.
Finally, we used Support Vector Machine (SVM) for classiﬁcation. Evaluations conducted on two challenging datasets, namely HDM05 and UTKinect, testify the soundness of our approach as the obtained results outperform the state-of-the-art algorithms that rely on skeleton data.</p>
        <p>This work has been carried-out in collaboration with the IRISA Intuidoc team, with Yacine Boulahia who is a co-supervised PhD student with Eric Anquetil.</p>
      </subsection>
      <subsection id="uid75" level="2">
        <bodyTitle>Avatar Embodiment in Virtual Reality</bodyTitle>
        <participants>
          <person key="mimetic-2015-idm26392">
            <firstname>Ludovic</firstname>
            <lastname>Hoyet</lastname>
          </person>
        </participants>
        <p>With the massive development of virtual reality products investigated by major industrial companies (Google, Facebook, HTC, Sony, etc), there is a new need for understanding what makes users immersed in virtual environments, especially regarding their relation to their virtual representation (i.e., avatar). Amongst others, an important factor is for users to feel incarnated in their avatar, which is called <i>virtual embodiment</i>. As more and more technological limitations are now being unlocked, understanding such factors become important to lever new immersive applications, e.g., in education, ergonomics or entertainment.</p>
        <p>In collaboration with the EPI Hybrid (Ferran Argelaguet and Anatole Lécuyer), we explore the capacity of avatars to convey such a sense of “virtual embodiment”, i.e., the extent to which we accept an avatar to be our representation in the virtual environment. The question of embodiment originates from the famous Rubber Hand Illusion experiment of Botvinick and Cohen (1998). This experiment demonstrated that when participants are presented with a fake rubber hand positioned beside their real hidden hand, and that both hands are synchronously stroked by an experimenter, after some time participants consider their real hand to be positioned at the location of the fake rubber hand. Today, understanding how similar phenomena happen in virtual environments is crucial to provide a maximum immersion for users. For instance, previous work demonstrated that racial biases can be reduced when users are incarnated in virtual characters of a different race, or explored body weight perception by altering the morphology of the avatar. The innovative aspect of our contributions is that we explore this embodiment effect in terms of interactions of the user with the virtual environment.</p>
        <p>So far, we explored how people appropriate avatars by evaluating how they accept different representations of their virtual hand in virtual environments. Using various representations ranging from simplistic to highly realistic when interacting in virtual environments <ref xlink:href="#mimetic-2016-bid4" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>, we demonstrated that the sense of ownership (i.e., the impression that the virtual hand is actually our own hand) is increased when displaying highly realistic hand representations, but that the sense of agency (i.e., the impression to be able to control the actions of the virtual hand) is stronger for less realistic representations. With the potential of VR to alter and control avatars in different ways, e.g., the user representation, we also explored how structural differences of the hand representation can influence embodiment through controlling a six-digit virtual hand <ref xlink:href="#mimetic-2016-bid3" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. We found that participants responded positively to the possibility of controlling the virtual hand despite the structural difference, and accepted it as their own to some extent. Overall, results from such experiments further our understanding of the capacity of avatars to elicit a sense of embodiment in the users, and help to design more immersive VR experiences.</p>
      </subsection>
      <subsection id="uid76" level="2">
        <bodyTitle>VR and Ergonomics</bodyTitle>
        <participants>
          <person key="mimetic-2014-idp79256">
            <firstname>Charles</firstname>
            <lastname>Pontonnier</lastname>
          </person>
          <person key="mimetic-2014-idp71256">
            <firstname>Georges</firstname>
            <lastname>Dumont</lastname>
          </person>
          <person key="mimetic-2014-idp104376">
            <firstname>Pierre</firstname>
            <lastname>Plantard</lastname>
          </person>
          <person key="mimetic-2014-idm27032">
            <firstname>Franck</firstname>
            <lastname>Multon</lastname>
          </person>
        </participants>
        <p>The use of virtual reality tools for ergonomics applications is a very important challenge in order to generalize the use of such devices for the design of workstations.</p>
        <p>We proposed a framework for collaborative ergonomic design in virtual environments. The framework consists in defining design modes and metaphors that help the users (engineers, ergonomists, end-users) to find a good trade-off between their own design constraints that can be contradictory at some point. We evaluated the framework and concluded that the active user has to be carefully chosen with regard to the design specifications, since the active user is favouring systematically its own constraints. This work has been published in the Journal on Multimodal User Interfaces <ref xlink:href="#mimetic-2016-bid19" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
      </subsection>
    </subsection>
    <subsection id="uid77" level="1">
      <bodyTitle>Digital Storytelling</bodyTitle>
      <p>A transversal research of MimeTIC is digital storytelling as it enables to analyse, capture, model and simulate scenarios involving several humans (real and/or virtual). In this context, it is important to propose annotation tools and languages being able to capture such scenarios and stylistic informations before being able to simulate new ones. Moreover, when living an immersive experience in VR the user may want to have a summarize of his experience, which goes beyond simply replaying the recorded motions. Narration techniques can be positively used to highlight key events and actions, with nonlinear storytelling and intelligent camera placement to convey the desired emotion. The research in this field in MimeTIC contributes to the creation of complex stories on social and human themes. Such approaches are more and more required to create interactive storylines, which massively enhances the possibilities of interactive entertainment, training, computer games and digital applications.</p>
      <subsection id="uid78" level="2">
        <bodyTitle>Trip Synopsis: virtual camera control applied to route visualisation</bodyTitle>
        <participants>
          <person key="mimetic-2014-idp68552">
            <firstname>Marc</firstname>
            <lastname>Christie</lastname>
          </person>
        </participants>
        <p>Computerized route planning tools are widely used today by travelers all around the globe, while 3D terrain and urban models are becoming increasingly elaborate and abundant. This makes it feasible to generate a virtual 3D flyby along a planned route. Such a flyby may be useful, either as a preview of the trip, or as an after-the-fact visual summary. However, a naively generated preview is likely to contain many boring portions, while skipping too quickly over areas worthy of attention. We have therefore proposed a general interest-driven framework that automatically computes a flyby along a planned route <ref xlink:href="#mimetic-2016-bid20" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. This flyby relies on an interest function to derive how close and how slow the camera should focus on the interesting areas, while skipping interest-less regions by using elevated smoothed camera motions. To address the problem, we devised a specific iterative solving process that incrementally approaches the optimal camera trajectory by adjusting position and speed.</p>
      </subsection>
      <subsection id="uid79" level="2">
        <bodyTitle>Flashbacks in narratives</bodyTitle>
        <participants>
          <person key="mimetic-2014-idp68552">
            <firstname>Marc</firstname>
            <lastname>Christie</lastname>
          </person>
          <person key="mimetic-2014-idp110528">
            <firstname>Hui-Yin</firstname>
            <lastname>Wu</lastname>
          </person>
        </participants>
        <p>The flashback is a well-known storytelling device used to invoke surprise, suspense, or fill in missing details in a story. Film literature provides a deeper and more complex grounding of flashbacks by explaining their role to stimulate the viewer’s memory in order to guide and change viewer comprehension. Yet, in adapting flashback mechanisms to AI storytelling systems, existing approaches have not fully modelled the roles of a flashback event on the viewer’s comprehension and memory. To expand the scope of AI generated stories, we propose a formal definition of flashbacks based on the identification of four different impacts on the viewer’s beliefs. We then establish a cognitive model that can predict how viewers would perceive a flashback event. We finally design a user evaluation to demonstrate that our model correctly predicts the effects of different flashbacks. This opens great opportunities for creating compelling and temporally complex interactive narratives grounded on cognitive models <ref xlink:href="#mimetic-2016-bid21" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
      </subsection>
      <subsection id="uid80" level="2">
        <bodyTitle>Embedded Cinematography Patterns for film Analysis</bodyTitle>
        <participants>
          <person key="mimetic-2014-idp68552">
            <firstname>Marc</firstname>
            <lastname>Christie</lastname>
          </person>
          <person key="mimetic-2014-idp110528">
            <firstname>Hui-Yin</firstname>
            <lastname>Wu</lastname>
          </person>
        </participants>
        <p>Cinematography carries messages on the plot, emotion, or more general feeling of the film. Yet cinematographic devices are often overlooked in existing approaches to film analysis. To solve this limitation, we present Embedded Constrained Patterns (ECPs), a dedicated query language to search annotated film clips for sequences that fulfill complex stylistic constraints <ref xlink:href="#mimetic-2016-bid22" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. ECPs are groups of framing and sequencing constraints defined using vocabulary in film textbooks. Using a set algorithm, all occurrences of the ECPs can be found in annotated film sequences. We use a film clip from the Lord of the Rings to demonstrate a range of ECPs that can be detected, and analyse them in relation to story and emotions in the film.</p>
      </subsection>
    </subsection>
  </resultats>
  <contrats id="uid81">
    <bodyTitle>Bilateral Contracts and Grants with Industry</bodyTitle>
    <subsection id="uid82" level="1">
      <bodyTitle>Cifre Faurecia</bodyTitle>
      <participants>
        <person key="mimetic-2014-idm27032">
          <firstname>Franck</firstname>
          <lastname>Multon</lastname>
          <moreinfo>contact</moreinfo>
        </person>
        <person key="mimetic-2014-idp104376">
          <firstname>Pierre</firstname>
          <lastname>Plantard</lastname>
        </person>
      </participants>
      <p>This contract aims at developing new ergonomics assessments based on inaccurate Kinect measurements in real manufacturing conditions. The main challenges are:</p>
      <simplelist>
        <li id="uid83">
          <p noindent="true">being able to improve the Microsoft Kinect measurement in order to extract accurate poses from depth images while occlusions may occur,</p>
        </li>
        <li id="uid84">
          <p noindent="true">developing new inverse dynamics methods based on such inaccurate kinematic data in order to estimate the joint torques required to perform the observed task,</p>
        </li>
        <li id="uid85">
          <p noindent="true">and proposing a new assessment tool to translate joint torques and poses into potential musculoskeletal disorders risks.</p>
        </li>
      </simplelist>
      <p>Faurecia has developed its own assessment tool but it requires tedious and subjective tasks for the user, at specific times in the work cycle. By using Kinect information we aim at providing more objective data over the whole cycle not only for specific times. We also wish to make the user focus on the interpretation and understanding of the operator's tasks instead of taking time estimating joint angles in images.</p>
      <p>This work is performed in close collaboration with an ergonomist in Faurecia together with the software development service of the company to design the new version of their assessment tool. This tool will be first evaluated on a selection of manufacturing sites and will then be spread worldwide among the 300 Faurecia sites in 33 countries.</p>
      <p>This contract enabled us to hire Pierre Plantard as a PhD student to carry-out this work in MimeTIC and M2S Lab. He started in January 2013, finished at the beginning of 2016, and defended his PhD in July 2016. This contract was the opportunity to demonstrate the impact of MimeTIC's work about in-site motion capture on ergonomic assessment, as a decision-support system for ergonomists. The software Kimea is one of the results of this collaboration. It is currently spread in the factories of Faurecia around the world, which demonstrates the maturity of this work for industrial transfer. The method has been published with ergonomic validation in the famous journal Applied Ergonomics (see Highlight section).
</p>
    </subsection>
  </contrats>
  <partenariat id="uid86">
    <bodyTitle>Partnerships and Cooperations</bodyTitle>
    <subsection id="uid87" level="1">
      <bodyTitle>National Initiatives</bodyTitle>
      <subsection id="uid88" level="2">
        <bodyTitle>ANR</bodyTitle>
        <subsection id="uid89" level="3">
          <bodyTitle>Cineviz</bodyTitle>
          <participants>
            <person key="mimetic-2014-idp68552">
              <firstname>Marc</firstname>
              <lastname>Christie</lastname>
              <moreinfo>contact</moreinfo>
            </person>
            <person key="imagine-2014-idp148824">
              <firstname>Christophe</firstname>
              <lastname>Lino</lastname>
            </person>
            <person key="mimetic-2014-idp110528">
              <firstname>Hui-Yin</firstname>
              <lastname>Wu</lastname>
            </person>
          </participants>
          <p>Cineviz is a 3-year ANR LabCom project (2016-2019). Amount: 300kE. Parnters: SolidAnim, UR1.</p>
          <p>The project is a bilateral collaboration with the SolidAnim company. The objective is to jointly progress on the design and implementation of novel tools for the preproduction in the film industry. The project will address the challenges related to (i) proposing expressive framing tools, (ii) integrating the technical aspects of shooting (how to place the cameras, lights, green sets) directly at the design stage), and (iii) novel interaction metaphors for designing and controlling the staging of lights in preproduction, using an example-based approach.</p>
        </subsection>
        <subsection id="uid90" level="3">
          <bodyTitle>Cinecitta</bodyTitle>
          <participants>
            <person key="mimetic-2014-idp68552">
              <firstname>Marc</firstname>
              <lastname>Christie</lastname>
              <moreinfo>contact</moreinfo>
            </person>
            <person key="imagine-2014-idp148824">
              <firstname>Christophe</firstname>
              <lastname>Lino</lastname>
            </person>
            <person key="mimetic-2014-idp110528">
              <firstname>Hui-Yin</firstname>
              <lastname>Wu</lastname>
            </person>
          </participants>
          <p>Cinecitta is a 3.5 year ANR young researcher project lead by Marc Christie (ANR JCJC 2012-2016). Amount: 208kE.</p>
          <p>The main objective of Cinecitta was to propose and evaluate a novel workﬂow which mixes user interaction using motion-tracked cameras and automated computation aspects for interactive virtual cinematography that will better support user creativity. We designed a novel cinematographic workﬂow that features a dynamic collaboration of a creative human filmmaker with an automated virtual camera planner. The process enhances the quality and utility of the automated planner’s suggestions by adapting and reacting to the creative choices made by the ﬁlmmaker. This required three advances in the ﬁeld. First, the ability to generate relevant viewpoint suggestions following classical cinematic conventions. The formalization of these conventions in a computationally efﬁcient and expressive model is a challenging task in order to select and propose the user with a relevant subset of viewpoints among millions of possibilities. Second, the ability to analyze data from real movies in order to formalize some elements of cinematographic style and genre. Third, the integration of motion-tracked cameras in the workﬂow. Motion-tracked cameras represent a great potential for cinematographic content creation. However given that tracking spaces are of limited size, there is a need to provide novel interaction metaphors to ease the process of content creation with tracked cameras. Finally we gathered feedback on our prototype by involving professionals (during dedicated workshops) and numerous interactions with the Louis Lumière Film School.</p>
        </subsection>
        <subsection id="uid91" level="3">
          <bodyTitle>Entracte</bodyTitle>
          <participants>
            <person key="mimetic-2014-idp79256">
              <firstname>Charles</firstname>
              <lastname>Pontonnier</lastname>
              <moreinfo>contact</moreinfo>
            </person>
            <person key="mimetic-2014-idp71256">
              <firstname>Georges</firstname>
              <lastname>Dumont</lastname>
            </person>
            <person key="mimetic-2014-idm27032">
              <firstname>Franck</firstname>
              <lastname>Multon</lastname>
            </person>
            <person key="mimetic-2014-idp104376">
              <firstname>Pierre</firstname>
              <lastname>Plantard</lastname>
            </person>
            <person key="mimetic-2014-idp98224">
              <firstname>Ana Lucia</firstname>
              <lastname>Cruz Ruiz</lastname>
            </person>
            <person key="mimetic-2014-idp103120">
              <firstname>Antoine</firstname>
              <lastname>Muller</lastname>
            </person>
            <person key="mimetic-2014-idp85504">
              <firstname>Anthony</firstname>
              <lastname>Sorel</lastname>
            </person>
            <person key="mimetic-2014-idp67352">
              <firstname>Nicolas</firstname>
              <lastname>Bideau</lastname>
            </person>
            <person key="mimetic-2014-idp73992">
              <firstname>Richard</firstname>
              <lastname>Kulpa</lastname>
            </person>
          </participants>
          <p>The ANR project ENTRACTE is a collaboration between the Gepetto team in LAAS, Toulouse (head of the project) and the Inria/MimeTIC team. The project started in November 2013 and will end in August 2017. The purpose of the ENTRACTE project is to address the action planning problem, crucial for robots as well as for virtual human avatars, in analyzing human motion at a biomechanical level and in defining from this analysis bio-inspired motor control laws and bio-inspired paradigms for action planning. The project is launched since november 2013 and Ana Lucia Cruz Ruiz, who has been recruited as a PhD student since this date, just defended her thesis on muscle-based control based on synergies.</p>
        </subsection>
      </subsection>
      <subsection id="uid92" level="2">
        <bodyTitle>National scientific collaborations</bodyTitle>
        <subsection id="uid93" level="3">
          <bodyTitle>Cavaletic</bodyTitle>
          <participants>
            <person key="mimetic-2014-idm27032">
              <firstname>Franck</firstname>
              <lastname>Multon</lastname>
            </person>
          </participants>
          <p>The Cavaletic collaborative project is leaded by University Bretagne Sud and also involves University Rennes2 (CREAD Lab.). It has been funded by the National IFCE (Institut Français du Cheval et de l'Equitation) in order to develop and evaluate technological assistance in horse riding learning, thanks to a user-centered approach. MimeTIC is involved in measuring expert and non-expert horse riders’ motions in standardized situations in order to develop metrics to measure riders’ performance. It will be used to develop a technological system embedded on users to evaluate their performance and provide them with real-time feedback to correct potential errors.</p>
        </subsection>
        <subsection id="uid94" level="3">
          <bodyTitle>FFT</bodyTitle>
          <participants>
            <person key="mimetic-2014-idp73992">
              <firstname>Richard</firstname>
              <lastname>Kulpa</lastname>
            </person>
            <person key="mimetic-2014-idp65960">
              <firstname>Benoit</firstname>
              <lastname>Bideau</lastname>
            </person>
            <person key="mimetic-2016-idp219488">
              <firstname>Pierre</firstname>
              <lastname>Touzard</lastname>
            </person>
          </participants>
          <p>An exclusive contract has been signed between the M2S laboratory and the French Federation of Tennis for three years. The goal is to perform biomechanical analyses of 3D tennis serves on a population of 40 players of the Pôle France. The objective is to determine the link between injuries and biomechanical constraints on joints and muscles depending on the age and gender of the players. At the end, the goal is to evaluate their load training.</p>
        </subsection>
        <subsection id="uid95" level="3">
          <bodyTitle>gDGA</bodyTitle>
          <participants>
            <person key="genscale-2014-idp67832">
              <firstname>Antonio</firstname>
              <lastname>Mucherino</lastname>
            </person>
            <person key="mimetic-2015-idm26392">
              <firstname>Ludovic</firstname>
              <lastname>Hoyet</lastname>
            </person>
            <person key="mimetic-2014-idm27032">
              <firstname>Franck</firstname>
              <lastname>Multon</lastname>
            </person>
          </participants>
          <p>gDGA (generalization of the Distance Geometry and its Applications) is a INS2I/CNRS PEPS project involving local and national partners. Distance geometry can nowadays be seen as a classical problem in operational research, having a wide range of applications. The main aim of this interdisciplinary project is to extend the definition and the range of applicability of distance geometry. In particular, our main interest is on dynamical problems, motivated by a certain number of applications of interest, including interaction motion adaptation, the simulation of crowd behaviours, and the conception of modern recommender systems. The classical application of distance geometry arising in the biological field is also taken into consideration. The necessity of a strong computational power for the considered applications motivates the need of implementing our algorithms in environments capable of exploiting the resources on GPU cards.</p>
        </subsection>
        <subsection id="uid96" level="3">
          <bodyTitle>IRMA</bodyTitle>
          <participants>
            <person key="hybrid-2016-idp152560">
              <firstname>Ronan</firstname>
              <lastname>Gaugne</lastname>
              <moreinfo>contact</moreinfo>
            </person>
            <person key="mimetic-2014-idp71256">
              <firstname>Georges</firstname>
              <lastname>Dumont</lastname>
            </person>
          </participants>
          <p>The IRMA project is an Imag'In project funded by CNRS which aims at developping innovative methodologies for research in the field of cultural heritage based on the combination of medical imaging technologies and interactive 3D technologies (virtual reality, augmented reality, haptics, additive manufacturing). It relies on close collaborations with the National Institute of Preventive Archaeological Research (Inrap), the Research Center Archaeology, and History Archéosciences (CReAAH UMR 6566) and the company Image ET. The developed tools are intended for cultural heritage professionals such as museums, curators, restorers, and archaeologists. We focus on a large number of archeological artefacts of different nature, and various time periods (Paleolithic, Mesolithic, and Iron Age Medieval) from all over France. We can notably mention the oldest human bones found in Brittany (clavicle Beg Er Vil), a funeral urn from Trebeurden (22), or a Bronze Cauldron from a burial of the Merovingian necropolis "Crassés Saint-Dizier" (51). This project involves a strong collaboration with members of the team Hybrid (Valérie Gouranton, Bruno Arnaldi and Jean-Baptiste Barreau), Théophane Nicolas (Inrap/UMR Trajectoires), Quentin Petit (SED Inria Rennes), and Grégor Marchand (CNRS/UMR CReAAH).</p>
        </subsection>
      </subsection>
      <subsection id="uid97" level="2">
        <bodyTitle>ADT: Immerstar</bodyTitle>
        <participants>
          <person key="mimetic-2014-idm27032">
            <firstname>Franck</firstname>
            <lastname>Multon</lastname>
          </person>
          <person key="mimetic-2014-idp71256">
            <firstname>Georges</firstname>
            <lastname>Dumont</lastname>
          </person>
          <person key="hybrid-2016-idp152560">
            <firstname>Ronan</firstname>
            <lastname>Gaugne</lastname>
          </person>
        </participants>
        <p>The ADT-Immerstar is driven by the SED and aims at developing new tools and facilities for the scientific community in order to develop demos and use the two immersive rooms in Rennes: Immersia and Immermove. The engineer (Quentin Petit, SED) has the responsibility of homogenizing the software modules and development facilities in each platform, of installing new upgrades and of developping collaborative applications between the two sites.</p>
      </subsection>
      <subsection id="uid98" level="2">
        <bodyTitle>PRE</bodyTitle>
        <participants>
          <person key="mimetic-2014-idm27032">
            <firstname>Franck</firstname>
            <lastname>Multon</lastname>
          </person>
          <person key="mimetic-2015-idm26392">
            <firstname>Ludovic</firstname>
            <lastname>Hoyet</lastname>
          </person>
        </participants>
        <p>The Inria PRE entitled "Smart sensors and novel motion representation breakthrough for human performance analysis" aims at designing a new description for human motion in order to automatically capture, measure and transfer the intrinsic constraints of human motion. Current approaches consist in manually editing the constraints associated with a motion, to use classical skeleton representation with joint angles based on direct or indirect measurements, and then perform inverse kinematics to fulfill these constraints. We aim at designing a new representation to simplify this process pipeline and make it automatic, together with relevant motion sensors that could provide enough information to automatically extract these intrinsic constraints. To this end, this project has been jointly proposed with the Inria CAIRN team, which develops sensors based on joint orientations and distances between sensors. We aim at extending this type of device to measure new types of information that would help to simplify the above mentionned pipeline. Zhiguang Liu started to work as a research fellow on this project since November 2016, working in collaboration with CAIRN. We also involved Hubert Shum from Northumbria University to link this project with our long-term collaboration on this type of problems.
</p>
      </subsection>
    </subsection>
    <subsection id="uid99" level="1">
      <bodyTitle>International Initiatives</bodyTitle>
      <subsection id="uid100" level="2">
        <bodyTitle>Inria Associate Teams Not Involved in an Inria International Labs</bodyTitle>
        <subsection id="uid101" level="3">
          <bodyTitle>
            <ref xlink:href="http://www.irisa.fr/mimetic/GENS/mchristi/EA-FORMOSA/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">FORMOSA</ref>
          </bodyTitle>
          <sanspuceslist>
            <li id="uid102">
              <p noindent="true">Title: Fostering Research on Models for Storytelling Applications</p>
            </li>
            <li id="uid103">
              <p noindent="true">International Partner (Institution - Laboratory - Researcher):</p>
              <sanspuceslist>
                <li id="uid104">
                  <p noindent="true">NCCU (Taiwan)
- Intelligent Media Lab (IML) - Tsai-Yen Li</p>
                </li>
              </sanspuceslist>
            </li>
            <li id="uid105">
              <p noindent="true">Start year: 2016</p>
            </li>
            <li id="uid106">
              <p noindent="true">See also: <ref xlink:href="http://www.irisa.fr/mimetic/GENS/mchristi/EA-FORMOSA/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>www.<allowbreak/>irisa.<allowbreak/>fr/<allowbreak/>mimetic/<allowbreak/>GENS/<allowbreak/>mchristi/<allowbreak/>EA-FORMOSA/</ref></p>
            </li>
            <li id="uid107">
              <p noindent="true">Interactive Storytelling is a new media which allows users to alter the content and outcome of narratives through role-playing and specific actions. With the quality, the availability and reasonable costs of display technologies and 3D interaction devices on one side, and the accessibility of 3D content creation tools on the other, this media is taking a significant share in entertainment (as demonstrated by the success of cinematographic games such as Heavy Rain or Beyond: two souls). These advances push us to re-think the way narratives are traditionally structured, explore new interactive modalities and provide new interactive cinematographic experiences. As a sequel of the first associate team FORMOSA 1, we propose to address new challenges pertained to interactive storytelling such as the use of temporal structures in narratives, interaction modalities and their impact in terms of immersion, and the adaptation of cinematographic real data to 3D environments. To achieve these objectives, the associate team will rely on the complementary skills of its partners and on the co-supervision of students.</p>
            </li>
          </sanspuceslist>
        </subsection>
        <subsection id="uid108" level="3">
          <bodyTitle>
            <ref xlink:href="http://www.irisa.fr/mimetic/GENS/jpettre/EASIMS/easims.html" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">RE-SIMS</ref>
          </bodyTitle>
          <sanspuceslist>
            <li id="uid109">
              <p noindent="true">Title: REal data against crowd SImulation algorithMS</p>
            </li>
            <li id="uid110">
              <p noindent="true">International Partner (Institution - Laboratory - Researcher):</p>
              <sanspuceslist>
                <li id="uid111">
                  <p noindent="true">University of North Carolina at Chapel Hill (United States)
- GAMMA Research Group (GAMMA) - Ming LIN</p>
                </li>
              </sanspuceslist>
            </li>
            <li id="uid112">
              <p noindent="true">Start year: 2015</p>
            </li>
            <li id="uid113">
              <p noindent="true">See also: <ref xlink:href="http://www.irisa.fr/mimetic/GENS/jpettre/EASIMS/easims.html" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>www.<allowbreak/>irisa.<allowbreak/>fr/<allowbreak/>mimetic/<allowbreak/>GENS/<allowbreak/>jpettre/<allowbreak/>EASIMS/<allowbreak/>easims.<allowbreak/>html</ref></p>
            </li>
            <li id="uid114">
              <p noindent="true">RE-SIMS aims at gathering the best international research teams working on crowd simulation to allow significant progresses on the level of realism achieved by crowd simulators. To this end, RE-SIMS aims at improving methods for capturing crowd motion data that describe real crowd behaviors, as well as by improving data assimilation techniques.</p>
              <p>In this renewal, RE-SIMS extends the previous SIMS partnership and follows a multidiciplinary direction.</p>
            </li>
          </sanspuceslist>
        </subsection>
      </subsection>
      <subsection id="uid115" level="2">
        <bodyTitle>Informal Inria International Partners</bodyTitle>
        <sanspuceslist>
          <li id="uid116">
            <p noindent="true">Dr. Edouard Auvinet, Imperial College London, UK (collaboration with Franck Multon, visited the team for a wekk in November)</p>
          </li>
          <li id="uid117">
            <p noindent="true">Dr. Douglas S. Gonçalves, Federal University of Santa Catarina, Florianópolis, Brazil (collaboration with Antonio Mucherino, visited the team in December)</p>
          </li>
          <li id="uid118">
            <p noindent="true">Prof. Carlile Lavor, UNICAMP, Campinas, São Paulo, Brazil (collaboration with Antonio Mucherino)</p>
          </li>
          <li id="uid119">
            <p noindent="true">Dr. Rachel McDonnell, Trinity College Dublin, Ireland (collaboration with Ludovic Hoyet, joint paper submission)</p>
          </li>
          <li id="uid120">
            <p noindent="true">Prof. Carol O'Sullivan, Trinity College Dublin, Ireland (collaboration with Ludovic Hoyet, visited the team for a week in June)</p>
          </li>
          <li id="uid121">
            <p noindent="true">Dr. Huber Shum, Northumbria University, Newcastle, UK (collaboration with Franck Multon and Ludovic Hoyet, with joint papers and supervision, visited the team in November)</p>
          </li>
        </sanspuceslist>
      </subsection>
    </subsection>
    <subsection id="uid122" level="1">
      <bodyTitle>International Research Visitors</bodyTitle>
      <subsection id="uid123" level="2">
        <bodyTitle>Visits of International Scientists</bodyTitle>
        <sanspuceslist>
          <li id="uid124">
            <p noindent="true">Dr. Edouard Auvinet, Imperial College London, UK (one week in November)</p>
          </li>
          <li id="uid125">
            <p noindent="true">Dr. Douglas S. Gonçalves, Federal University of Santa Catarina, Florianópolis, Brazil (one week in December)</p>
          </li>
          <li id="uid126">
            <p noindent="true">Prof. Carol O'Sullivan, Trinity College Dublin, Ireland (one week in June)</p>
          </li>
          <li id="uid127">
            <p noindent="true">Dr. Hubert Shum, Northumbria University, Newcastle, UK (joint supervision, visit for two days in November)</p>
          </li>
        </sanspuceslist>
        <subsection id="uid128" level="3">
          <bodyTitle>Internships</bodyTitle>
          <sanspuceslist>
            <li id="uid129">
              <p noindent="true">Yihun Shen, Northumbria University, Newcastle, UK (PhD supervisor: Dr. Hubert Shum), 4-month internship on Rennes Metropole incoming mobility funding (Sept. to Dec. 2016).</p>
            </li>
          </sanspuceslist>
        </subsection>
      </subsection>
    </subsection>
  </partenariat>
  <diffusion id="uid130">
    <bodyTitle>Dissemination</bodyTitle>
    <subsection id="uid131" level="1">
      <bodyTitle>Promoting Scientific Activities</bodyTitle>
      <subsection id="uid132" level="2">
        <bodyTitle>Scientific Events Organisation</bodyTitle>
        <subsection id="uid133" level="3">
          <bodyTitle>General Chair, Scientific Chair</bodyTitle>
          <sanspuceslist>
            <li id="uid134">
              <p noindent="true">Marc Christie, Program chair of Motion in Games 2015 (but held in 2016)</p>
            </li>
          </sanspuceslist>
        </subsection>
        <subsection id="uid135" level="3">
          <bodyTitle>Member of the Organizing Committees</bodyTitle>
          <sanspuceslist>
            <li id="uid136">
              <p noindent="true">Antonio Mucherio, organiser of Distance Geometry Day 2016, Rennes, France, December 2016</p>
            </li>
            <li id="uid137">
              <p noindent="true">Anne-Hélène Olivier, co-chair of Workshop VHCIE 2016, IEEE VR 2016, Greenville, United-States, October 2016</p>
            </li>
            <li id="uid138">
              <p noindent="true">Marc Christie, steering committee of Motion in Games 2015 and 2016, co-chair of WICED 2016 (Eurographics Workshop on Intelligent Cinematography and Editing)</p>
            </li>
          </sanspuceslist>
        </subsection>
      </subsection>
      <subsection id="uid139" level="2">
        <bodyTitle>Scientific Events Selection</bodyTitle>
        <subsection id="uid140" level="3">
          <bodyTitle>Member of the Conference Program Committees</bodyTitle>
          <p>Marc Christie</p>
          <sanspuceslist>
            <li id="uid141">
              <p noindent="true">ACM Motion in Games MIG 2016, San Francisco, United-States, October 2016</p>
            </li>
            <li id="uid142">
              <p noindent="true">ACM Symposium on Computer Animation 2016, Zurich, Switzerland, July 2016</p>
            </li>
          </sanspuceslist>
          <p>Ludovic Hoyet</p>
          <sanspuceslist>
            <li id="uid143">
              <p noindent="true">ACM Motion in Games MIG 2016, San Francisco, United-States, October 2016</p>
            </li>
            <li id="uid144">
              <p noindent="true">ACM Symposium on Applied Perception 2016, Los Angeles, United-States, July 2016</p>
            </li>
            <li id="uid145">
              <p noindent="true">International Conference on Computer Graphics Theory and Applications 2017, Porto, Portugal, February 2017</p>
            </li>
          </sanspuceslist>
          <p>Richard Kulpa</p>
          <sanspuceslist>
            <li id="uid146">
              <p noindent="true">International Conference on Computer Graphics Theory and Applications 2017, Porto, Portugal, February 2017</p>
            </li>
          </sanspuceslist>
          <p>Franck Multon</p>
          <sanspuceslist>
            <li id="uid147">
              <p noindent="true">ACM Motion in Games MIG 2016, San Francisco, United-States, October 2016</p>
            </li>
            <li id="uid148">
              <p noindent="true">Computer Animation and Social Agents CASA 2016, Geneva, Switzerland, May 2016</p>
            </li>
          </sanspuceslist>
          <p>Anne-Hélène Olivier</p>
          <sanspuceslist>
            <li id="uid149">
              <p noindent="true">ACM Motion in Games MIG 2016, San Francisco, United-States, October 2016</p>
            </li>
          </sanspuceslist>
        </subsection>
        <subsection id="uid150" level="3">
          <bodyTitle>Reviewer</bodyTitle>
          <p>Marc Christie</p>
          <sanspuceslist>
            <li id="uid151">
              <p noindent="true">Eurographics, Lyon, France, April 2017</p>
            </li>
            <li id="uid152">
              <p noindent="true">ACM CHI, Denver, United-States, May 2017</p>
            </li>
            <li id="uid153">
              <p noindent="true">ACM Siggraph, Anaheim, United-States, July 2016</p>
            </li>
            <li id="uid154">
              <p noindent="true">Eurographics 2017, CHI 2017, Siggraph 2017,</p>
            </li>
          </sanspuceslist>
          <p>Ludovic Hoyet</p>
          <sanspuceslist>
            <li id="uid155">
              <p noindent="true">ACM Siggraph, Anaheim, United-States, July 2016</p>
            </li>
            <li id="uid156">
              <p noindent="true">ACM SigChi, San Jose, United-States, May 2016</p>
            </li>
            <li id="uid157">
              <p noindent="true">Eurographics, Lyon, France, April 2017</p>
            </li>
            <li id="uid158">
              <p noindent="true">IEEE VR 2017, Los Angeles, United-States, March 2017</p>
            </li>
            <li id="uid159">
              <p noindent="true">Pacific Graphics, Okinawa, Japan, October 2016</p>
            </li>
          </sanspuceslist>
          <p>Richard Kulpa</p>
          <sanspuceslist>
            <li id="uid160">
              <p noindent="true">IEEE International Conference on Automatic Face and Gesture Recognition, 2017</p>
            </li>
          </sanspuceslist>
          <p>Franck Multon</p>
          <sanspuceslist>
            <li id="uid161">
              <p noindent="true">IEEE VR 2017, Los Angeles, United-States, March 2017</p>
            </li>
          </sanspuceslist>
          <p>Anne-Hélène Olivier</p>
          <sanspuceslist>
            <li id="uid162">
              <p noindent="true">IEEE VR 2017, Los Angeles, United-States, March 2017</p>
            </li>
            <li id="uid163">
              <p noindent="true">ACM Siggraph, Anaheim, United-States, July 2016</p>
            </li>
            <li id="uid164">
              <p noindent="true">ACM Siggraph Asia 2016, Macao, China, December 2016</p>
            </li>
          </sanspuceslist>
          <p>Charles Pontonnier</p>
          <sanspuceslist>
            <li id="uid165">
              <p noindent="true">ACM VRST 2016, Munich, Germany, November 2016</p>
            </li>
          </sanspuceslist>
        </subsection>
      </subsection>
      <subsection id="uid166" level="2">
        <bodyTitle>Journal</bodyTitle>
        <subsection id="uid167" level="3">
          <bodyTitle>Member of the Editorial Boards</bodyTitle>
          <sanspuceslist>
            <li id="uid168">
              <p noindent="true">Marc Christie, Associate Editor of the Visual Computer</p>
            </li>
            <li id="uid169">
              <p noindent="true">Armel Crétual, Editorial board of Journal of Electromyography and Kinesiology</p>
            </li>
            <li id="uid170">
              <p noindent="true">Franck Multon, Presence, MIT Press</p>
            </li>
          </sanspuceslist>
        </subsection>
        <subsection id="uid171" level="3">
          <bodyTitle>Reviewer - Reviewing Activities</bodyTitle>
          <p>Marc Christie</p>
          <sanspuceslist>
            <li id="uid172">
              <p noindent="true">IEEE Transactions on Visualization and Computer Graphics, The Visual Computer, Computer Graphics Forum</p>
            </li>
          </sanspuceslist>
          <p>Armel Crétual</p>
          <sanspuceslist>
            <li id="uid173">
              <p noindent="true">Journal of Electromyography and Kinesiology, British Medical Journal open, Clinical Biomechanics, Journal of Orthopaedic Research, IEEE Computer Graphics and Applications</p>
            </li>
          </sanspuceslist>
          <p>Ludovic Hoyet</p>
          <sanspuceslist>
            <li id="uid174">
              <p noindent="true">IEEE Transactions on Visualization and Computer Graphics, IEEE Computer Graphics &amp; Applications, Computer &amp; Graphics, The Visual Computer Journal, Computer Animation and Virtual Worlds</p>
            </li>
          </sanspuceslist>
          <p>Richard Kulpa</p>
          <sanspuceslist>
            <li id="uid175">
              <p noindent="true">Journal of Sports Engineering and Technology, Computer</p>
            </li>
          </sanspuceslist>
          <p>Antonio Mucherino</p>
          <sanspuceslist>
            <li id="uid176">
              <p noindent="true">Mathematical Programming Series A and B, Springer, October 2016.</p>
            </li>
          </sanspuceslist>
          <p>Franck Multon</p>
          <sanspuceslist>
            <li id="uid177">
              <p noindent="true">Journal Applied Ergonomics, IEEE Transaction on Haptics, IEEE Trans. on Visualization and Computer Graphics, ACM Transactions on Applied Perception, IEEE Computer Graphics and Applications, International Journal of Computer Games Technology</p>
            </li>
          </sanspuceslist>
          <p>Anne-Hélène Olivier</p>
          <sanspuceslist>
            <li id="uid178">
              <p noindent="true">Journal of Experimental Psychology Human Perception and Performance</p>
            </li>
          </sanspuceslist>
          <p>Charles Pontonnier</p>
          <sanspuceslist>
            <li id="uid179">
              <p noindent="true">Applied Ergonomics, IEEE Computer Graphics and Applications, MDPI Computers, IEEE Transactions on Visualization and Computer Graphics, ACM Computing surveys</p>
            </li>
          </sanspuceslist>
        </subsection>
      </subsection>
      <subsection id="uid180" level="2">
        <bodyTitle>Invited Talks</bodyTitle>
        <sanspuceslist>
          <li id="uid181">
            <p noindent="true">Ludovic Hoyet. Perception of Biological Human Motion for Plausible Character Animation. Invited speaker at Université Bretagne Sud, team Expression, Vannes, France, June 2016</p>
          </li>
          <li id="uid182">
            <p noindent="true">Antonio Mucherino. Vertex Orders in Distance Geometry. Invited seminar at LIA, University of Avignon, France. Invited by R. Figueiredo. November 2016.</p>
          </li>
        </sanspuceslist>
      </subsection>
      <subsection id="uid183" level="2">
        <bodyTitle>Scientific Expertise</bodyTitle>
        <sanspuceslist>
          <li id="uid184">
            <p noindent="true">Marc Christie, expert for CIR (credit impot recherche – three cases in 2016)</p>
          </li>
          <li id="uid185">
            <p noindent="true">Georges Dumont, expert for Dutch Research Council VENI (Netherlands) project</p>
          </li>
          <li id="uid186">
            <p noindent="true">Franck Multon, HCERES expert for UMR 7287 AMU/CNRS "Institut des Sciences du Mouvements" in Marseille en 2016-2017, ANR expert, member of the ANR CPDS 4 "Santé Bien-être" through the Allistene national Alliance to design the next ANR call for projects, expert for international NSRC (Canada), CRSNG (Canada) and Dutch Research Council VENI (Netherlands) projects</p>
          </li>
          <li id="uid187">
            <p noindent="true">Charles Pontonnier, Member of the Normalization Work Group "Impact of exoskeletons on work conditions", groupe AFNOR.</p>
          </li>
        </sanspuceslist>
      </subsection>
      <subsection id="uid188" level="2">
        <bodyTitle>Research Administration</bodyTitle>
        <sanspuceslist>
          <li id="uid189">
            <p noindent="true">Georges Dumont is president of the elected group at scientific council of École Normale Supérieure de Rennes, member of the scientific council of École Normale Supérieure de Rennes</p>
          </li>
          <li id="uid190">
            <p noindent="true">Georges Dumont is scientific head of Immerstar platforms (Immersia + Immermove) jointly for Inria and Irisa Partners</p>
          </li>
          <li id="uid191">
            <p noindent="true">Ludovic Hoyet participated in the local MESR PhD Grant Auditions 2016</p>
          </li>
          <li id="uid192">
            <p noindent="true">Richard Kulpa is member of the University Rennes2 Research steering committee "commission recherche", and Academic Council "CAC"</p>
          </li>
          <li id="uid193">
            <p noindent="true">Fabrice Lamarche is a member of the national council of universities (Conseil National des Universités - CNU) since november 2015</p>
          </li>
          <li id="uid194">
            <p noindent="true">Antonio Mucherinon is the person in charge of International Relationships at ISTIC, and member of the "Commission Affaires Internationales" at Université Rennes 1</p>
          </li>
          <li id="uid195">
            <p noindent="true">Franck Multon, member of the "Conseil Académique" and "Commission Recherche" of University Rennes2, head of Immermove platform in the Immerstar group, member of the D6 "Media and Interactions" department in IRISA, head of MimeTIC team</p>
          </li>
        </sanspuceslist>
      </subsection>
    </subsection>
    <subsection id="uid196" level="1">
      <bodyTitle>Teaching - Supervision - Juries</bodyTitle>
      <subsection id="uid197" level="2">
        <bodyTitle>Teaching</bodyTitle>
        <subsection id="uid198" level="3">
          <bodyTitle>Master</bodyTitle>
          <p>Marc Christie</p>
          <sanspuceslist>
            <li id="uid199">
              <p noindent="true">"Multimedia Mobile", Master 2, leader of the module, 32h, Computer Science, University of Rennes 1, France</p>
            </li>
            <li id="uid200">
              <p noindent="true">"Projet Industriel Transverse", Master 2, 32h, leader of the module, Computer Science, University of Rennes 1, France</p>
            </li>
            <li id="uid201">
              <p noindent="true">"Outils pour la Conception d'IHM", Master 2, 32h, leader of the module, Computer Science, University of Rennes 1, France</p>
            </li>
          </sanspuceslist>
          <p>Armel Crétual</p>
          <sanspuceslist>
            <li id="uid202">
              <p noindent="true">"Méthodologie", leader of the module, 20h, Master 1 M2S, University Rennes2, France</p>
            </li>
            <li id="uid203">
              <p noindent="true">"Biostatstiques", leader of the module, 30h, Master 2 M2S, University Rennes2, France</p>
            </li>
          </sanspuceslist>
          <p>Georges Dumont</p>
          <sanspuceslist>
            <li id="uid204">
              <p noindent="true">Responsible of the second year of the master Mechatronics, Rennes 1 University and École Normale Supérieure de Rennes, France</p>
            </li>
            <li id="uid205">
              <p noindent="true">"Mechanical simulation in Virtual Reality", 36h, Master Mechatronics, Rennes 1 University and École Normale Supérieure de Rennes, France</p>
            </li>
            <li id="uid206">
              <p noindent="true">"Mechanics of deformable systems", 40h, Master FE, École Normale Supérieure de Rennes, France</p>
            </li>
            <li id="uid207">
              <p noindent="true">"Oral preparation to agregation competitive exam", 20h, Master FE, École Normale Supérieure de Rennes, France</p>
            </li>
            <li id="uid208">
              <p noindent="true">"Vibrations in Mechanics", 10h, Master FE, École Normale Supérieure de Rennes, France</p>
            </li>
            <li id="uid209">
              <p noindent="true">"Multibody Dynamics", 9h, Master FE, École Normale Supérieure de Rennes, France</p>
            </li>
            <li id="uid210">
              <p noindent="true">"Finite Element method", 12h, Master FE, École Normale Supérieure de Rennes, France</p>
            </li>
          </sanspuceslist>
          <p>Ronan Gaugne</p>
          <sanspuceslist>
            <li id="uid211">
              <p noindent="true">"VR projects", 40h, M1/M2, INSA Rennes, France</p>
            </li>
          </sanspuceslist>
          <p>Ludovic Hoyet</p>
          <sanspuceslist>
            <li id="uid212">
              <p noindent="true">"Images et Mouvement - IMO", Part "Mouvement Humain", 10h, Master 2 research in computer sciences, University Rennes1, France</p>
            </li>
          </sanspuceslist>
          <p>Richard Kulpa</p>
          <sanspuceslist>
            <li id="uid213">
              <p noindent="true">"Boucle analyse-modélisation-simulation du mouvement", 27h, leader of the module, Master 2 M2S, Université Rennes 2, France</p>
            </li>
            <li id="uid214">
              <p noindent="true">"Méthodes numériques d'analyse du geste", 27h, leader of the module, Master 2 M2S, Université Rennes 2, France</p>
            </li>
            <li id="uid215">
              <p noindent="true">"Cinématique inverse", 3h, leader of the module, Master 2 M2S, Université Rennes 2, France</p>
            </li>
          </sanspuceslist>
          <p>Fabrice Lamarche</p>
          <sanspuceslist>
            <li id="uid216">
              <p noindent="true">"Compilation pour l'image numérique", 29h, Master 1, ESIR, University of Rennes 1, France</p>
            </li>
            <li id="uid217">
              <p noindent="true">"Synthèse d'images", 12h, Master 1, ESIR, University of Rennes 1, France</p>
            </li>
            <li id="uid218">
              <p noindent="true">"Synthèse d'images avancée", 28h, Master 1, ESIR, University of Rennes 1, France</p>
            </li>
            <li id="uid219">
              <p noindent="true">"Modélisation Animation Rendu", 36h, Master 2, ISTIC, University of Rennes 1, France</p>
            </li>
            <li id="uid220">
              <p noindent="true">"Jeux vidéo", 26h, Master 2, ESIR, University of Rennes 1, France</p>
            </li>
          </sanspuceslist>
          <p>Antonio Mucherino</p>
          <sanspuceslist>
            <li id="uid221">
              <p noindent="true">"Parallel Computing" (in English), 30h, M1 Informatique, Université Rennes 1, France</p>
            </li>
            <li id="uid222">
              <p noindent="true">"Introduction aux Systèmes et Réseaux", 42h, M1 BIG (SVE), Université Rennes 1, France</p>
            </li>
            <li id="uid223">
              <p noindent="true">"Programmation Orienté à Objets", 40h, M1 BIG (SVE), Univ. Université Rennes 1, France</p>
            </li>
            <li id="uid224">
              <p noindent="true">"Algorithmes pour les Séquences et les Structures", 12h, M2 BIG (SVE), Université Rennes 1, France</p>
            </li>
          </sanspuceslist>
          <p>Franck Multon</p>
          <sanspuceslist>
            <li id="uid225">
              <p noindent="true">"Images et Mouvement - IMO", leader of the module, 20h, Master 2 research in computer sciences, University Rennes1, France</p>
            </li>
            <li id="uid226">
              <p noindent="true">"Santé et Performance au Travail : étude de cas", leader of the module, 30h, Master 1 M2S, University Rennes2, France</p>
            </li>
            <li id="uid227">
              <p noindent="true">"Analyse Biomécanique de la Performance Motrice", leader of the module, 30h, Master 1 M2S, University Rennes2, France</p>
            </li>
            <li id="uid228">
              <p noindent="true">"Modélisation et Simulation du Mouvement", leader of the module, 30h, Master 2 M2S, University Rennes2, France</p>
            </li>
            <li id="uid229">
              <p noindent="true">"Connaissances neurophysiologiques et biomécaniques", Mastere "Excellence Operationnelle", INSA Rennes, France</p>
            </li>
          </sanspuceslist>
          <p>Anne-Hélène Olivier</p>
          <sanspuceslist>
            <li id="uid230">
              <p noindent="true">"Biostatstiques", 18h, Master 2 M2S, University Rennes2, France</p>
            </li>
            <li id="uid231">
              <p noindent="true">"Biostatstiques", 16h, Master 1 2SEP, École Normale Supérieure de Rennes, France</p>
            </li>
            <li id="uid232">
              <p noindent="true">"Contrôle moteur : loi de contrôle de la locomotion", 3h30, Master 1 M2S, Université Rennes 2, France</p>
            </li>
            <li id="uid233">
              <p noindent="true">"Contrôle moteur : Boucle perceptivo-motrice", 3h30, Master 1 M2S, Université Rennes 2, France</p>
            </li>
            <li id="uid234">
              <p noindent="true">"Analyse Biomécanique de la Performance Motrice", 15h, Master 1 M2S, University Rennes2, France</p>
            </li>
          </sanspuceslist>
          <p>Charles Pontonnier</p>
          <sanspuceslist>
            <li id="uid235">
              <p noindent="true">"Numerical methods", leader of the module, Mechanics, École Spéciale Militaire de Saint-Cyr Coëtquidan, France</p>
            </li>
            <li id="uid236">
              <p noindent="true">"Numerical simulation of mechanical systems", leader of the module, Mechanics, École Spéciale Militaire de Saint-Cyr Coëtquidan, France</p>
            </li>
            <li id="uid237">
              <p noindent="true">"Analytical Mechanics" , Mechanics, École Spéciale Militaire de Saint-Cyr Coëtquidan, France</p>
            </li>
            <li id="uid238">
              <p noindent="true">"Design and control of legged robots", leader of the module, Electronics, École Spéciale Militaire de Saint-Cyr Coëtquidan, France</p>
            </li>
            <li id="uid239">
              <p noindent="true">"Design, simulation and control of mechanical systems", leader of the module, Lecturers training in mechatronics, École Normale Supérieure de Rennes, France</p>
            </li>
            <li id="uid240">
              <p noindent="true">"Musculoskeletal modeling and ergonomics", 30h, Master 1 M2S, University Rennes2, France</p>
            </li>
          </sanspuceslist>
        </subsection>
        <subsection id="uid241" level="3">
          <bodyTitle>License level</bodyTitle>
          <p>Marc Christie</p>
          <sanspuceslist>
            <li id="uid242">
              <p noindent="true">"Programmation Impérative 1", leader of the module, University of Rennes 1, France</p>
            </li>
          </sanspuceslist>
          <p>Armel Crétual</p>
          <sanspuceslist>
            <li id="uid243">
              <p noindent="true">"Analyse cinématique du mouvement", 100h, Licence 1, University Rennes 2, France</p>
            </li>
          </sanspuceslist>
          <p>Richard Kulpa</p>
          <sanspuceslist>
            <li id="uid244">
              <p noindent="true">"Biomécanique (dynamique en translation et rotation)", 48h, Licence 2, Université Rennes 2, France</p>
            </li>
            <li id="uid245">
              <p noindent="true">"Méthodes numériques d'analyse du geste", 48h, Licence 3, Université Rennes 2, France</p>
            </li>
            <li id="uid246">
              <p noindent="true">"Statistiques et informatique", 15h, Licence 3, Université Rennes 2, France</p>
            </li>
          </sanspuceslist>
          <p>Ronan Gaugne</p>
          <sanspuceslist>
            <li id="uid247">
              <p noindent="true">"VR projects", 10h, L3, INSA Rennes, France</p>
            </li>
          </sanspuceslist>
          <p>Fabrice Lamarche</p>
          <sanspuceslist>
            <li id="uid248">
              <p noindent="true">"Initiation à l'algorithmique et à la programmation", 56h, License 3, ESIR, University of Rennes 1, France</p>
            </li>
            <li id="uid249">
              <p noindent="true">"Programmation en C++", 46h, License 3, ESIR, University of Rennes 1, France</p>
            </li>
            <li id="uid250">
              <p noindent="true">"IMA", 24h, License 3, ENS Rennes, ISTIC, University of Rennes 1, France</p>
            </li>
          </sanspuceslist>
          <p>Antonio Mucherino</p>
          <sanspuceslist>
            <li id="uid251">
              <p noindent="true">"Programmation Impérative 1", 80h, L1, Université Rennes 1, France</p>
            </li>
          </sanspuceslist>
          <p>Franck Multon</p>
          <sanspuceslist>
            <li id="uid252">
              <p noindent="true">"Ergonomie du poste de travail", Licence STAPS L2 &amp; L3, University Rennes2, France</p>
            </li>
          </sanspuceslist>
          <p>Anne-Hélène Olivier</p>
          <sanspuceslist>
            <li id="uid253">
              <p noindent="true">"Analyse cinématique du mouvement", 100h , Licence 1, University Rennes 2, France</p>
            </li>
            <li id="uid254">
              <p noindent="true">"Anatomie fonctionnelle", 8h , Licence 2, University Rennes 2, France</p>
            </li>
            <li id="uid255">
              <p noindent="true">"Effort et efficience", 12h , Licence 2, University Rennes 2, France</p>
            </li>
            <li id="uid256">
              <p noindent="true">"Locomotion et handicap", 12h , Licence 3, University Rennes 2, France</p>
            </li>
            <li id="uid257">
              <p noindent="true">"Biomécanique du viellissement", 12h , Licence 3, University Rennes 2, France</p>
            </li>
          </sanspuceslist>
          <p>Charles Pontonnier</p>
          <sanspuceslist>
            <li id="uid258">
              <p noindent="true">"Numerical control", leader of the module, Electronics, École Inter-Armes de Saint-Cyr Coëtquidan, France</p>
            </li>
          </sanspuceslist>
        </subsection>
      </subsection>
      <subsection id="uid259" level="2">
        <bodyTitle>Supervision</bodyTitle>
        <subsection id="uid260" level="3">
          <bodyTitle>PhD (defended)</bodyTitle>
          <sanspuceslist>
            <li id="uid261">
              <p noindent="true">Julien Bruneau, Studying and modeling complex interactions for crowd simulation, University Rennes 1, defended in Nov. 2016, Julien Pettré (Lagadic) &amp; Anne-Hélène Olivier</p>
            </li>
            <li id="uid262">
              <p noindent="true">Ana Lucia Cruz Ruiz, Low-Dimensional Control Representations for Muscle-Based Characters: Application to Overhead Throwing, ENS Rennes, defended in Dec. 2016, Georges Dumont &amp; Charles Pontonnier</p>
            </li>
            <li id="uid263">
              <p noindent="true">Pierre Plantard, Estimation des efforts musculaires à partir de données in situ pour l’évaluation ergonomique d’un poste de travail, defended in July 2016, Franck Multon &amp; Anne-Sophie LePierres</p>
            </li>
            <li id="uid264">
              <p noindent="true">Cunka Sanokho, Data-driven Virtual Cinematography, University Rennes1, defended in Feb. 2016, Marc Christie</p>
            </li>
            <li id="uid265">
              <p noindent="true">Hui-yin Wu, Cinematic discourse for Interactive 3D Storytelling, University Rennes1, defended in Oct. 2016, Marc Christie</p>
            </li>
          </sanspuceslist>
        </subsection>
        <subsection id="uid266" level="3">
          <bodyTitle>PhD (in progress)</bodyTitle>
          <sanspuceslist>
            <li id="uid267">
              <p noindent="true">Yacine Bouhalia, Approche transversale pour l’analyse et la reconnaissance de gestes 2D et 3D, INSA of Rennes, September 2015, Richard Kulpa &amp; Franck Multon &amp; Eric Anquetil</p>
            </li>
            <li id="uid268">
              <p noindent="true">Charles Faure, Stratégies coopératives et compétitives dans des tâches d'interactions physiques multiples, Université Rennes 2, September 2016, Benoit Bideau &amp; Richard Kulpa</p>
            </li>
            <li id="uid269">
              <p noindent="true">Florence Gaillard, Evaluation en situation écologique des capacités fonctionnelles des membres supérieurs d’enfants hémiplégiques, University Rennes 2, December 2015, Armel Crétual &amp; Isabelle Bonan</p>
            </li>
            <li id="uid270">
              <p noindent="true">Karim Jamal, Les effets des stimulations sensorielles par vibration sur les perturbations posturales secondaires à des troubles de la cognition spatiale après un Accident vasculaire Cérébrale, University Rennes 2, September 2016, Isabelle Bonan &amp; Armel Crétual</p>
            </li>
            <li id="uid271">
              <p noindent="true">Sean D. Lynch, Perception visuelle du mouvement humain dans les interactions lors de tâches locomotrices, M2S - University Rennes 2, September 2015, Anne-Hélène Olivier &amp; Richard Kulpa</p>
            </li>
            <li id="uid272">
              <p noindent="true">Marion Morel, Suivi et étude des interactions pour l'analyse des tactiques durant un match de basket-ball, UPMC - University Rennes 2, September 2014, Catherine Achard &amp; Séverine Dubuisson &amp; Richard Kulpa</p>
            </li>
            <li id="uid273">
              <p noindent="true">Antoine Muller, Design of a modular and multiscale musculoskeletal library as a support to motion analysis-synthesis, Ecole normale supérieure, September 2014, Georges Dumont &amp; Charles Pontonnier</p>
            </li>
            <li id="uid274">
              <p noindent="true">Camille Pouliquen, Optimization of musculoskeletal models during the sporting gesture: Cycling application, University Rennes 2, September 2013, Paul Delamarche &amp; Nicolas Bideau</p>
            </li>
            <li id="uid275">
              <p noindent="true">Pierre Touzard, Suivi longitudinal du service de jeunes joueurs de tennis élite : identification biomécanique des facteurs de performance et de risque de blessures, University Rennes 2, September 2014, Benoit Bideau &amp; Richard Kulpa &amp; Caroline Martin</p>
            </li>
          </sanspuceslist>
        </subsection>
      </subsection>
      <subsection id="uid276" level="2">
        <bodyTitle>Juries</bodyTitle>
        <sanspuceslist>
          <li id="uid277">
            <p noindent="true">PhD: Deep Seth, Contribution to the evaluation of muscle fatigue model and recovery model, Centrale Nantes, Rapporteur Franck Multon</p>
          </li>
          <li id="uid278">
            <p noindent="true">PhD: Pamela Carreno Medrano, Analysis and Synthesis of Expressive Theatrical Movements, Université Bretagne Sud, Rapporteur Franck Multon</p>
          </li>
        </sanspuceslist>
      </subsection>
    </subsection>
    <subsection id="uid279" level="1">
      <bodyTitle>Popularization</bodyTitle>
      <sanspuceslist>
        <li id="uid280">
          <p noindent="true">Franck Multon managed a 4 days Booth to present ergonomic work in MIDEST in Paris, with a plenary session conference about penibility at work, MIDEST December 2016</p>
        </li>
        <li id="uid281">
          <p noindent="true">Franck Multon and Richard Kulpa managed a 2 days Inria Booth to present VR and Sports in Futur en Seine in Paris, June 2016</p>
        </li>
        <li id="uid282">
          <p noindent="true">Ludovic Hoyet, Journées Scientifiques Inria 2016, exposé court en 180s, “Perceptual Effect of Shoulder Motions on Crowd Animations”.</p>
        </li>
        <li id="uid283">
          <p noindent="true">Ludovic Hoyet, Press conference, « Six-Finger Illusion : pour mieux comprendre la perception de notre corps et de notre avatar ». With Ferran Argelaguet and Anatole Lécuyer, Inria, Paris, 12 May 2016, <ref xlink:href="https://www.inria.fr/centre/rennes/actualites/six-finger-illusion" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>www.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>centre/<allowbreak/>rennes/<allowbreak/>actualites/<allowbreak/>six-finger-illusion</ref></p>
        </li>
      </sanspuceslist>
    </subsection>
  </diffusion>
  <biblio id="bibliography" html="bibliography" numero="10" titre="Bibliography">
    
    <biblStruct id="mimetic-2016-bid24" type="proceedings" rend="year" n="cite:ronfard:hal-01427243">
      <identifiant type="hal" value="hal-01427243"/>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes">
        <title level="m">Eurographics Workshop on Intelligent Cinematography and Editing</title>
        <title level="s">Eurographics Workshop on Intelligent Cinematography and Editing</title>
        <editor role="editor">
          <persName>
            <foreName>The Eurographics</foreName>
            <surname>Association</surname>
            <initial>T. E.</initial>
          </persName>
        </editor>
        <imprint>
          <publisher>
            <orgName type="organisation">The Eurographics Association<address><addrLine>Lisbonne, Portugal</addrLine></address></orgName>
          </publisher>
          <dateStruct>
            <month>May</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01427243" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01427243</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid27" type="phdthesis" rend="year" n="cite:wolinski:tel-01420105">
      <identifiant type="hal" value="tel-01420105"/>
      <monogr>
        <title level="m">Microscopic crowd simulation : evaluation and development of algorithms</title>
        <author>
          <persName key="mimetic-2014-idp109304">
            <foreName>David</foreName>
            <surname>Wolinski</surname>
            <initial>D.</initial>
          </persName>
        </author>
        <imprint>
          <publisher>
            <orgName type="school">Université Rennes 1</orgName>
          </publisher>
          <dateStruct>
            <month>January</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://tel.archives-ouvertes.fr/tel-01420105" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>tel.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>tel-01420105</ref>
        </imprint>
      </monogr>
      <note type="typdoc">Theses</note>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid5" type="article" rend="year" n="cite:auvinet:hal-01359845">
      <identifiant type="doi" value="10.1016/j.gaitpost.2016.08.022"/>
      <identifiant type="hal" value="hal-01359845"/>
      <analytic>
        <title level="a">Validity and sensitivity of the Longitudinal Asymmetry Index to detect gait asymmetry using Microsoft Kinect data</title>
        <author>
          <persName>
            <foreName>Edouard</foreName>
            <surname>Auvinet</surname>
            <initial>E.</initial>
          </persName>
          <persName key="mimetic-2014-idm27032">
            <foreName>Franck</foreName>
            <surname>Multon</surname>
            <initial>F.</initial>
          </persName>
          <persName>
            <foreName>Victoria</foreName>
            <surname>Manning</surname>
            <initial>V.</initial>
          </persName>
          <persName>
            <foreName>Jean</foreName>
            <surname>Meunier</surname>
            <initial>J.</initial>
          </persName>
          <persName>
            <foreName>Justin P.</foreName>
            <surname>Cobb</surname>
            <initial>J. P.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00624">
        <idno type="issn">0966-6362</idno>
        <title level="j">Gait and Posture</title>
        <imprint>
          <biblScope type="volume">51</biblScope>
          <dateStruct>
            <year>2017</year>
          </dateStruct>
          <biblScope type="pages">17</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01359845" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01359845</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid17" type="article" rend="year" n="cite:billinge:hal-01401745">
      <identifiant type="hal" value="hal-01401745"/>
      <analytic>
        <title level="a">Assigned and Unassigned Distance Geometry: Applications to Biological Molecules and Nanostructures</title>
        <author>
          <persName>
            <foreName>Simon J.L.</foreName>
            <surname>Billinge</surname>
            <initial>S. J.</initial>
          </persName>
          <persName>
            <foreName>Philip M.</foreName>
            <surname>Duxbury</surname>
            <initial>P. M.</initial>
          </persName>
          <persName key="genscale-2014-idp70360">
            <foreName>Douglas S.</foreName>
            <surname>Gonçalves</surname>
            <initial>D. S.</initial>
          </persName>
          <persName>
            <foreName>Carlile</foreName>
            <surname>Lavor</surname>
            <initial>C.</initial>
          </persName>
          <persName key="genscale-2014-idp67832">
            <foreName>Antonio</foreName>
            <surname>Mucherino</surname>
            <initial>A.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00001">
        <idno type="issn">1619-4500</idno>
        <title level="j">Quarterly Journal of Operations Research</title>
        <imprint>
          <biblScope type="volume">14</biblScope>
          <biblScope type="number">4</biblScope>
          <dateStruct>
            <month>December</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">337–376</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01401745" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01401745</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid30" type="article" rend="year" n="cite:bruder:hal-01388499">
      <identifiant type="doi" value="10.1162/PRES_a_00241"/>
      <identifiant type="hal" value="hal-01388499"/>
      <analytic>
        <title level="a">CAVE Size Matters: Effects of Screen Distance and Parallax on Distance Estimation in Large Immersive Display Setups</title>
        <author>
          <persName key="hybrid-2014-idp81336">
            <foreName>Gerd</foreName>
            <surname>Bruder</surname>
            <initial>G.</initial>
          </persName>
          <persName>
            <foreName>Ferran</foreName>
            <surname>Argelaguet</surname>
            <initial>F.</initial>
          </persName>
          <persName key="mimetic-2014-idp77968">
            <foreName>Anne-Héléne</foreName>
            <surname>Olivier</surname>
            <initial>A.-H.</initial>
          </persName>
          <persName key="hybrid-2014-idm28656">
            <foreName>Anatole</foreName>
            <surname>Lécuyer</surname>
            <initial>A.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid01604">
        <idno type="issn">1054-7460</idno>
        <title level="j">Presence: Teleoperators and Virtual Environments</title>
        <imprint>
          <biblScope type="volume">25</biblScope>
          <biblScope type="number">1</biblScope>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">1 - 16</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01388499" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01388499</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid12" type="article" rend="year" n="cite:cruzruiz:hal-01377058">
      <identifiant type="hal" value="hal-01377058"/>
      <analytic>
        <title level="a">A Synergy-Based Control Solution for Overactuated Characters: Application to Throwing</title>
        <author>
          <persName key="mimetic-2014-idp98224">
            <foreName>Ana Lucia</foreName>
            <surname>Cruz Ruiz</surname>
            <initial>A. L.</initial>
          </persName>
          <persName key="mimetic-2014-idp79256">
            <foreName>Charles</foreName>
            <surname>Pontonnier</surname>
            <initial>C.</initial>
          </persName>
          <persName key="mimetic-2015-idp110408">
            <foreName>Jonathan</foreName>
            <surname>Levy</surname>
            <initial>J.</initial>
          </persName>
          <persName key="mimetic-2014-idp71256">
            <foreName>Georges</foreName>
            <surname>Dumont</surname>
            <initial>G.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00388">
        <idno type="issn">1546-4261</idno>
        <title level="j">Computer Animation and Virtual Worlds</title>
        <imprint>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01377058" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01377058</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid1" type="article" rend="year" n="cite:cruzruiz:hal-01317881">
      <identifiant type="hal" value="hal-01317881"/>
      <analytic>
        <title level="a">Muscle-Based Control For Character Animation</title>
        <author>
          <persName key="mimetic-2014-idp98224">
            <foreName>Ana Lucia</foreName>
            <surname>Cruz Ruiz</surname>
            <initial>A. L.</initial>
          </persName>
          <persName key="mimetic-2014-idp79256">
            <foreName>Charles</foreName>
            <surname>Pontonnier</surname>
            <initial>C.</initial>
          </persName>
          <persName>
            <foreName>Nicolas</foreName>
            <surname>Pronost</surname>
            <initial>N.</initial>
          </persName>
          <persName key="mimetic-2014-idp71256">
            <foreName>Georges</foreName>
            <surname>Dumont</surname>
            <initial>G.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00391">
        <idno type="issn">0167-7055</idno>
        <title level="j">Computer Graphics Forum</title>
        <imprint>
          <dateStruct>
            <month>May</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01317881" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01317881</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid16" type="article" rend="year" n="cite:goncalves:hal-01402366">
      <identifiant type="doi" value="10.1111/itor.12249"/>
      <identifiant type="hal" value="hal-01402366"/>
      <analytic>
        <title level="a">Optimal Partial Discretization Orders for Discretizable Distance Geometry</title>
        <author>
          <persName key="genscale-2014-idp70360">
            <foreName>Douglas S.</foreName>
            <surname>Gonçalves</surname>
            <initial>D. S.</initial>
          </persName>
          <persName key="genscale-2014-idp67832">
            <foreName>Antonio</foreName>
            <surname>Mucherino</surname>
            <initial>A.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid02361">
        <idno type="issn">0969-6016</idno>
        <title level="j">International Transactions in Operational Research</title>
        <imprint>
          <biblScope type="volume">23</biblScope>
          <biblScope type="number">5</biblScope>
          <dateStruct>
            <month>September</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">947–967</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01402366" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01402366</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid29" type="article" rend="year" n="cite:goncalves:hal-01429540">
      <identifiant type="hal" value="hal-01429540"/>
      <analytic>
        <title level="a">Recent Advances on the Interval Distance Geometry</title>
        <author>
          <persName key="genscale-2014-idp70360">
            <foreName>Douglas S.</foreName>
            <surname>Gonçalves</surname>
            <initial>D. S.</initial>
          </persName>
          <persName key="genscale-2014-idp67832">
            <foreName>Antonio</foreName>
            <surname>Mucherino</surname>
            <initial>A.</initial>
          </persName>
          <persName>
            <foreName>Carlile</foreName>
            <surname>Lavor</surname>
            <initial>C.</initial>
          </persName>
          <persName>
            <foreName>Leo</foreName>
            <surname>Liberti</surname>
            <initial>L.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid01151">
        <idno type="issn">0925-5001</idno>
        <title level="j">Journal of Global Optimization</title>
        <imprint>
          <dateStruct>
            <month>January</month>
            <year>2017</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01429540" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01429540</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid3" type="article" rend="year" n="cite:hoyet:hal-01334359">
      <identifiant type="doi" value="10.3389/frobt.2016.00027"/>
      <identifiant type="hal" value="hal-01334359"/>
      <analytic>
        <title level="a">"Wow! I Have Six Fingers!": Would You Accept Structural Changes of Your Hand in VR?</title>
        <author>
          <persName key="mimetic-2015-idm26392">
            <foreName>Ludovic</foreName>
            <surname>Hoyet</surname>
            <initial>L.</initial>
          </persName>
          <persName>
            <foreName>Ferran</foreName>
            <surname>Argelaguet</surname>
            <initial>F.</initial>
          </persName>
          <persName>
            <foreName>Corentin</foreName>
            <surname>Nicole</surname>
            <initial>C.</initial>
          </persName>
          <persName key="hybrid-2014-idm28656">
            <foreName>Anatole</foreName>
            <surname>Lécuyer</surname>
            <initial>A.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid02833">
        <idno type="issn">2296-9144</idno>
        <title level="j">Frontiers in Robotics and AI</title>
        <imprint>
          <biblScope type="volume">3</biblScope>
          <biblScope type="number">27</biblScope>
          <dateStruct>
            <month>March</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01334359" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01334359</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid2" type="article" rend="year" n="cite:hoyet:hal-01357713">
      <identifiant type="doi" value="10.1145/2897824.2925931"/>
      <identifiant type="hal" value="hal-01357713"/>
      <analytic>
        <title level="a">Perceptual Effect of Shoulder Motions on Crowd Animations</title>
        <author>
          <persName key="mimetic-2015-idm26392">
            <foreName>Ludovic</foreName>
            <surname>Hoyet</surname>
            <initial>L.</initial>
          </persName>
          <persName key="mimetic-2014-idp77968">
            <foreName>Anne-Hélène</foreName>
            <surname>Olivier</surname>
            <initial>A.-H.</initial>
          </persName>
          <persName key="mimetic-2014-idp73992">
            <foreName>Richard</foreName>
            <surname>Kulpa</surname>
            <initial>R.</initial>
          </persName>
          <persName key="mimetic-2014-idm25552">
            <foreName>Julien</foreName>
            <surname>Pettré</surname>
            <initial>J.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00024">
        <idno type="issn">0730-0301</idno>
        <title level="j">ACM Transactions on Graphics</title>
        <imprint>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01357713" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01357713</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid20" type="article" rend="year" n="cite:huang:hal-01413388">
      <identifiant type="doi" value="10.1111/cgf.13008"/>
      <identifiant type="hal" value="hal-01413388"/>
      <analytic>
        <title level="a">Trip Synopsis: 60km in 60sec</title>
        <author>
          <persName>
            <foreName>Hui</foreName>
            <surname>HUANG</surname>
            <initial>H.</initial>
          </persName>
          <persName>
            <foreName>Dani</foreName>
            <surname>Lischinski</surname>
            <initial>D.</initial>
          </persName>
          <persName>
            <foreName>Zhuming</foreName>
            <surname>Hao</surname>
            <initial>Z.</initial>
          </persName>
          <persName>
            <foreName>Minglun</foreName>
            <surname>Gong</surname>
            <initial>M.</initial>
          </persName>
          <persName key="mimetic-2014-idp68552">
            <foreName>Marc</foreName>
            <surname>Christie</surname>
            <initial>M.</initial>
          </persName>
          <persName>
            <foreName>Daniel</foreName>
            <surname>Cohen-Or</surname>
            <initial>D.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00391">
        <idno type="issn">0167-7055</idno>
        <title level="j">Computer Graphics Forum</title>
        <imprint>
          <biblScope type="volume">35</biblScope>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">107 - 116</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01413388" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01413388</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid8" type="article" rend="year" n="cite:martin:hal-01397596">
      <identifiant type="doi" value="10.1371/journal.pone.0159979"/>
      <identifiant type="hal" value="hal-01397596"/>
      <analytic>
        <title level="a">Influence of a Prolonged Tennis Match Play on Serve Biomechanics</title>
        <author>
          <persName>
            <foreName>Caroline</foreName>
            <surname>Martin</surname>
            <initial>C.</initial>
          </persName>
          <persName key="mimetic-2014-idp65960">
            <foreName>Benoit</foreName>
            <surname>Bideau</surname>
            <initial>B.</initial>
          </persName>
          <persName>
            <foreName>Paul</foreName>
            <surname>Delamarche</surname>
            <initial>P.</initial>
          </persName>
          <persName key="mimetic-2014-idp73992">
            <foreName>Richard</foreName>
            <surname>Kulpa</surname>
            <initial>R.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid01553">
        <idno type="issn">1932-6203</idno>
        <title level="j">PLoS ONE</title>
        <imprint>
          <biblScope type="volume">11</biblScope>
          <biblScope type="number">8</biblScope>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal-univ-rennes1.archives-ouvertes.fr/hal-01397596" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal-univ-rennes1.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01397596</ref>
        </imprint>
      </monogr>
      <note type="bnote">e0159979</note>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid9" type="article" rend="year" n="cite:martin:hal-01397597">
      <identifiant type="doi" value="10.1177/0363546516645542"/>
      <identifiant type="hal" value="hal-01397597"/>
      <analytic>
        <title level="a">Influence of Playing a Prolonged Tennis Match on Shoulder Internal Range of Motion</title>
        <author>
          <persName>
            <foreName>Caroline</foreName>
            <surname>Martin</surname>
            <initial>C.</initial>
          </persName>
          <persName key="mimetic-2014-idp73992">
            <foreName>Richard</foreName>
            <surname>Kulpa</surname>
            <initial>R.</initial>
          </persName>
          <persName>
            <foreName>Felix</foreName>
            <surname>Ezanno</surname>
            <initial>F.</initial>
          </persName>
          <persName>
            <foreName>Paul</foreName>
            <surname>Delamarche</surname>
            <initial>P.</initial>
          </persName>
          <persName key="mimetic-2014-idp65960">
            <foreName>Benoit</foreName>
            <surname>Bideau</surname>
            <initial>B.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid03133">
        <idno type="issn">0363-5465</idno>
        <title level="j">American Journal of Sports Medicine</title>
        <imprint>
          <biblScope type="volume">44</biblScope>
          <biblScope type="number">8</biblScope>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">2147–2151</biblScope>
          <ref xlink:href="https://hal-univ-rennes1.archives-ouvertes.fr/hal-01397597" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal-univ-rennes1.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01397597</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid19" type="article" rend="year" n="cite:nguyen:hal-01381243">
      <identifiant type="hal" value="hal-01381243"/>
      <analytic>
        <title level="a">VR-based Operating Modes and Metaphors for Collaborative Ergonomic Design of Industrial Workstations</title>
        <author>
          <persName>
            <foreName>Huyen</foreName>
            <surname>Nguyen</surname>
            <initial>H.</initial>
          </persName>
          <persName key="mimetic-2014-idp79256">
            <foreName>Charles</foreName>
            <surname>Pontonnier</surname>
            <initial>C.</initial>
          </persName>
          <persName key="mimetic-2014-idp114328">
            <foreName>Simon</foreName>
            <surname>Hilt</surname>
            <initial>S.</initial>
          </persName>
          <persName key="hybrid-2014-idp90000">
            <foreName>Thierry</foreName>
            <surname>Duval</surname>
            <initial>T.</initial>
          </persName>
          <persName key="mimetic-2014-idp71256">
            <foreName>Georges</foreName>
            <surname>Dumont</surname>
            <initial>G.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid01312">
        <idno type="issn">1783-7677</idno>
        <title level="j">Journal on Multimodal User Interfaces</title>
        <imprint>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01381243" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01381243</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid0" type="article" rend="year" n="cite:plantard:hal-01393066">
      <identifiant type="doi" value="10.1016/j.apergo.2016.10.015"/>
      <identifiant type="hal" value="hal-01393066"/>
      <analytic>
        <title level="a">Validation of an ergonomic assessment method using Kinect data in real workplace conditions</title>
        <author>
          <persName key="mimetic-2014-idp104376">
            <foreName>Pierre</foreName>
            <surname>Plantard</surname>
            <initial>P.</initial>
          </persName>
          <persName>
            <foreName>Hubert P H</foreName>
            <surname>Shum</surname>
            <initial>H. P. H.</initial>
          </persName>
          <persName>
            <foreName>Anne-Sophie</foreName>
            <surname>Le Pierres</surname>
            <initial>A.-S.</initial>
          </persName>
          <persName key="mimetic-2014-idm27032">
            <foreName>Franck</foreName>
            <surname>Multon</surname>
            <initial>F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00159">
        <idno type="issn">0003-6870</idno>
        <title level="j">Applied Ergonomics</title>
        <imprint>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01393066" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01393066</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid6" type="article" rend="year" n="cite:plantard:hal-01332711">
      <identifiant type="doi" value="10.1007/s11042-016-3546-4"/>
      <identifiant type="hal" value="hal-01332711"/>
      <analytic>
        <title level="a">Filtered Pose Graph for Efficient Kinect Pose Reconstruction</title>
        <author>
          <persName key="mimetic-2014-idp104376">
            <foreName>Pierre</foreName>
            <surname>Plantard</surname>
            <initial>P.</initial>
          </persName>
          <persName>
            <foreName>Hubert</foreName>
            <surname>Shum</surname>
            <initial>H.</initial>
          </persName>
          <persName key="mimetic-2014-idm27032">
            <foreName>Franck</foreName>
            <surname>Multon</surname>
            <initial>F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid01453">
        <idno type="issn">1380-7501</idno>
        <title level="j">Multimedia Tools and Applications</title>
        <imprint>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">24</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01332711" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01332711</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid31" type="article" rend="year" n="cite:ropars:hal-01239752">
      <identifiant type="doi" value="10.1007/s00167-015-3621-9"/>
      <identifiant type="hal" value="hal-01239752"/>
      <analytic>
        <title level="a">Diagnosis and treatment of anteroinferior capsular redundancy associated with anterior shoulder instability using an open Latarjet procedure and capsulorrhaphy</title>
        <author>
          <persName>
            <foreName>Mickaël</foreName>
            <surname>Ropars</surname>
            <initial>M.</initial>
          </persName>
          <persName key="mimetic-2014-idp69792">
            <foreName>Armel</foreName>
            <surname>Crétual</surname>
            <initial>A.</initial>
          </persName>
          <persName>
            <foreName>Rajiv</foreName>
            <surname>Kaila</surname>
            <initial>R.</initial>
          </persName>
          <persName key="visages-2014-idp131872">
            <foreName>Isabelle</foreName>
            <surname>Bonan</surname>
            <initial>I.</initial>
          </persName>
          <persName>
            <foreName>Hervé</foreName>
            <surname>Anthony</surname>
            <initial>H.</initial>
          </persName>
          <persName>
            <foreName>Hervé</foreName>
            <surname>Thomazeau</surname>
            <initial>H.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid02835">
        <idno type="issn">0942-2056</idno>
        <title level="j">Knee Surgery, Sports Traumatology, Arthroscopy</title>
        <imprint>
          <biblScope type="volume">24</biblScope>
          <biblScope type="number">12</biblScope>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">3756–3764</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01239752" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01239752</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid11" type="article" rend="year" n="cite:vassallo:hal-01371202">
      <identifiant type="hal" value="hal-01371202"/>
      <analytic>
        <title level="a">How do walkers avoid a mobile robot crossing their way?</title>
        <author>
          <persName>
            <foreName>Christian</foreName>
            <surname>Vassallo</surname>
            <initial>C.</initial>
          </persName>
          <persName key="mimetic-2014-idp77968">
            <foreName>Anne-Hélène</foreName>
            <surname>Olivier</surname>
            <initial>A.-H.</initial>
          </persName>
          <persName>
            <foreName>Philippe</foreName>
            <surname>Souères</surname>
            <initial>P.</initial>
          </persName>
          <persName key="mimetic-2014-idp69792">
            <foreName>Armel</foreName>
            <surname>Crétual</surname>
            <initial>A.</initial>
          </persName>
          <persName>
            <foreName>Olivier</foreName>
            <surname>Stasse</surname>
            <initial>O.</initial>
          </persName>
          <persName key="mimetic-2014-idm25552">
            <foreName>Julien</foreName>
            <surname>Pettré</surname>
            <initial>J.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00624">
        <idno type="issn">0966-6362</idno>
        <title level="j">Gait and Posture</title>
        <imprint>
          <biblScope type="volume">51</biblScope>
          <dateStruct>
            <month>January</month>
            <year>2017</year>
          </dateStruct>
          <biblScope type="pages">97-103</biblScope>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01371202" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01371202</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid4" type="inproceedings" rend="year" n="cite:argelaguet:hal-01346229">
      <identifiant type="doi" value="10.1109/VR.2016.7504682"/>
      <identifiant type="hal" value="hal-01346229"/>
      <analytic>
        <title level="a">The role of interaction in virtual embodiment: Effects of the virtual hand representation</title>
        <author>
          <persName>
            <foreName>Ferran</foreName>
            <surname>Argelaguet</surname>
            <initial>F.</initial>
          </persName>
          <persName key="mimetic-2015-idm26392">
            <foreName>Ludovic</foreName>
            <surname>Hoyet</surname>
            <initial>L.</initial>
          </persName>
          <persName>
            <foreName>Michaël</foreName>
            <surname>Trico</surname>
            <initial>M.</initial>
          </persName>
          <persName key="hybrid-2014-idm28656">
            <foreName>Anatole</foreName>
            <surname>Lécuyer</surname>
            <initial>A.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">IEEE Virtual Reality</title>
        <loc>Greenville, United States</loc>
        <imprint>
          <dateStruct>
            <month>March</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">3-10</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01346229" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01346229</ref>
        </imprint>
        <meeting id="cid86390">
          <title>IEEE International Conference on Virtual Reality</title>
          <num>2007</num>
          <abbr type="sigle">IEEE VR</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid18" type="inproceedings" rend="year" n="cite:boulahia:hal-01376113">
      <identifiant type="hal" value="hal-01376113"/>
      <analytic>
        <title level="a">HIF3D: Handwriting-Inspired Features for 3D Skeleton-Based Action Recognition</title>
        <author>
          <persName>
            <foreName>SAID YACINE</foreName>
            <surname>BOULAHIA</surname>
            <initial>S. Y.</initial>
          </persName>
          <persName>
            <foreName>Eric</foreName>
            <surname>Anquetil</surname>
            <initial>E.</initial>
          </persName>
          <persName key="mimetic-2014-idp73992">
            <foreName>Richard</foreName>
            <surname>Kulpa</surname>
            <initial>R.</initial>
          </persName>
          <persName key="mimetic-2014-idm27032">
            <foreName>Franck</foreName>
            <surname>Multon</surname>
            <initial>F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <editor role="editor">
          <persName>
            <foreName/>
            <surname>IEEE</surname>
            <initial/>
          </persName>
        </editor>
        <title level="m">23rd International Conference on Pattern Recognition (ICPR 2016)</title>
        <loc>Cancun, Mexico</loc>
        <imprint>
          <dateStruct>
            <month>December</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01376113" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01376113</ref>
        </imprint>
        <meeting id="cid295950">
          <title>International Conference on Pattern Recognition</title>
          <num>23</num>
          <abbr type="sigle">ICPR</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid14" type="inproceedings" rend="year" n="cite:haering:hal-01317876">
      <identifiant type="hal" value="hal-01317876"/>
      <analytic>
        <title level="a">Preliminary report on the effects of patient positioning and testing modes on elbow isokinetic measurement</title>
        <author>
          <persName key="mimetic-2015-idp102880">
            <foreName>Diane</foreName>
            <surname>Haering</surname>
            <initial>D.</initial>
          </persName>
          <persName key="mimetic-2014-idp79256">
            <foreName>Charles</foreName>
            <surname>Pontonnier</surname>
            <initial>C.</initial>
          </persName>
          <persName key="mimetic-2014-idp67352">
            <foreName>Nicolas</foreName>
            <surname>Bideau</surname>
            <initial>N.</initial>
          </persName>
          <persName key="mimetic-2014-idp76704">
            <foreName>Guillaume</foreName>
            <surname>Nicolas</surname>
            <initial>G.</initial>
          </persName>
          <persName key="mimetic-2014-idp71256">
            <foreName>Georges</foreName>
            <surname>Dumont</surname>
            <initial>G.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">22nd Congress of the European Society of Biomechanics</title>
        <loc>Lyon, France</loc>
        <title level="s">22nd Congress of the European Society of Biomechanics</title>
        <imprint>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01317876" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01317876</ref>
        </imprint>
        <meeting id="cid625484">
          <title>Congress of the European Society of Biomechanics</title>
          <num>22</num>
          <abbr type="sigle"/>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid10" type="inproceedings" rend="year" n="cite:morel:hal-01373822">
      <identifiant type="doi" value="10.5220/0005778505420551"/>
      <identifiant type="hal" value="hal-01373822"/>
      <analytic>
        <title level="a">Automatic and Generic Evaluation of Spatial and Temporal Errors in Sport Motions</title>
        <author>
          <persName key="mimetic-2016-idp209728">
            <foreName>Marion</foreName>
            <surname>Morel</surname>
            <initial>M.</initial>
          </persName>
          <persName key="mimetic-2014-idp73992">
            <foreName>Richard</foreName>
            <surname>Kulpa</surname>
            <initial>R.</initial>
          </persName>
          <persName key="mimetic-2014-idp85504">
            <foreName>Anthony</foreName>
            <surname>Sorel</surname>
            <initial>A.</initial>
          </persName>
          <persName>
            <foreName>Catherine</foreName>
            <surname>Achard</surname>
            <initial>C.</initial>
          </persName>
          <persName>
            <foreName>Séverine</foreName>
            <surname>Dubuisson</surname>
            <initial>S.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">11th International Conference on Computer Vision Theory and Applications (VISAPP 2016)</title>
        <loc>Rome, Italy</loc>
        <imprint>
          <dateStruct>
            <month>February</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">542-551</biblScope>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01373822" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01373822</ref>
        </imprint>
        <meeting id="cid117378">
          <title>International Conference on Computer Vision Theory and Applications</title>
          <num>11</num>
          <abbr type="sigle">VISAPP</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid13" type="inproceedings" rend="year" n="cite:muller:hal-01317865">
      <identifiant type="hal" value="hal-01317865"/>
      <analytic>
        <title level="a">Uncertainty spreading from kinematics to dynamics in multibody human models</title>
        <author>
          <persName key="mimetic-2014-idp103120">
            <foreName>Antoine</foreName>
            <surname>Muller</surname>
            <initial>A.</initial>
          </persName>
          <persName key="mimetic-2014-idp79256">
            <foreName>Charles</foreName>
            <surname>Pontonnier</surname>
            <initial>C.</initial>
          </persName>
          <persName key="mimetic-2014-idp71256">
            <foreName>Georges</foreName>
            <surname>Dumont</surname>
            <initial>G.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">22nd Congress of the European Society of Biomechanics</title>
        <loc>Lyon, France</loc>
        <title level="s">22nd Congress of the European Society of Biomechanics</title>
        <imprint>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01317865" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01317865</ref>
        </imprint>
        <meeting id="cid625484">
          <title>Congress of the European Society of Biomechanics</title>
          <num>22</num>
          <abbr type="sigle"/>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid26" type="inproceedings" rend="year" n="cite:park:hal-01290368">
      <identifiant type="doi" value="10.1145/2856400.2856405"/>
      <identifiant type="hal" value="hal-01290368"/>
      <analytic>
        <title level="a">Dynamically balanced and plausible trajectory planning for human-like characters</title>
        <author>
          <persName>
            <foreName>Chonhyon</foreName>
            <surname>Park</surname>
            <initial>C.</initial>
          </persName>
          <persName>
            <foreName>Jae Sung</foreName>
            <surname>Park</surname>
            <initial>J. S.</initial>
          </persName>
          <persName key="mimetic-2014-idp106864">
            <foreName>Steve</foreName>
            <surname>Tonneau</surname>
            <initial>S.</initial>
          </persName>
          <persName>
            <foreName>Nicolas</foreName>
            <surname>Mansard</surname>
            <initial>N.</initial>
          </persName>
          <persName key="mimetic-2014-idm27032">
            <foreName>Franck</foreName>
            <surname>Multon</surname>
            <initial>F.</initial>
          </persName>
          <persName key="mimetic-2014-idm25552">
            <foreName>Julien</foreName>
            <surname>Pettré</surname>
            <initial>J.</initial>
          </persName>
          <persName>
            <foreName>Dinesh</foreName>
            <surname>Manocha</surname>
            <initial>D.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">20th ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games</title>
        <loc>Redmond, United States</loc>
        <imprint>
          <publisher>
            <orgName type="organisation">ACM</orgName>
          </publisher>
          <dateStruct>
            <month>February</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">39-48</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01290368" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01290368</ref>
        </imprint>
        <meeting id="cid21691">
          <title>ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games</title>
          <num>20</num>
          <abbr type="sigle">I3D</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid7" type="inproceedings" rend="year" n="cite:plantard:hal-01332716">
      <identifiant type="hal" value="hal-01332716"/>
      <analytic>
        <title level="a">Ergonomics Measurements using Kinect with a Pose Correction Framework</title>
        <author>
          <persName key="mimetic-2014-idp104376">
            <foreName>Pierre</foreName>
            <surname>Plantard</surname>
            <initial>P.</initial>
          </persName>
          <persName>
            <foreName>Hubert</foreName>
            <surname>Shum</surname>
            <initial>H.</initial>
          </persName>
          <persName key="mimetic-2014-idm27032">
            <foreName>Franck</foreName>
            <surname>Multon</surname>
            <initial>F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">Digital Human Modeling</title>
        <loc>Montreal, Canada</loc>
        <imprint>
          <dateStruct>
            <month>June</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">8</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01332716" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01332716</ref>
        </imprint>
        <meeting id="cid624364">
          <title>International Conference on Digital Human Modeling and Applications in Health, Safety, Ergonomics and Risk Management</title>
          <num>7</num>
          <abbr type="sigle">DHM</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid15" type="inproceedings" rend="year" n="cite:pontonnier:hal-01317869">
      <identifiant type="hal" value="hal-01317869"/>
      <analytic>
        <title level="a">Identifying knee prosthesis characteristics during swing phase through optimization</title>
        <author>
          <persName key="mimetic-2014-idp79256">
            <foreName>Charles</foreName>
            <surname>Pontonnier</surname>
            <initial>C.</initial>
          </persName>
          <persName>
            <foreName>Coralie</foreName>
            <surname>Villa</surname>
            <initial>C.</initial>
          </persName>
          <persName>
            <foreName>Joseph</foreName>
            <surname>Bascou</surname>
            <initial>J.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">22nd Congress of the European Society of Biomechanics</title>
        <loc>Lyon, France</loc>
        <title level="s">22nd Congress of the European Society of Biomechanics</title>
        <imprint>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01317869" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01317869</ref>
        </imprint>
        <meeting id="cid625484">
          <title>Congress of the European Society of Biomechanics</title>
          <num>22</num>
          <abbr type="sigle"/>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid25" type="inproceedings" rend="year" n="cite:safa:hal-01391755">
      <identifiant type="hal" value="hal-01391755"/>
      <analytic>
        <title level="a">Digital and handcrafting processes applied to sound-studies of archaeological bone flutes</title>
        <author>
          <persName>
            <foreName>Etienne</foreName>
            <surname>Safa</surname>
            <initial>E.</initial>
          </persName>
          <persName key="hybrid-2014-idp87552">
            <foreName>Jean-Baptiste</foreName>
            <surname>Barreau</surname>
            <initial>J.-B.</initial>
          </persName>
          <persName key="hybrid-2016-idp152560">
            <foreName>Ronan</foreName>
            <surname>Gaugne</surname>
            <initial>R.</initial>
          </persName>
          <persName key="beagle-2014-idp97688">
            <foreName>Wandrille</foreName>
            <surname>Duchemin</surname>
            <initial>W.</initial>
          </persName>
          <persName>
            <foreName>Jean-Daniel</foreName>
            <surname>Talma</surname>
            <initial>J.-D.</initial>
          </persName>
          <persName key="hybrid-2014-idm25952">
            <foreName>Bruno</foreName>
            <surname>Arnaldi</surname>
            <initial>B.</initial>
          </persName>
          <persName key="mimetic-2014-idp71256">
            <foreName>Georges</foreName>
            <surname>Dumont</surname>
            <initial>G.</initial>
          </persName>
          <persName key="hybrid-2014-idp66240">
            <foreName>Valérie</foreName>
            <surname>Gouranton</surname>
            <initial>V.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">International Conference on Culturage Heritage, EuroMed</title>
        <loc>Nicosia, Cyprus</loc>
        <imprint>
          <biblScope type="volume">1</biblScope>
          <biblScope type="number">10058</biblScope>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">184-195</biblScope>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01391755" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01391755</ref>
        </imprint>
        <meeting id="cid624584">
          <title>International Conference on Cultural Heritage</title>
          <num>6</num>
          <abbr type="sigle">EuroMed</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid23" type="inproceedings" rend="year" n="cite:tonneau:hal-01207688">
      <identifiant type="hal" value="hal-01207688"/>
      <analytic>
        <title level="a">Character contact re-positioning under large environment deformation</title>
        <author>
          <persName key="mimetic-2014-idp106864">
            <foreName>Steve</foreName>
            <surname>Tonneau</surname>
            <initial>S.</initial>
          </persName>
          <persName>
            <foreName>Al-Ashqar</foreName>
            <surname>Rami</surname>
            <initial>A.-A.</initial>
          </persName>
          <persName key="mimetic-2014-idm25552">
            <foreName>Julien</foreName>
            <surname>Pettré</surname>
            <initial>J.</initial>
          </persName>
          <persName>
            <foreName>Taku</foreName>
            <surname>Komura</surname>
            <initial>T.</initial>
          </persName>
          <persName>
            <foreName>Nicolas</foreName>
            <surname>Mansard</surname>
            <initial>N.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="no" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">Eurographics</title>
        <loc>Lisbonne, Portugal</loc>
        <imprint>
          <publisher>
            <orgName type="organisation">eurographics</orgName>
          </publisher>
          <dateStruct>
            <month>May</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01207688" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01207688</ref>
        </imprint>
        <meeting id="cid29028">
          <title>Annual Conference of the European Association for Computer Graphics</title>
          <num>32</num>
          <abbr type="sigle">EUROGRAPHICS</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid22" type="inproceedings" rend="year" n="cite:wu:hal-01413407">
      <identifiant type="hal" value="hal-01413407"/>
      <analytic>
        <title level="a">Analysing Cinematography with Embedded Constrained Patterns</title>
        <author>
          <persName key="mimetic-2014-idp110528">
            <foreName>Hui-Yin</foreName>
            <surname>Wu</surname>
            <initial>H.-Y.</initial>
          </persName>
          <persName key="mimetic-2014-idp68552">
            <foreName>Marc</foreName>
            <surname>Christie</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">WICED - Eurographics Workshop on Intelligent Cinematography and Editing</title>
        <loc>Lisbon, Portugal</loc>
        <imprint>
          <dateStruct>
            <month>May</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01413407" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01413407</ref>
        </imprint>
        <meeting id="cid624141">
          <title>Foundations of Digital Games Workshop on Intelligent Cinematography and Editing</title>
          <num>2016</num>
          <abbr type="sigle">WICED</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid21" type="inproceedings" rend="year" n="cite:wu:hal-01413401">
      <identifiant type="hal" value="hal-01413401"/>
      <analytic>
        <title level="a">A Cognitive-Based Model of Flashbacks for Computational Narratives</title>
        <author>
          <persName>
            <foreName>hui-yin</foreName>
            <surname>Wu</surname>
            <initial>h.-y.</initial>
          </persName>
          <persName>
            <foreName>Michael</foreName>
            <surname>Young</surname>
            <initial>M.</initial>
          </persName>
          <persName key="mimetic-2014-idp68552">
            <foreName>Marc</foreName>
            <surname>Christie</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">Proceedings of Artificial Intelligence and Interactive Digital Entertainment 2016</title>
        <loc>San Francisco, United States</loc>
        <imprint>
          <dateStruct>
            <month>October</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01413401" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01413401</ref>
        </imprint>
        <meeting id="cid399812">
          <title>AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment</title>
          <num>12</num>
          <abbr type="sigle">AIIDE</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="mimetic-2016-bid28" type="unpublished" rend="year" n="cite:tonneau:hal-01267345">
      <identifiant type="doi" value="10.1177/ToBeAssigned"/>
      <identifiant type="hal" value="hal-01267345"/>
      <monogr>
        <title level="m">An efficient acyclic contact planner for multiped robots</title>
        <author>
          <persName key="mimetic-2014-idp106864">
            <foreName>Steve</foreName>
            <surname>Tonneau</surname>
            <initial>S.</initial>
          </persName>
          <persName>
            <foreName>Andrea</foreName>
            <surname>Del Prete</surname>
            <initial>A.</initial>
          </persName>
          <persName key="mimetic-2014-idm25552">
            <foreName>Julien</foreName>
            <surname>Pettré</surname>
            <initial>J.</initial>
          </persName>
          <persName>
            <foreName>Chonhyon</foreName>
            <surname>Park</surname>
            <initial>C.</initial>
          </persName>
          <persName>
            <foreName>Dinesh</foreName>
            <surname>Manocha</surname>
            <initial>D.</initial>
          </persName>
          <persName>
            <foreName>Nicolas</foreName>
            <surname>Mansard</surname>
            <initial>N.</initial>
          </persName>
        </author>
        <imprint>
          <dateStruct>
            <month>February</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01267345" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01267345</ref>
        </imprint>
      </monogr>
      <note type="bnote">working paper or preprint</note>
    </biblStruct>
  </biblio>
</raweb>
