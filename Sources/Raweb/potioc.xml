<?xml version="1.0" encoding="utf-8"?>
<raweb xmlns:xlink="http://www.w3.org/1999/xlink" xml:lang="en" year="2016">
  <identification id="potioc" isproject="true">
    <shortname>POTIOC</shortname>
    <projectName>Popular interaction</projectName>
    <theme-de-recherche>Interaction and visualization</theme-de-recherche>
    <domaine-de-recherche>Perception, Cognition and Interaction</domaine-de-recherche>
    <urlTeam>http://team.inria.fr/potioc</urlTeam>
    <structure_exterieure type="Organism">
      <libelle>CNRS</libelle>
    </structure_exterieure>
    <structure_exterieure type="Organism">
      <libelle>Université de Bordeaux</libelle>
    </structure_exterieure>
    <header_dates_team>Creation of the Team: 2012 January 01, updated into Project-Team: 2014 January 01</header_dates_team>
    <LeTypeProjet>Project-Team</LeTypeProjet>
    <keywordsSdN>
      <term>3.2.2. - Knowledge extraction, cleaning</term>
      <term>3.4.1. - Supervised learning</term>
      <term>5.1. - Human-Computer Interaction</term>
      <term>5.1.1. - Engineering of interactive systems</term>
      <term>5.1.2. - Evaluation of interactive systems</term>
      <term>5.1.4. - Brain-computer interfaces, physiological computing</term>
      <term>5.1.5. - Body-based interfaces</term>
      <term>5.1.6. - Tangible interfaces</term>
      <term>5.1.7. - Multimodal interfaces</term>
      <term>5.1.8. - 3D User Interfaces</term>
      <term>5.6. - Virtual reality, augmented reality</term>
      <term>5.9. - Signal processing</term>
      <term>5.9.2. - Estimation, modeling</term>
      <term>8.2. - Machine learning</term>
      <term>8.3. - Signal analysis</term>
    </keywordsSdN>
    <keywordsSecteurs>
      <term>1.3. - Neuroscience and cognitive science</term>
      <term>2.1. - Well being</term>
      <term>2.5.1. - Sensorimotor disabilities</term>
      <term>2.5.2. - Cognitive disabilities</term>
      <term>2.6.1. - Brain imaging</term>
      <term>5.2.4. - Aerospace</term>
      <term>9.1. - Education</term>
      <term>9.1.1. - E-learning, MOOC</term>
      <term>9.2. - Art</term>
      <term>9.2.1. - Music, sound</term>
      <term>9.4.3. - Physics</term>
      <term>9.5.1. - Psychology</term>
      <term>9.5.7. - Geography</term>
    </keywordsSecteurs>
    <UR name="Bordeaux"/>
  </identification>
  <team id="uid1">
    <person key="potioc-2014-idp62512">
      <firstname>Martin</firstname>
      <lastname>Hachet</lastname>
      <categoryPro>Chercheur</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Team leader, Inria, Researcher</moreinfo>
      <hdr>oui</hdr>
    </person>
    <person key="potioc-2014-idp65160">
      <firstname>Fabien</firstname>
      <lastname>Lotte</lastname>
      <categoryPro>Chercheur</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Inria, Researcher</moreinfo>
      <hdr>oui</hdr>
    </person>
    <person key="potioc-2014-idp63920">
      <firstname>Anke</firstname>
      <lastname>Brock</lastname>
      <categoryPro>Chercheur</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Inria, Researcher</moreinfo>
    </person>
    <person key="potioc-2015-idm26120">
      <firstname>Pascal</firstname>
      <lastname>Guitton</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Univ. Bordeaux, Professor</moreinfo>
      <hdr>oui</hdr>
    </person>
    <person key="potioc-2014-idp69016">
      <firstname>Jeremy</firstname>
      <lastname>Laviole</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Inria, until Aug 2016</moreinfo>
    </person>
    <person key="potioc-2014-idp93232">
      <firstname>Renaud</firstname>
      <lastname>Gervais</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Inria, until Nov 2016</moreinfo>
    </person>
    <person key="potioc-2015-idp68616">
      <firstname>Benoit</firstname>
      <lastname>Coulais</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Inria</moreinfo>
    </person>
    <person key="potioc-2015-idp72416">
      <firstname>Robin</firstname>
      <lastname>Gourdel</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>SATT Nancy Grand-Est, until May 2016</moreinfo>
    </person>
    <person key="potioc-2015-idp65992">
      <firstname>Boris</firstname>
      <lastname>Mansencal</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Bordeaux INP, From January to May 2016</moreinfo>
    </person>
    <person key="potioc-2014-idp94448">
      <firstname>Camille</firstname>
      <lastname>Jeunet</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Univ. Bordeaux, defence on Dec. 2nd</moreinfo>
    </person>
    <person key="potioc-2014-idp95672">
      <firstname>Joan Sol</firstname>
      <lastname>Roo</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Inria</moreinfo>
    </person>
    <person key="potioc-2014-idp89488">
      <firstname>Damien</firstname>
      <lastname>Clergeaud</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Inria</moreinfo>
    </person>
    <person key="potioc-2015-idp74944">
      <firstname>Julia</firstname>
      <lastname>Chatain</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Univ. Bordeaux</moreinfo>
    </person>
    <person key="potioc-2016-idp142032">
      <firstname>Jelena</firstname>
      <lastname>Mladenovic</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Inria</moreinfo>
    </person>
    <person key="potioc-2016-idp144464">
      <firstname>Pierre-Antoine</firstname>
      <lastname>Cinquin</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Univ. Bordeaux, from September 2016</moreinfo>
    </person>
    <person key="potioc-2016-idp146928">
      <firstname>Lea</firstname>
      <lastname>Pillette</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Inria, from October 2016</moreinfo>
    </person>
    <person key="potioc-2014-idp70256">
      <firstname>David</firstname>
      <lastname>Furio</lastname>
      <categoryPro>PostDoc</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Univ. Bordeaux</moreinfo>
    </person>
    <person key="potioc-2014-idp92000">
      <firstname>Jeremy</firstname>
      <lastname>Frey</lastname>
      <categoryPro>PostDoc</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Univ. Bordeaux, ATER, until July 2016</moreinfo>
    </person>
    <person key="phoenix-2016-idp180592">
      <firstname>Cecile</firstname>
      <lastname>Boutros</lastname>
      <categoryPro>Assistant</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Inria</moreinfo>
    </person>
    <person key="potioc-2014-idp77944">
      <firstname>Catherine</firstname>
      <lastname>Cattaert Megrat</lastname>
      <categoryPro>Assistant</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Inria</moreinfo>
    </person>
    <person key="potioc-2016-idp159232">
      <firstname>Suzy</firstname>
      <lastname>Teillet</lastname>
      <categoryPro>AutreCategorie</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>ENSC, Internship M2, from Feb 2016 until Jul 2016</moreinfo>
    </person>
    <person key="potioc-2016-idp161728">
      <firstname>Hugo</firstname>
      <lastname>Germain</lastname>
      <categoryPro>AutreCategorie</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>CentraleSupelec, Internship M1, from Jun 2016 until Aug 2016</moreinfo>
    </person>
    <person key="potioc-2016-idp164240">
      <firstname>Benjamin</firstname>
      <lastname>Muzart</lastname>
      <categoryPro>AutreCategorie</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>Univ. Bordeaux, Internship M1, from Apr 2016 until Jun 2016</moreinfo>
    </person>
    <person key="potioc-2016-idp166752">
      <firstname>Juliette</firstname>
      <lastname>Pelletier</lastname>
      <categoryPro>AutreCategorie</categoryPro>
      <research-centre>Bordeaux</research-centre>
      <moreinfo>ENSC, Internship 1st Year, from May 2016 until Jul 2016</moreinfo>
    </person>
  </team>
  <presentation id="uid2">
    <bodyTitle>Overall Objectives</bodyTitle>
    <subsection id="uid3" level="1">
      <bodyTitle>Overall Objectives</bodyTitle>
      <p>The overall objective of Potioc is <b>to design, to develop, and to evaluate</b> new approaches that
provide <b>rich interaction experiences between users and the digital world</b>. Thus,
we aim at stimulating motivation, curiosity, engagement, or pleasure of use. In other
words, we are interested in <b>popular interaction</b>, mainly targeted at the general public.
 </p>
      <p noindent="true">We believe that such popular interaction may enhance <b>learning, creation,
entertainment or popularization of science</b> that are the main application areas targeted by our project-team.
To this end, we explore input and output modalities that go beyond standard interaction
approaches which are based on mice/keyboards and (touch)screens. Similarly, we are
interested in 3D content that offers new opportunities compared to traditional 2D contexts.
More precisely, Potioc explores interaction approaches that rely notably on interactive 3D
graphics, augmented and virtual reality (AR/VR), tangible interaction, brain-computer
interfaces (BCI) and physiological computing.</p>
      <object id="uid4">
        <table>
          <tr>
            <td>
              <ressource xlink:href="IMG/tobe-coherence.jpg" type="float" width="298.8987pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
          </tr>
        </table>
        <caption><i>Tobe</i> combines tangible interaction, spatial augmented reality, and physiological computing. It allows users to feel and explore their inner states.</caption>
      </object>
      <p>Such approaches hold great promises in a number of fields. For example, interactive 3D
graphics have become ubiquitous in the industry, where they have revolutionized usages,
notably by improving work cycles for conception or simulation tasks. However, except for
video games, we believe that such approaches are still far from being exploited to their
full extent outside such industrial contexts despite having a huge potential for the masses
in the areas targeted by our project.
 </p>
      <p noindent="true">In order to design interactive systems that can be beneficial to many people, and not only
expert users, we propose to change the usual design approaches that are generally driven
by criteria such as speed, efficiency or precision. Instead, we give more credit to the user
experience, in particular criteria such as interface appeal and enjoyment arising from the
interface use. Indeed, these criteria have been often neglected in academic research whereas
we believe they are crucial for users who are novices with 3D interaction, multisensory
spaces, or brain-computer interfaces. An interface with a strong appeal and enjoyment
factor will motivate users to use and benefit from the system.
 </p>
      <p noindent="true">In the Potioc team, we follow a multidisciplinary approach in order to tackle the problem as a
whole, from the most fundamental works on human sensori-motor and cognitive abilities
and preferences, to the aspects that are linked to the usage and applications, passing
through the technical aspects of the interaction, both at a hardware and software level.</p>
    </subsection>
  </presentation>
  <fondements id="uid5">
    <bodyTitle>Research Program</bodyTitle>
    <subsection id="uid6" level="1">
      <bodyTitle>Introduction</bodyTitle>
      <p>The project of team potioc is oriented along three axes:</p>
      <simplelist>
        <li id="uid7">
          <p noindent="true">Understanding humans interacting with the digital world</p>
        </li>
        <li id="uid8">
          <p noindent="true">Creating interactive systems</p>
        </li>
        <li id="uid9">
          <p noindent="true">Exploring new applications and usages</p>
        </li>
      </simplelist>
      <p>These axes are depicted in Figure <ref xlink:href="#uid10" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
      <object id="uid10">
        <table>
          <tr>
            <td>
              <ressource xlink:href="IMG/objectives.jpg" type="float" width="298.8987pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
          </tr>
        </table>
        <caption>The three axes of the potioc team objectives.</caption>
      </object>
      <p>Objective 1 is centered on the human sensori-motor and cognitive abilities, as well as
user strategies and preferences, for completing interaction tasks. Our target contribution for
this objective are a better understanding of humans interacting with interactive systems.
The impact of this objective is mainly at a fundamental level.
 </p>
      <p noindent="true">In objective 2, our goal is to create interactive systems. This may include hardware
parts where new input and output modalities are explored. This also includes software
parts, that are strongly linked to the underlying hardware components. Our target contribution
in objective 2 is to develop (hardware/software) interaction techniques allowing humans
to perform interaction tasks.
 </p>
      <p noindent="true">Finally, in objective 3, we consider interaction at a higher level, taking into account
factors that are linked to specific application domains and usages. Our target contribution in
this area is the exploration and the emergence of new applications and usages that take
benefit from the results of the project. With this objective, we target mainly a
societal impact.
 </p>
      <p noindent="true">Of course, strong links exist between the three objectives of the project. For example,
the results obtained in objective 1 guide the development of objective 2. Conversely, new
systems developed in objective 2 may feed research questions of objective 1. There are
similar links with objective 3.</p>
    </subsection>
    <subsection id="uid11" level="1">
      <bodyTitle>Objective 1: Understanding humans interacting with the digital world</bodyTitle>
      <p>Our first objective is centered on the human side. Our finality is not to enhance the
general knowledge about the human being as a research team in psychology would do. Instead,
we focus on human skills and behaviors during interaction processes. To this end, we
conduct experiments that allow us to better understand what users like, where and
why they have difficulties. Thanks to these investigations, we are able to design interaction
techniques and systems (described in Objective 2) that are well suited to the targeted
users. We believe that this fundamental piece of work is the first step that is required for
the design of usable popular interactions. We are particularly interested in 3D interaction
tasks for which we design dedicated experiments. We also explore a new approach based
on physiological and brain (ElectroEncephaloGraphy - EEG) signals for the evaluation of
these interactions.</p>
      <subsection id="uid12" level="2">
        <bodyTitle>Interacting with physical and virtual environments</bodyTitle>
        <p>Interacting with digital content displayed on 2D screens has been extensively studied in HCI. On the other hand, less conventional contexts have been studied less. This is the case of 3D environments, immersive virtual environments, augmented reality, and tangible objects. With the final goal of making interaction in such contexts user-friendly, we conduct experiments to better understand user strategies and performance. This allows us to propose guidelines to help designers creating of tools that are accessible to non-expert users.</p>
      </subsection>
      <subsection id="uid13" level="2">
        <bodyTitle>Evaluating (3D) interaction with physiological signals</bodyTitle>
        <p>Recently, physiological computing has been shown to be a promising complement to Human-Computer Interfaces (HCI) in general, and to 3D User Interfaces (3DUI) in particular, in several directions. Within this research area, we are interested in using various physiological signals, and notably EEG signals, as a new tool to assess objectively the ergonomic quality of a given (3D) UI, to identify where and when are the pros and cons of this interface, based on the user’s mental state during interaction. For instance, estimating the user’s mental workload during interaction can give insights about where and when the interface is cognitively difficult to use. This could be useful for 2D HCI in general, and even more for 3DUI. Indeed, in a 3DUI, the user perception of the 3D scene – part of which could potentially be measured in EEG - is essential. Moreover, the usual need for a mapping between the user inputs and the corresponding actions on 3D objects make 3DUI and interaction techniques more difficult to assess and to design.</p>
      </subsection>
      <subsection id="uid14" level="2">
        <bodyTitle>Interacting with Brain-Computer Interfaces</bodyTitle>
        <p>Although very promising for numerous applications, BCIs mostly remain prototypes not used outside laboratories, due to their low reliability. Poor BCI performances are partly due to imperfect EEG signal processing algorithms but also to the user who may not be able to produce reliable EEG patterns. Indeed, BCI use is a skill, requiring the user to be properly trained to achieve BCI control. If he/she cannot perform the desired mental commands, no signal processing algorithm can identify them. Therefore, rather than improving EEG signal processing alone, an interesting research direction is to also guide users to learn BCI control mastery. We aim at addressing this objective. We are notably exploring theoretical models and guidelines from educational sciences to improve BCI training protocols. We also study which users’ profiles (personality and cognitive profile) fail or succeed at learning BCI control. Finally, we explore new feedback types and new EEG visualization techniques in order to help users gain BCI control skills more efficiently. These new feedback and visualizations notably aim at providing BCI users with more information about their EEG patterns, in order to identify more easily relevant BCI control strategies, as well as motivating and engaging them in the learning task.</p>
      </subsection>
      <subsection id="uid15" level="2">
        <bodyTitle>Interaction for people with special needs</bodyTitle>
        <p>Interaction capabilities and needs largely depend on the target user group. In the Potioc project-team, we work with people having special needs. As an example, we work with children in the context of education, which requires us to design interfaces that are usable, engaging and support learning for this target group. Furthermore, we work with people with cognitive or perceptive disabilities, which requires us to consider accessibility, while at the same time designing interfaces that are learnable and enjoyable to use. In order to meet the needs of the different target groups, we apply participative and user-centred design methods.</p>
      </subsection>
    </subsection>
    <subsection id="uid16" level="1">
      <bodyTitle>Objective 2: Creating interactive systems</bodyTitle>
      <p>Our objective here is to create interactive systems and design interaction techniques dedicated
to the completion of interaction tasks. We divide our work into three main categories:</p>
      <simplelist>
        <li id="uid17">
          <p noindent="true">Interaction techniques based on existing Input/Output (IO) devices.</p>
        </li>
        <li id="uid18">
          <p noindent="true">New IO and related techniques.</p>
        </li>
        <li id="uid19">
          <p noindent="true">BCI and physiological computing.</p>
        </li>
      </simplelist>
      <subsection id="uid20" level="2">
        <bodyTitle>Interaction techniques based on existing Input/Output (IO) devices</bodyTitle>
        <p>When using desktop IOs (i.e.,
based on mice/keyboards/monitors), a big challenge is to design interaction techniques
that allow users to complete 3D interaction tasks. Indeed, the desktop IO space that is
mainly dedicated to the completion of 2D interaction task is not well suited to 3D content
and, consequently, 3D user interfaces need to be designed with a great care.
In the past few years, we have been particularly interested in the problem of interaction
when the 3D content is displayed on a touchscreen. Indeed, standard (2D) HCI has
evolved from mouse to touch input, and numerous research projects have been conducted.
On the contrary, in 3D, very little work has been proposed. We are contributing to moving
desktop 3D UIs from the mouse to the touch paradigm; what we used to do with mice in
front of a screen does not work well on touch devices anymore.
In the future, we will continue designing new interaction techniques that are based on standard IOs (eg. pointing devices and webcams) and that target the main objectives of Potioc which are to enhance the interaction bandwidth for non expert users.</p>
      </subsection>
      <subsection id="uid21" level="2">
        <bodyTitle>New IO and related techniques</bodyTitle>
        <p>Beyond standard IOs, we are interested in exploring new IO
modalities that may make interaction easier, more engaging and motivating. In Potioc, we design new interactive systems that exploit unconventional IO modalities such as stereoscopy, 3D spatial input, augmented reality and so on.
In particular, tangible interaction and spatial augmented reality are major subjects of interest for us. Indeed, we believe that
manipulating directly physical objects for interacting with the digital world has a great
potential, in particular when the general public is targeted.
With such approaches, the computer disappears, and the
user interacts with the digital content as he or she would do with physical content, which reduces the distance to the manipulated content.
As an example, we recently designed Teegi, a new system based on a unique combination
of spatial augmented reality, tangible interaction and real-time neurotechnologies. With Teegi, a user can visualize and analyze his or her own brain activity
in real-time, on a tangible character that can be easily manipulated, and with which it is
possible to interact. Such unconventionnal user interfaces that are based on rich sensing modalities hold great promises in the field of popular interaction.</p>
        <p>We are also interested in designing systems that combine different sensory modalities, such as vision, touch and audition. Concrete examples include the design of tangible user interfaces or interfaces for visually impaired people. It has been shown that multimodality can provide rich interaction that can efficiently support learning, and it is also important in the context of accessibility.</p>
      </subsection>
      <subsection id="uid22" level="2">
        <bodyTitle>BCI and physiological computing</bodyTitle>
        <p>Although Brain-Computer Interfaces (BCI) have demonstrated their tremendous potential in numerous applications, they are still mostly prototypes, not used outside laboratories. This is mainly due to the following limitations:</p>
        <simplelist>
          <li id="uid23">
            <p noindent="true">Performances: the poor classification accuracies of BCIs make them inconvenient to use or simply useless compared to available alternatives</p>
          </li>
          <li id="uid24">
            <p noindent="true">Stability and robustness: the sensibility of ElectroEncephaloGraphic (EEG) signals to noise and their inherent non-stationarity make the already poor initial performances difficult to maintain over time</p>
          </li>
          <li id="uid25">
            <p noindent="true">Calibration time: the need to tune current BCIs to each user’s EEG signals makes their calibration times too long.</p>
          </li>
        </simplelist>
        <p>As part of our research on EEG-based BCIs, we notably aim at addressing these limitations by designing robust EEG signal processing tools with minimal calibration times, in order to design practical BCI systems, usable and useful outside laboratories. To do so we explore the design of alternative features and robust spatial filtering algorithms to make BCIs more robust to noise and non-stationarities, as well as more accurate. We also explore artificial EEG data generation and user-to-user data transfer to reduce calibration times.</p>
      </subsection>
    </subsection>
    <subsection id="uid26" level="1">
      <bodyTitle>Objective 3: Exploring new applications and usages</bodyTitle>
      <p>Objective 3 is centered on the applications and usages. Beyond the human sensori-motor
and cognitive skills (Objective 1), and the hardware and software components (Objective
2), Objectives 3 takes into account broader criteria for the emergence of new usages and
applications in various areas, and in particular in the scope of education, art, popularization of science
and entertainment. Our goal here is not to develop full-fledged end-user applications.
Instead, our contribution is to stimulate the evolution of current applications with new
engaging interactive systems.</p>
      <subsection id="uid27" level="2">
        <bodyTitle>Education</bodyTitle>
        <p>Education is at the core of the motivations of the Potioc group. Indeed, we are convinced that the approaches we investigate—which target motivation, curiosity, pleasure of use and high level of interactivity—may serve education purposes. To this end, we collaborate with experts in Educational Sciences and teachers for exploring new interactive systems that enhance learning processes. We are currently investigating the fields of astronomy, optics, and neurosciences. We are also working with special education centres for the blind on accessible augmented reality prototypes. In the future, we will continue exploring new interactive approaches dedicated to education, in various fields.</p>
      </subsection>
      <subsection id="uid28" level="2">
        <bodyTitle>Popularization of science</bodyTitle>
        <p>Popularization of Science is also a key domain for Potioc. Focusing on this subject allows us to get inspiration for the development of new interactive approaches. In particular, we have built a strong partnership with Cap Sciences, which is
a center dedicated to the popularization of science in Bordeaux that is visited by thousands of
visitors every month. This was initiated with the ANR national project InSTInCT, whose
goal was to study the benefits of 3D touch-based interaction in public exhibitions. This
project has led to the creation of a Living Lab where several systems developed by Potioc
have been tested and will be tested by the visitors. This provides us with very interesting observations that go beyond the
feedback we can obtain in our controlled lab-experiments.</p>
      </subsection>
      <subsection id="uid29" level="2">
        <bodyTitle>Art</bodyTitle>
        <p>Art, which is strongly linked with emotions and user experiences, is also a target area for Potioc. We believe that the work conducted in Potioc may
be beneficial for creation from the artist point of view, and it may open new interactive experiences
from the audience point of view. As an example, we are working with colleagues
who are specialists in digital music, and with musicians. We are also working with jugglers and mockup builders with the goal of enhancing interactivity and user experience.</p>
      </subsection>
      <subsection id="uid30" level="2">
        <bodyTitle>Entertainment</bodyTitle>
        <p>Similarly, entertainment is a domain where our work may have an impact. We notably explored BCI-based gaming and non-medical
applications of BCI, as well as mobile Augmented Reality games. Once again, we believe that our approaches that merge the physical and the virtual world may enhance the user experience. Exploring such a domain will raise numerous scientific and technological questions.</p>
      </subsection>
    </subsection>
  </fondements>
  <domaine id="uid31">
    <bodyTitle>Application Domains</bodyTitle>
    <subsection id="uid32" level="1">
      <bodyTitle>Education, popularization of science, art, entertainment</bodyTitle>
      <p>Our project aims at providing rich interaction experiences between users and the digital world, in particular for non-expert users.
The final goal is to stimulate understanding, learning, communication and creation. Our scope of applications encompasses</p>
      <simplelist>
        <li id="uid33">
          <p noindent="true">education</p>
        </li>
        <li id="uid34">
          <p noindent="true">popularization of science</p>
        </li>
        <li id="uid35">
          <p noindent="true">art</p>
        </li>
        <li id="uid36">
          <p noindent="true">entertainment</p>
        </li>
      </simplelist>
      <p>See "Objective 3: Exploring new applications and usages" (<ref xlink:href="#uid26" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>) for a detailed description.</p>
    </subsection>
  </domaine>
  <highlights id="uid37">
    <bodyTitle>Highlights of the Year</bodyTitle>
    <subsection id="uid38" level="1">
      <bodyTitle>Highlights of the Year</bodyTitle>
      <simplelist>
        <li id="uid39">
          <p noindent="true">ERC Grant "BrainConquest : Boosting Brain-Computer Communication with high Quality User Training" (Fabien Lotte)</p>
        </li>
        <li id="uid40">
          <p noindent="true">EFRAN project e-tac "Tangible and augmented interface for collaborative learning" (Martin Hachet)</p>
        </li>
        <li id="uid41">
          <p noindent="true">First book in French about BCI <ref xlink:href="#potioc-2016-bid0" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/> <ref xlink:href="#potioc-2016-bid1" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/> (Fabien Lotte)</p>
        </li>
        <li id="uid42">
          <p noindent="true">First accessible MOOC on "Accessibilité numérique" <ref xlink:href="https://www.fun-mooc.fr/courses/inria/41012/session01/about" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>www.<allowbreak/>fun-mooc.<allowbreak/>fr/<allowbreak/>courses/<allowbreak/>inria/<allowbreak/>41012/<allowbreak/>session01/<allowbreak/>about</ref> (Pascal Guitton)</p>
        </li>
      </simplelist>
    </subsection>
  </highlights>
  <logiciels id="uid43">
    <bodyTitle>New Software and Platforms</bodyTitle>
    <subsection id="uid44" level="1">
      <bodyTitle>PapARt</bodyTitle>
      <p>PapARt is a software development kit (SDK) that enables the creation of interactive projection mapping (See <ref xlink:href="https://project.inria.fr/papart" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>project.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>papart</ref>).
This year, we focused on making this toolkit widely available. We created a set of examples and created tutorials. The PapARt code is now Open Source, our objective being to favor a wide appropiration by artists, teachers, or students.</p>
      <sanspuceslist>
        <li id="uid45">
          <p noindent="true">Participants: Jeremy Laviole, Martin Hachet</p>
        </li>
        <li id="uid46">
          <p noindent="true">URL: <ref xlink:href="https://github.com/poqudrof/Papart-examples/wiki" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>github.<allowbreak/>com/<allowbreak/>poqudrof/<allowbreak/>Papart-examples/<allowbreak/>wiki</ref></p>
        </li>
      </sanspuceslist>
    </subsection>
    <subsection id="uid47" level="1">
      <bodyTitle>Helios</bodyTitle>
      <p>Helios is a software tool (Unity3D) we have developed in collaboration with Stéphanie Fleck from Université de Lorraine.
It is dedicated to the learning of astronomy at school. It bases on augmented reality and tangible interaction. See Section <ref xlink:href="#uid64" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
      <sanspuceslist>
        <li id="uid48">
          <p noindent="true">Participants: Robin Gourdel, Jérémy Laviole, Benoit Coulais, Martin Hachet.</p>
        </li>
        <li id="uid49">
          <p noindent="true">Partners: Université de Loraine - SATT Nancy Grand-Est.</p>
        </li>
      </sanspuceslist>
    </subsection>
    <subsection id="uid50" level="1">
      <bodyTitle>Aïana</bodyTitle>
      <p>We have developped Aïana, a MOOC player, with the support of the Inria MOOC Lab. Aïana offers original interaction features in order to enable a wide spectrum of users including persons with disabilities. The first version of Aïana has been used by the 3700 participants of the Digital Accessibility MOOC we have produced on the national MOOC platform FUN. See Section <ref xlink:href="#uid73" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
      <sanspuceslist>
        <li id="uid51">
          <p noindent="true">Participants: Pierre-Antoine Cinquin, Pascal Guitton</p>
        </li>
        <li id="uid52">
          <p noindent="true">Partners: LearningLab Inria</p>
        </li>
      </sanspuceslist>
    </subsection>
    <subsection id="uid53" level="1">
      <bodyTitle>HOBIT</bodyTitle>
      <p>Along with the project HOBIT (see Section <ref xlink:href="#uid58" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>), we continue enhancing the platform that is dedicated to the simulation and augmentation of optics experiments. In particular, this year, we did a major evolution that consists in making the system reconfigurable. Various optical components be plugged in, and the simulation and augmentations are updated accordingly.</p>
      <sanspuceslist>
        <li id="uid54">
          <p noindent="true">Participants: Benoit Coulais, David Furio, Martin Hachet.</p>
        </li>
        <li id="uid55">
          <p noindent="true">Partners: Université de Bordeaux - IUT de Bordeaux, LaBRI, IMS, CELIA</p>
        </li>
        <li id="uid56">
          <p noindent="true">
            <ref xlink:href="https://project.inria.fr/hobit" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>project.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hobit</ref>
          </p>
        </li>
      </sanspuceslist>
    </subsection>
  </logiciels>
  <resultats id="uid57">
    <bodyTitle>New Results</bodyTitle>
    <subsection id="uid58" level="1">
      <bodyTitle>HOBIT</bodyTitle>
      <p><b>Participants</b>: David Furio, Benoit Coulais, Martin Hachet</p>
      <p>Practical work in optics learning allows supporting the construction of knowledge, in particular when the concept to be learned remains diffuse. To overcome the limitations of the current experimental setups, we have designed a hybrid system that combines physical interaction and numerical simulation. This system relies on 3D-printed replicas of optical elements, which are augmented with pedagogical information (see Figure <ref xlink:href="#uid59" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>). In a first step, we have focused on the well-known Michelson interferometer experiment, widely studied in under graduate programs of Science. A 3-months user study with 101 students and 6 teachers showed that, beyond the practical aspects offered by this system, such an approach enhances the technical and scientific learning compared to a standard Michelson interferometer experiment. A second version of HOBIT is currently being developed. This new version will let us simulate and augment multiple experiments related with optics, like polarization or Young’s interferometer.</p>
      <p>A paper presenting HOBIT has been (conditionaly) accepted at ACM CHI 2017.</p>
      <object id="uid59">
        <table>
          <tr>
            <td>
              <ressource xlink:href="IMG/hobit.png" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
          </tr>
        </table>
        <caption>HOBIT: Hybrid Optical Bench for Innovative Teaching</caption>
      </object>
    </subsection>
    <subsection id="uid60" level="1">
      <bodyTitle>Inner Garden</bodyTitle>
      <p><b>Participants</b>: Joan Sol Roo, Renaud Gervais, Jeremy Frey, Martin Hachet</p>
      <p>Digital technology has completely integrated our daily lives; we use it for entertainment, productivity and our social lives. However, the potential of leveraging technology to improve its users' overall happiness and life satisfaction is still largely untapped. Mindfulness, the act of paying a deliberate and non-judgmental attention to the present moment, has been shown to have a positive impact on a person's subjective well-being. With this in mind we created Inner Garden, an ambient mixed reality installation, inspired by a zen garden, comprised of an augmented sandbox along with a virtual reality modality to support mindful experiences (Figure <ref xlink:href="#uid61" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. By shaping the sand, the user creates a living miniature world that is projected back onto the sand. Moreover, using a VR headset, she can take a moment to herself by actually going inside her own garden to meditate. The natural elements of the garden are connected to real-time physiological measurements, such as breathing, helping staying focused on the body. We evaluated the system through a first user study and consulted meditation teachers, who envisioned the use of the garden in their teaching, especially for novice practitioners. The reception of the system seems to indicate that technology can, when designed carefully, both engage the users and foster well-being.</p>
      <p>A paper presenting Inner Garden has been (conditionaly) accepted at ACM CHI 2017.</p>
      <object id="uid61">
        <table>
          <tr>
            <td>
              <ressource xlink:href="IMG/InnerGarden.jpg" type="float" height="142.26378pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
          </tr>
        </table>
        <caption>Inner Garden, an ambient mixed reality installation to support mindful experiences</caption>
      </object>
    </subsection>
    <subsection id="uid62" level="1">
      <bodyTitle>Hybridation of Spatial Augmented Reality and Virtual Reality</bodyTitle>
      <p><b>Participants</b>: Joan Sol Roo and Martin Hachet</p>
      <p>Spatial Augmented Reality (SAR) allows a user, or a group of users, to benefit from digital augmentations embedded directly into the physical world. This enables co-located information and unobstructed interaction. On the other hand, SAR suffers from limitations that are inherently linked to its physical dependency, which is not the case for see-through or immersive displays. In this work, we explore how to facilitate the transition from SAR to VR, and vice versa, integrating both into a unified experience (Figure <ref xlink:href="#uid63" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>). We developed a set of interaction techniques and obtained first feedback from informal interviews.</p>
      <p>A technote presenting this work has been (conditionaly) accepted at IEEE 3DUI 2017.</p>
      <object id="uid63">
        <table>
          <tr>
            <td>
              <ressource xlink:href="IMG/sar-vr.png" type="float" height="113.81102pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
          </tr>
        </table>
        <caption>Transition from Spatial Augmented Reality to Virtual Reality</caption>
      </object>
    </subsection>
    <subsection id="uid64" level="1">
      <bodyTitle>Augmented Reality and Tangible User Interfaces for Understanding Astronomy</bodyTitle>
      <p><b>Participants</b>: Robin Gourdel, Benoit Coulais, Jeremy Laviole, Martin Hachet</p>
      <p>We have worked with Stephanie Fleck (Université de Lorraine) to improve the leraning environment AIBLE she had imagined (see <ref xlink:href="http://stefleck4.wixsite.com/aible/-propos2-cw4c" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>stefleck4.<allowbreak/>wixsite.<allowbreak/>com/<allowbreak/>aible/<allowbreak/>-propos2-cw4c</ref>).
We have designed Helios, an augmented reality platform that aims at enhancing the understanding of abstract concepts in astronomy, specifically for primary schools’
curriculum with children aged from 8 to 11. In order to provide physical evidence for the influence of sunlight on the Earth and the Moon, and of
the consequences of their relative positions, the learning tasks are designed on inquiry-based learning principles. Children have to test their own
hypotheses by using tangible props and a set of cards that trigger dedicated pedagogical activities (e.g. seasons and the Earth revolution around the
Sun, lunation origin, Earth rotation and time measurement).</p>
      <p>Helios basically consists of a standard laptop computer, a webcam, printable AR markers placed on tangible props and on dedicated pedagogical cards (See Figure <ref xlink:href="#uid65" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>).
The (virtual) celestial bodies are displayed on the screen, and many visual feedback help understanding various phenomena (e.g. shadow cones, time zones, and so on).
In <ref xlink:href="#potioc-2016-bid2" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>, we discuss how such an approach allows learners to better understand abstract phenomena.</p>
      <object id="uid65">
        <table>
          <tr>
            <td>
              <ressource xlink:href="IMG/helios.jpg" type="float" height="113.81102pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
          </tr>
        </table>
        <caption>Helios: Manipulation of tangible objects and visualization of an augmented scene to learn astronomy.</caption>
      </object>
    </subsection>
    <subsection id="uid66" level="1">
      <bodyTitle>Collaboration in VR</bodyTitle>
      <p><b>Participants</b>: Damien Clergeaud and Pascal Guitton</p>
      <p>The Airbus company regularly uses virtual reality for design, manufacturing and maintenance. We work with them on collaborative interaction in order to enable an efficient collaboration between operators immersed in the same virtual environment from remote locations and with heterogeneous equipment (large displays, CAVE, HMD). More precisely, we have developped tools to point and manipulate 3D objects, to remotely visualize the virtual environment, to be aware of remote manipulations and to describe tools and components trajectories (Figure <ref xlink:href="#uid67" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>). These tools have been validated by Airbus experts and the next step is to integrate them in their global process.</p>
      <p>We are also working on Through-The-Lens Interaction techniques to ease the collaboration in some asymmetric tasks that requires a guide and an operator. Through-The-Lens techniques enable the guide to interact with the surroundings of the operator in order to help him in the task he has to perfrom. A paper presenting such a technique has been (conditionaly) accepted at IEEE 3DUI 2017.</p>
      <object id="uid67">
        <table>
          <tr>
            <td>
              <ressource xlink:href="IMG/airbus.png" type="float" height="142.26378pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
          </tr>
        </table>
        <caption>An immersed user has to perform a virtual task in a complex environment. In order to help the user to be fully aware of the VE, another immersed operator may guide him using a Through-The-Lens metaphor.</caption>
      </object>
    </subsection>
    <subsection id="uid68" level="1">
      <bodyTitle>Interactive 3D Environments for Immersive Musical Performances</bodyTitle>
      <p><b>Participants</b>: Martin Hachet</p>
      <p>Together with Florent Berthaut (Univeristé Lille 3), we presented a set of works that attempts to extent the frontiers of music creation as well as the experience of audiences attending digital performances. Indeed, the power of interactive 3D graphics, immersive displays, and spatial interfaces is still under-explored in domains where the main target is to enhance creativity and emotional experiences. The goal of our work is to connect sounds to interactive 3D graphics that musicians can interact with and the audience can observe <ref xlink:href="#potioc-2016-bid3" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
    </subsection>
    <subsection id="uid69" level="1">
      <bodyTitle>Multisensory Maps and 3D Printed Interactive Maps for Visually Impaired People</bodyTitle>
      <p><b>Participant</b>: Anke Brock</p>
      <p>Visually impaired people face important challenges related to orientation and mobility. Accessible geographic maps are helpful for acquiring knowledge of an urban environment. Historically, raised-line paper maps with braille text have been used, but these maps possess significant limitations. For instance, only a small percentage of the visually impaired population reads braille. Recent technological advances have enabled the design of accessible interactive maps with the aim to overcome these limitations.
We designed Mappie, an accessible interactive map prototype based on the use of a multi-touch screen with a raised-line map overlay and speech output (Figure <ref xlink:href="#uid70" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>). Then, we deployed Mappie in a class of seven children and one caretaker during three months. Our formative study showed promising results and allowed insights in the design of accessible interactive maps, such as using olfactory and gustatory modalities to foster reflective learning, and using tangible objects to support storytelling.
Following this first study, we designed MapSense as an extension of Mappie. MapSense uses the same hardware and interaction techniques as Mappie, but additionally provides fourteen ”Do-It-Yourself” conductive tangibles. Some tangibles could be filled with scented material, such as olive oil, smashed raisins or honey, thus creating a real multi-sensory experience. The map was explored during two classes of three hours separated by a week, taught conjointly by a locomotion trainer and a specialized teacher. We observed that the map and tangible objects triggered strong positive emotions and stimulated spatial learning as well as creativity of the visually impaired students.
This work has been conducted as part of the PhD thesis of Emeline Brulé under the supervision of Gilles Bailly and Annie Gentes, and in collaboration with the IRIT research lab in Toulouse. It has been published at CHI'16 <ref xlink:href="#potioc-2016-bid4" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
      <p>As part of the postdoc of Stephanie Giraud at IRIT Toulouse under the supervision of Christophe Jouffrais, we have investigated how to print entire interactive maps in 3D, allowing users to construct a city like using a puzzle. We have conducted a user study comparing an interactive map that has been entirely 3D printed to a raised-line map with braille text (Figure <ref xlink:href="#uid70" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/> left). Our results suggest that the interactive map is significantly more effective for providing spatial knowledge than a tactile paper map with braille.</p>
      <object id="uid70">
        <table>
          <tr>
            <td>
              <ressource xlink:href="IMG/map.jpg" type="inline" height="142.26378pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
            <td>
              <ressource xlink:href="IMG/3Dprint.png" type="inline" height="142.26378pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
          </tr>
        </table>
        <caption>(Left) 3D printed interactive map, (Right) 3D printed tangibles for multisensory maps</caption>
      </object>
    </subsection>
    <subsection id="uid71" level="1">
      <bodyTitle>Navidrone</bodyTitle>
      <p><b>Participants</b>: Julia Chatain, Anke Brock, Martin Hachet</p>
      <p>With recent technological advances, the shapes of mobile devices are evolving. For example, we now see the emergence of new types of devices in form of autonomous aerial vehicles (drones) that become available in our everyday environment. As drones are becoming increasingly autonomous, it is crucial to understand how interaction with such devices will happen. These new devices, allow us to imagine new contexts of map usage, as for instance drone-based autonomous tour guides ((Figure <ref xlink:href="#uid72" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>). In order for those scenarios to happen, many problems need to be investigated. From a perspective in Human-Computer Interaction (HCI), the first questions to study are related to suitable input and output techniques.
We iteratively designed interaction techniques for Navidrone, a drone-based autonomous tour guide. This work has been done in collaboration with the Prof. James Landay and Dr. Jessica Cauchard from the Stanford HCI Group.</p>
      <object id="uid72">
        <table>
          <tr>
            <td>
              <ressource xlink:href="IMG/DroneSketch.jpg" type="float" height="142.26378pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
          </tr>
        </table>
        <caption>Sketch showing the Navidrone concept: users interact with maps projected from drones by using their phones.</caption>
      </object>
    </subsection>
    <subsection id="uid73" level="1">
      <bodyTitle>Accessibility of e-learning systems</bodyTitle>
      <p><b>Participants</b>: Pierre-Antoine Cinquin and Pascal Guitton</p>
      <p>E-learning systems, such as MOOC or serious games, are increasingly taking part in training process. Unfortunately, like most digital systems, they suffer from a lack of accessibility, in particular for people with cognitive disabilities (e.g. who have limited attention and memory). In this project, we develop a framework based on various disciplinary fields (education, cognitive sciences, human factors) but also participatory design research with students with disabilities to design interfaces promoting e-learning accessibility.
From this framework, we have designed interaction features which have been implemented in a specific MOOC player called Aïana. Moreover, we have produced a MOOC on digital accessibility which is published on the national MOOC platform (FUN) using Aïana. We are currently working on the analysis of this first play in order to enhance Aïana by designing new interaction modalities.</p>
      <object id="uid74">
        <table>
          <tr>
            <td>
              <ressource xlink:href="IMG/mooc.jpg" type="float" height="142.26378pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
          </tr>
        </table>
        <caption>The Aïana MOOC player.</caption>
      </object>
    </subsection>
    <subsection id="uid75" level="1">
      <bodyTitle>Teegi, a tangible EEG interface for scientific outreach</bodyTitle>
      <p><b>Participants</b> : Thibault Lainé, Renaud Gervais, Jérémy Frey, Hugo Germain, Fabien Lotte, Martin Hachet</p>
      <p>Teegi is an interactive systems that combines electroencephalographic (EEG) recordings and tangible interaction in order to let novices learn about how their brain works. By displaying EEG activity in real time on a support that is easy to manipulate and to comprehend, Teegi is a good tool for scientific outreach, that raises public interest.</p>
      <object id="uid76">
        <table>
          <tr>
            <td>
              <ressource xlink:href="IMG/teegi_close.jpg" type="float" height="113.81102pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
          </tr>
        </table>
        <caption>Teegi is a “Tangible EEG interface” that displays cerebral activity in real time by the mean of electroencephalography. A new robotized version can move and react accordingly to the brain patterns of the user, helping to explain to novices how the brain works.</caption>
      </object>
      <p>While last year we developed a semi-spherical display based on LEDs, we push the project further during 2016 and built a complete autonomous puppet (Figure <ref xlink:href="#uid76" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>). The robot can move its two hands independently or its feet, and it can close its eyes. Beside the display of EEG activity, Teegi can react accordingly to the brain patterns recorded in real time from the user.</p>
      <p>We demonstrated this new prototype in various occasions over the year, during public events such as “Fête de la Science” in La Cité des Sciences in Paris, a manifestation that gathered thousands of visitors (See Section <ref xlink:href="#uid355" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/> "Popularization").</p>
    </subsection>
    <subsection id="uid77" level="1">
      <bodyTitle>Neuroergonomy</bodyTitle>
      <p><b>Participants</b> : Jérémy Frey, Martin Hachet, Fabien Lotte</p>
      <p>3D user interfaces are increasingly used in a number of applications, spanning from entertainment to industrial design. However, 3D interaction tasks are generally more complex for users since interacting with a 3D environment is more cognitively demanding than perceiving and interacting with a 2D one. As such, it is essential that we could finely evaluate user experience, in order to propose seamless interfaces. To do so, a promising research direction is to measure users' inner states based on brain signals acquired during interaction, by following a neuroergonomics approach. Combined with existing methods, such tool can be used to strengthen the understanding of user experience.</p>
      <p>In <ref xlink:href="#potioc-2016-bid5" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/><ref xlink:href="#potioc-2016-bid6" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>, we reviewed the related work in this area. We summurized what has been achieved and the new challenges that arise. We described how a mobile brain imaging technique such as electroencephalography (EEG) brings continuous and non-disruptive measures. EEG-based evaluation of users can give insights about multiple dimensions of the user experience, with realistic interaction tasks or novel interfaces. We investigate four constructs: workload, attention, error recognition and visual comfort. Ultimately, these metrics could help to alleviate users when they interact with computers.</p>
      <p>Such advance in the understanding of the users will eventually come forward thanks to the increasing dissemination of non-invasive brain imaging devices that record electrical activity onto the scalp. In <ref xlink:href="#potioc-2016-bid7" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/><ref xlink:href="#potioc-2016-bid8" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/> we compared side by side two EEG amplifiers, the consumer grade OpenBCI and the medical grade g.tec g.USBamp. We suggested how an affordable and open-hardware device could facilitate, beside neuroergomomics, the appearance of various brain-computer interfaces applications.</p>
    </subsection>
    <subsection id="uid78" level="1">
      <bodyTitle>Physiological computing</bodyTitle>
      <subsection id="uid79" level="2">
        <bodyTitle>Physiological computing</bodyTitle>
        <p><b>Participants</b> : Jérémy Frey</p>
        <p>While physiological sensors enter the mass market and reach the general public, they are still mainly employed to monitor health. Over the course of a thesis that explored the new possibilities offered by physiological computing in terms of communication and social presence, we described several use-cases involving the externalization of inner states through novel user interfaces.</p>
        <p>For example, we created an application that uses heart rate feedback as an incentive for social interactions. A traditional board game was “augmented” through remote physiological sensing (Figure <ref xlink:href="#uid80" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>), using webcams to account for the subtle changes in blood flow that occur with each heartbeat. Projection helped to conceal the technological aspects from users and merged the biofeedback with the physical environment. We detailed how players reacted – stressful situations could emerge when users are deprived from their own signals – and we gave directions for game designers to integrate physiological sensors.</p>
        <object id="uid80">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/bluff_teaser.jpg" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>We augmented a traditional board game with remote physiological monitoring and projection to demonstrate how physiological computing could be used to foster new interactions between people and increase social presence.</caption>
        </object>
        <p>We envisioned a second application, that merges virtual reality, interactive fiction and physiological computing in order to craft <i>truly</i> immersive stories; narratives that evolve depending both on the actions and on the inner states of the user/reader, stretching a medium that shaped for ages humanity (Figure <ref xlink:href="#uid81" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>) <ref xlink:href="#potioc-2016-bid9" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        <object id="uid81">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/vif_teaser.jpg" type="float" height="113.81102pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>A combination of physiological sensors and head-mounted display (left) is used to immerse the reader in a narrative that reacts to gaze and to bodily activity (right).</caption>
        </object>
      </subsection>
    </subsection>
    <subsection id="uid82" level="1">
      <bodyTitle>EEG signal classification for BCI based on Riemannian geometry</bodyTitle>
      <p><b>Participants</b> : Fabien Lotte</p>
      <p>Although promising from numerous applications, current Brain-Computer Interfaces (BCIs) still suffer from a number of limitations. In particular, they are sensitive to noise, outliers and the non-stationarity of ElectroEncephaloGraphic (EEG) signals, they require long calibration times and are not reliable. Thus, new approaches and tools, notably at the EEG signal processing and classification level, are necessary to address these limitations. Riemannian approaches, spearheaded by the use of covariance matrices, are such a very promising tool slowly adopted by a growing number of researchers. We proposed a review of how these approaches have been used for EEG-based BCI, in particular for feature representation and learning, classifier design and calibration time reduction. Finally, we also identified relevant challenges and promising research directions for EEG signal classification in BCIs, such as feature tracking on manifold or multi-task learning <ref xlink:href="#potioc-2016-bid10" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
    </subsection>
    <subsection id="uid83" level="1">
      <bodyTitle>Understanding Mental Imagery-based Brain-Computer Interface user-training</bodyTitle>
      <p><b>Participants</b> : Camille Jeunet, Fabien Lotte</p>
      <p>Mental Imagery-based Brain-Computer Interface (MI-BCI) enable their users to send commands to computer by imagining mental tasks (i.e., by performing MI) that are recognized in their brain signals.
This type of BCI requires user training, and this training is currently poorly understood, and we basically do not know, who can learn MI-BCI control, what is to learn and how to learn it efficiently.
Moreover, we have shown that current MI-BCI training protocols were both theoretically and practically inappropriate, and that there is a lack of fundamental knowledge on BCI user training, which prevents us from designing better user training approach <ref xlink:href="#potioc-2016-bid11" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
      <p>In order to address these points, we first proposed a review and classification of cognitive and psychological predictors of MI-BCI performance. Three categories were defined: the user-technology relationship, attention and spatial abilities. The user-technology relationship refers to personality traits and states that influence users' perception of the technology and consequently impact the way they will interact with the technology (i.e., their feeling of being in control, their self-efficacy, etc.). The attention category gathers, among others, users' attentional abilities, motivation and engagement towards the task. These elements are essential to learn, whatever the skill targeted. They are also closely related to the user-technology relationship (for instance, feeling in control will increase users' engagement towards the task, thus they will allocate more attentional resources to the task). Finally, spatial abilities are the ability to produce, manipulate and transform mental images, which is closely related to the ability to control an MI-BCI. The description of these categories and of their neurophysiological correlates enabled us to submit ideas to improve MI-BCI user-training. For instance, we explained how to reduce computer-anxiety and increase the sense of agency, notably through the use of a positively biased feedback for novice users. Also, we proposed solutions to raise and improve attention, e.g., using neurofeedback or meditation. Finally, we argued that spatial abilities could be trained to improve users' capacity to perform mental imagery and consequently, potentially improve their MI-BCI performance <ref xlink:href="#potioc-2016-bid12" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
      <p>We also did a review of the literature of current training protocols (published as a book chapter in <ref xlink:href="#potioc-2016-bid13" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>) which suggests that these protocols are, at least theoretically, inappropriate to acquire a skill and thus that they could be one of the factors responsible for inefficient MI-BCI user-training. In particular, participants are most of the time provided with uni-modal and evaluative feedback while literature recommends multi-modal, informative and supporting feedback. Although instructive, these insights only provide theoretical considerations about the flaws associated with the feedback approaches used in MI-BCI. It was therefore necessary to <i>concretely</i> assess whether standard MI-BCI feedback is appropriate to train a skill, and to what extent the feedback impacts BCI performance and skill acquisition. In order to experimentally evaluate the extent to which such a feedback has an impact on their ability to acquire a skill, we used it to teach users to perform simple motor tasks. Results (N=53 participants) revealed that with this feedback, 17% did not manage to learn the skill. This suggests that current BCI feedback is most probably suboptimal to teach a skill. A sub-group of our participants (N=20) then took part in a motor-imagery based BCI experiment. Results showed that those who struggled during the first experiment improved in performance during the second, while the others did not. We hypothesised that these results are linked to the considerable cognitive resources required to process this feedback <ref xlink:href="#potioc-2016-bid14" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
      <p>It should be noted that there are many connections between BCI user training, and neurofeedback training for clinical applications, both field aiming at training their users to perform self regulation of their brain activity. We have therefore shown how these two field share fundamental research questions on BCI user training, and how they can both benefit from each other <ref xlink:href="#potioc-2016-bid15" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
    </subsection>
    <subsection id="uid84" level="1">
      <bodyTitle>Improving Mental Imagery BCI user-training &amp; feedback</bodyTitle>
      <subsection id="uid85" level="2">
        <bodyTitle>Spatial Ability Training Protocol</bodyTitle>
        <p><b>Participants</b> : Suzy Teillet, Camille Jeunet, Fabien Lotte</p>
        <p>The results of one of our previous studies suggested that users' MI-BCI performance correlates with their spatial abilities <ref xlink:href="#potioc-2016-bid16" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>, which is consistent with the literature. This result was replicated in a second study in a pure motor-imagery based BCI <ref xlink:href="#potioc-2016-bid14" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. We thus decided to explore the potential causal relationship between both: would an improvement of spatial abilities lead to better MI-BCI performances? To try to answer this question, we designed and implemented a spatial ability (SA) training procedure (see Figure <ref xlink:href="#uid86" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>). Then, we performed two user studies to validate the SA training procedure: results suggest that it efficiently improves participants' SA <ref xlink:href="#potioc-2016-bid17" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. Consequently, we included this SA training procedure in an MI-BCI protocol. Results (N=24) showed no difference in classification accuracy between participants performing 6 MI-BCI sessions and those performing 3 SA and 3 MI-BCI sessions. Nonetheless, SA training intensity impacted users' progression, and neurophysiological analyses provided us with valuable insights into brain pattern evolution throughout the training process.</p>
        <object id="uid86">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/FigSATraining.png" type="float" width="341.6013pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>One item per exercise included in the Spatial Ability training: the shape on top is the target, and the participant must identify the two shapes that are identical to the target among the four below.From the left to the right are displayed the <i>shapes, matrices, cubes, arms</i> exercises.</caption>
        </object>
      </subsection>
      <subsection id="uid87" level="2">
        <bodyTitle> PEANUT: Personalised Emotional Agent
for Neurotechnology User-Training </bodyTitle>
        <p><b>Participants</b> : Léa Pillette, Camille Jeunet, Boris Mansencal, Fabien Lotte</p>
        <object id="uid88">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/ImagePeanut10.jpg" type="float" height="113.81102pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>A participant taking part in a Brain-Computer Interface training process during which he learns to perform different mental imagery tasks (here, imagining a left-hand movement) to control the system. Along the training, PEANUT (on the left) provides the user with social presence and emotional support adapted to his performance and progression.</caption>
        </object>
        <p>Mental-Imagery based Brain-Computer Interfaces (MI-BCI) are neurotechnologies enabling users to control applications using their brain activity alone. These neurotechnologies are very promising. However, existing training protocols do not enable every user to acquire the skills needed to use them. Indeed, those protocols are not consonant with psychological field recommendations. In particular, the current protocols do not provide social presence and emotional support to the user. Therefore, we designed and tested PEANUT, the first Learning Companion dedicated to the improvement of MI-BCI user-training.
PEANUT has been designed throughout a combination of recommendations from the literature, the analysis of data from previous experiments and user-studies. He provides emotional support using spoken sentences, such as "`C'est avec la pratique que l'on progresse"', and facial expressions.
Experiments were conducted in order to assess his influence on user's performance and experience. The first results indicate that PEANUT improves the user experience. Indeed, people who trained with PEANUT found it was easier to learn and memorize how to use the MI-BCI system and rated themselves more efficient and effective than participants who had no learning companion. These results indicate that using PEANUT does benefit MI-BCI user training.
Future research will keep focusing on how to provide adapted cognitive and emotional feedback to MI-BCI users thanks to the use of learning companions.</p>
      </subsection>
    </subsection>
    <subsection id="uid89" level="1">
      <bodyTitle>Adaptive BCI training and operation</bodyTitle>
      <p><b>Participants</b> : Jelena Mladenović, Jérémy Frey, Fabien Lotte</p>
      <subsection id="uid90" level="2">
        <bodyTitle>A generic framework for adaptive EEG-based BCI training and operation</bodyTitle>
        <p>There are two main approaches engaged in improving BCI systems: (i) improving the machine learning techniques, and the newly introduced (ii) improving human learning, by using the knowledge from instructional design and positive psychology. Both agree that the system needs to be adapted to the user but rely on different sources of adaptation: the machine for the former and the brain for the latter. In particular, machine learning algorithms should adapt to non-stationary brain signals, while human learning approaches should adapt the system to the various users' skills and profiles. Including both aspects of adaptation would give rise to a system ready to be used in real life conditions.
However, a major obstacle lies in the large spectrum of sources of variability during BCI use, ranging from (i) imperfect recording conditions (e.g., environmental noise, humidity, static electricity etc. to (ii) the fluctuations in the user's psychophysiological states, due to e.g., fatigue, motivation or attention. For these reasons a BCI has not yet proved to be reliable enough to be used outside the laboratory. Particularly, it is still almost impossible to create one BCI design effective for every user, due to large inter subject variability. Therefore, the main concerns are to create a more robust system with the same high level of success for everyone, at all times, and to improve the current usability of the system. This calls for adaptive BCI training and operation.</p>
        <p>We propose a conceptual framework which encompasses most important approaches to fit them in such a way that a reader can clearly visualize which elements can be adapted and for what reason. In the interest of having a clear review of the existing adaptive BCIs, this framework considers adaptation approaches for both the user and the machine, i.e., referring to instructional design observations as well as the usual machine learning techniques. It provides not only a coherent review of the extensive literature but also enables the reader to perceive gaps and flaws in current BCI systems, which would, hopefully, bring novel solutions for an overall improvement.</p>
        <p>The framework (see Figure <ref xlink:href="#uid91" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>) has a hierarchical structure, from the lowest level elements which endure rapid changes, to the highest level elements which change at a much slower rate.
It is comprised of: (i) one or several BCI systems/pipelines; (ii) a user model, whose elements are arranged according to different time scales ; (iii) a task model, enabling the system adaptation with respect to the user model; (iv) the conductor, an intelligent agent which implements the adaptive control of the whole system. A book chapter on this framework was submitted to a handbook on BCI.</p>
        <object id="uid91">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/framework.png" type="float" height="170.71652pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>Multiple signals (input) maybe observed and processed in parallel in order to infer complementary states or intents, at the trial wise time scale. All the information extracted from these parallel pipelines may trigger the up-dating of the user or task model, which in turn might yield a decision from the conductor to take action, such as adapting one of the systems or the output, or modifying the task or the user model.</caption>
        </object>
      </subsection>
      <subsection id="uid92" level="2">
        <bodyTitle>Adapting BCI Feedback based on Flow Theory</bodyTitle>
        <p>Using BCI systems can be very frustrating for people because it is not trivial and so it takes time to master. Differently from other learning procedures, BCIs do not have enough, if any explanatory feedback in assisting the learning of users. Also, as the feedback is not engaging the user's mind might easily wander off, which highly affects the system's accuracy as well as the person's learning pace. For this reason it takes more time to train a user to understand the procedure and have control over the system. Hence, we want to create an immersive and playful environment to attract the user's attention and help them learn with less effort and frustration.</p>
        <p>We rely on the theory of Flow, introduced by Csikszentmihalyi in the 1970s. Flow is a state of enjoyment while effortlessly focused on a task so immersive that one looses the perception of time.
In order to fulfil these requirements, we choose the users to be involved in an open-source video game called Tux Racer. Also, to ensure the maximal attention of the users, the game difficulty adapts according to users performance in real-time.</p>
        <object id="uid93">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/tux.jpg" type="float" height="113.81102pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>A subject using motor imagery, i.e., imagining left or right hand movements to manipulate Tux to catch fish.</caption>
        </object>
      </subsection>
    </subsection>
    <subsection id="uid94" level="1">
      <bodyTitle>Brain-Computer Interfaces 1 and 2: foundations, methods, practice and applications</bodyTitle>
      <p><b>Participants</b> : Jérémy Frey, Camille Jeunet, Fabien Lotte</p>
      <p>Together with Maureen Clerc (Inria Sophia) and Laurent Bougrain (Inria Nancy), we co-edited the first book on Brain-Computer Interfaces in French <ref xlink:href="#potioc-2016-bid0" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>, <ref xlink:href="#potioc-2016-bid1" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>, this book being also translated into English <ref xlink:href="#potioc-2016-bid18" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>, <ref xlink:href="#potioc-2016-bid19" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.
It is published in two volumes, and co-written with researchers from all over France from many disciplines related to BCI. It covers both theoretical and practical aspects, as well as the neuroscience, mathematics, psychology, computer science, engineering, and ethical aspects of BCI. It is aimed at being a key resource for anyone who wants to start BCI research or want to deepen their knowledge in the many aspects of this exciting discipline.</p>
      <object id="uid95">
        <table>
          <tr>
            <td>
              <ressource xlink:href="IMG/livreBCI.jpg" type="float" height="85.35826pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
          </tr>
        </table>
        <caption>The two volumes of the French version of the BCI book we edited.</caption>
      </object>
    </subsection>
  </resultats>
  <contrats id="uid96">
    <bodyTitle>Bilateral Contracts and Grants with Industry</bodyTitle>
    <subsection id="uid97" level="1">
      <bodyTitle>Bilateral Contracts with Industry</bodyTitle>
      <p><b>Interactive Collaboration in Virtual Reality for Aerospace Scenarii</b>:</p>
      <sanspuceslist>
        <li id="uid98">
          <p noindent="true">Duration: 2014-2017</p>
        </li>
        <li id="uid99">
          <p noindent="true">PhD Thesis of Damien Clergeaud</p>
        </li>
        <li id="uid100">
          <p noindent="true">Partners: Airbus Group</p>
        </li>
        <li id="uid101">
          <p noindent="true">The Airbus company regularly uses virtual reality for design, manufacturing and maintenance. We
work with them on collaborative interaction in order to enable an efficient collaboration between
operators immersed in the virtual environment from remote locations and with heterogeneous
equipment. More precisely, we have developped tools to point and manipulate objects, to remotely visualize the virtual environment, to be aware of remote manipulations and to describe tools and components trajectories (see Section <ref xlink:href="#uid66" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>).</p>
        </li>
      </sanspuceslist>
    </subsection>
  </contrats>
  <partenariat id="uid102">
    <bodyTitle>Partnerships and Cooperations</bodyTitle>
    <subsection id="uid103" level="1">
      <bodyTitle>Regional Initiatives</bodyTitle>
      <p><b>HOBIT: Hybrid Optical Bench for Innovative Teaching</b>:</p>
      <sanspuceslist>
        <li id="uid104">
          <p noindent="true">Duration: 2015-2017</p>
        </li>
        <li id="uid105">
          <p noindent="true">Funding: Idex CPU &amp; LAPHIA, and Inria ADT</p>
        </li>
        <li id="uid106">
          <p noindent="true">Partners: Université de Bordeaux (IUT mesures physiques) &amp; Université de Lorraine</p>
        </li>
        <li id="uid107">
          <p noindent="true">The goal of the Hobit project (Hybrid Optical Bench for Innovative Teaching) is to design a hybrid optical bench that benefits from both the physical and the virtual worlds to enhance teaching and training in the field of optics and photonics (See Section <ref xlink:href="#uid58" location="intern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>).</p>
        </li>
        <li id="uid108">
          <p noindent="true">website: <ref xlink:href="https://project.inria.fr/hobit" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>project.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hobit</ref></p>
        </li>
      </sanspuceslist>
      <p> </p>
      <p noindent="true">
        <b>OpenStreetMap</b>
      </p>
      <p noindent="true">Collaboration with Marina Duféal (Assistant Professor in Geography at PASSAGES, UMR 5319, Univ. Bordeaux Montaigne) and Vincent Bergeot (Num&amp;Lib) regarding contribution to OpenStreetMap. We have jointly organized a cartopartie for “Fête de la Science2016” at Inria Bordeaux.
</p>
    </subsection>
    <subsection id="uid109" level="1">
      <bodyTitle>National Initiatives</bodyTitle>
      <p><b>eTAC: Tangible and Augmented Interfaces for Collaborative Learning</b>:</p>
      <sanspuceslist>
        <li id="uid110">
          <p noindent="true">Funding: EFRAN</p>
        </li>
        <li id="uid111">
          <p noindent="true">Duration: 2017-2021</p>
        </li>
        <li id="uid112">
          <p noindent="true">Coordinator: Université de Lorraine</p>
        </li>
        <li id="uid113">
          <p noindent="true">Local coordinator: Martin Hachet</p>
        </li>
        <li id="uid114">
          <p noindent="true">Partners: Université de Lorraine, Inria, ESPE, Canopé, OpenEdge,</p>
        </li>
        <li id="uid115">
          <p noindent="true">the e-TAC project proposes to investigate the potential
of technologies ”beyond the mouse” in order to promote collaborative learning in a school context.
In particular, we will explore augmented reality and tangible interfaces, which supports active learning and favors social interaction.</p>
        </li>
      </sanspuceslist>
      <p> </p>
      <p noindent="true"><b>ANR Rebel</b>:</p>
      <sanspuceslist>
        <li id="uid116">
          <p noindent="true">Duration: 2016-2019</p>
        </li>
        <li id="uid117">
          <p noindent="true">Coordinator: Fabien Lotte</p>
        </li>
        <li id="uid118">
          <p noindent="true">Funding: ANR Jeune Chercheur Jeune Chercheuse Project</p>
        </li>
        <li id="uid119">
          <p noindent="true">Partners: Disabilities and Nervous Systems Laboratory Bordeaux</p>
        </li>
        <li id="uid120">
          <p noindent="true">Brain-Computer Interfaces (BCI) are communication systems that enable their users to send commands to computers through brain activity only. While BCI are very promising for assistive technologies or human-computer interaction (HCI), they are barely used outside laboratories, due to a poor reliability. Designing a BCI requires 1) its user to learn to produce distinct brain activity patterns and 2) the machine to recognize these patterns using signal processing. Most research efforts focused on signal processing. However, BCI user training is as essential but is only scarcely studied and based on heuristics that do not satisfy human learning principles. Thus, currently poor BCI reliability is probably due to suboptimal user training. Thus, we propose to create a new generation of BCI that apply human learning principles in their design to ensure the users can learn high quality control skills, hence making BCI reliable. This could change HCI as BCI have promised but failed to do so far.</p>
        </li>
      </sanspuceslist>
      <p> </p>
      <p noindent="true"><b>ANR Project ISAR</b>:</p>
      <sanspuceslist>
        <li id="uid121">
          <p noindent="true">Duration: 2014-2017</p>
        </li>
        <li id="uid122">
          <p noindent="true">Coordinator: Martin Hachet</p>
        </li>
        <li id="uid123">
          <p noindent="true">Partners: LIG-CNRS (Grenoble), Diotasoft (Paris)</p>
        </li>
        <li id="uid124">
          <p noindent="true">Acronym: Interaction en Réalité Augmentée Spatiale / Interacting with Spatial Augmented Reality</p>
        </li>
        <li id="uid125">
          <p noindent="true">The ISAR project (Interaction with Spatial Augmented Reality) focuses on the design, implementation, and evaluation of new paradigms to improve
interaction with the digital world when digital content is directly projected onto physical objects. It opens new perspectives
for exciting tomorrow’s applications, beyond traditional screen-based applications.</p>
        </li>
        <li id="uid126">
          <p noindent="true">website: <ref xlink:href="https://team.inria.fr/potioc/scientific-subjects/papart/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>team.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>potioc/<allowbreak/>scientific-subjects/<allowbreak/>papart/</ref></p>
        </li>
      </sanspuceslist>
      <p> </p>
      <p noindent="true"><b>Inria ADT Artik</b>:</p>
      <sanspuceslist>
        <li id="uid127">
          <p noindent="true">Duration: 2014-2016</p>
        </li>
        <li id="uid128">
          <p noindent="true">Coordinator: Jérémy Laviole &amp; Martin Hachet</p>
        </li>
        <li id="uid129">
          <p noindent="true">The Artik projet is focused on the development of Papart (Paper Augmented Reality Toolkit).
Papart is a toolkit that enables projector/cameras (ProCam) and depth camera to work together to
create interactive surfaces. It works with comsumer-available hardware and enables tabletop
interactions, although high-end cameras and projectors are also well supported.
Here are the major advances of the developments of 2015:
The hardware is now managed with a dedicated application, each Papart application
is now hardware agnostic.
Extrinsic calibration of projector / color and depth cameras can be done with any application
running, the calibration processing is now below 2 minutes.
The touch detection can be tweaked to fit any suface: it has been tested on a table, wall, and floor with
respectively finger, hand, and foot interaction.
This project relies on open source software, we also maintain the support of Maven distribution
for the Processing project.</p>
        </li>
        <li id="uid130">
          <p noindent="true">website: <ref xlink:href="https://project.inria.fr/papart/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>project.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>papart/</ref></p>
        </li>
      </sanspuceslist>
      <p> </p>
      <p noindent="true"><b>Inria ADT OpenViBE-X</b>:</p>
      <sanspuceslist>
        <li id="uid131">
          <p noindent="true">Duration: 2014-2016</p>
        </li>
        <li id="uid132">
          <p noindent="true">Partners: Inria teams Hybrid and Athena</p>
        </li>
        <li id="uid133">
          <p noindent="true">Coordinator: Maureen Clerc (Inria Sophia Antipolis)</p>
        </li>
        <li id="uid134">
          <p noindent="true">This is the follow-up project of OpenViBE-NT</p>
        </li>
        <li id="uid135">
          <p noindent="true">website: <ref xlink:href="http://openvibe.inria.fr" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>openvibe.<allowbreak/>inria.<allowbreak/>fr</ref></p>
        </li>
      </sanspuceslist>
      <p> </p>
      <p noindent="true"><b>Inria Project Lab BCI-LIFT</b>:</p>
      <sanspuceslist>
        <li id="uid136">
          <p noindent="true">Duration: 2015-2018</p>
        </li>
        <li id="uid137">
          <p noindent="true">Partners: Inria team Athena (Inria Sophia-Antipolis), Inria team Hybrid (Inria Rennes), Inria team Neurosys (Inria Nancy), LITIS (Université de Rouen), Inria team DEMAR (Inria Sophia-Antipolis), Inria team MINT (Inria Lille), DyCOG (INSERM Lyon)</p>
        </li>
        <li id="uid138">
          <p noindent="true">Coordinator: Maureen Clerc (Inria Sophia Antipolis)</p>
        </li>
        <li id="uid139">
          <p noindent="true">The aim is to reach a next generation of non-invasive Brain-Computer Interfaces (BCI), more specifically BCI that are easier to appropriate, more efficient, and suit a larger number of people. With this concern of usability as our driving objective, we will build non-invasive systems that benefit from advanced signal processing and machine learning methods, from smart interface design, and where the user immediately receives supportive feedback. What drives this project is the concern that a substantial proportion of human participants is currently categorized “BCI-illiterate” because of their apparent inability to communicate through BCI. Through this project we aim at making it easier for people to learn to use the BCI, by implementing appropriate machine learning methods and developping user training scenarios.</p>
        </li>
        <li id="uid140">
          <p noindent="true">website: <ref xlink:href="http://bci-lift.inria.fr/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>bci-lift.<allowbreak/>inria.<allowbreak/>fr/</ref></p>
        </li>
      </sanspuceslist>
      <p> </p>
      <p noindent="true"><b>Helios</b>:</p>
      <sanspuceslist>
        <li id="uid141">
          <p noindent="true">Duration: 2015-2016</p>
        </li>
        <li id="uid142">
          <p noindent="true">Partners: Université de Lorraine</p>
        </li>
        <li id="uid143">
          <p noindent="true">Funding: SATT Nancy Grand Est</p>
        </li>
        <li id="uid144">
          <p noindent="true">Coordinator: Stéphanie Fleck (Université de Lorraine)</p>
        </li>
        <li id="uid145">
          <p noindent="true">The Helios project aims to provide a methodology and innovative media for the improvement of learning of basic astronomical phenomena for school groups (8-11 years). As part of this project, Potioc has focused on the development of the final application for augmented reality based and 3D manipulation, for providing a high-fidelity prototype.</p>
        </li>
      </sanspuceslist>
      <p> </p>
    </subsection>
    <subsection id="uid146" level="1">
      <bodyTitle>European Initiatives</bodyTitle>
      <subsection id="uid147" level="2">
        <bodyTitle>FP7 &amp; H2020 Projects</bodyTitle>
        <sanspuceslist>
          <li id="uid148">
            <p noindent="true">Program: ERC Starting Grant</p>
          </li>
          <li id="uid149">
            <p noindent="true">Project acronym: BrainConquest</p>
          </li>
          <li id="uid150">
            <p noindent="true">Project title: Boosting Brain-Computer Communication with High Quality User Training</p>
          </li>
          <li id="uid151">
            <p noindent="true">Duration: 2017-2021</p>
          </li>
          <li id="uid152">
            <p noindent="true">Coordinator: Fabien Lotte</p>
          </li>
          <li id="uid153">
            <p noindent="true">Abstract: Brain-Computer Interfaces (BCIs) are communication systems that enable users to send commands to computers through brain signals only, by measuring and processing these signals. Making computer control possible without any physical activity, BCIs have promised to revolutionize many application areas, notably assistive technologies, e.g., for wheelchair control, and man-machine interaction. Despite this promising potential, BCIs are still barely used outside laboratories, due to their current poor reliability. For instance, BCIs only using two imagined hand movements as mental commands decode, on average, less than 80A BCI should be considered a co-adaptive communication system: its users learn to encode commands in their brain signals (with mental imagery) that the machine learns to decode using signal processing. Most research efforts so far have been dedicated to decoding the commands. However, BCI control is a skill that users have to learn too. Unfortunately how BCI users learn to encode the commands is essential but is barely studied, i.e., fundamental knowledge about how users learn BCI control is lacking. Moreover standard training approaches are only based on heuristics, without satisfying human learning principles. Thus, poor BCI reliability is probably largely due to highly suboptimal user training.
In order to obtain a truly reliable BCI we need to completely redefine user training approaches. To do so, I propose to study and statistically model how users learn to encode BCI commands. Then, based on human learning principles and this model, I propose to create a new generation of BCIs which ensure that users learn how to successfully encode commands with high signal-to-noise ratio in their brain signals, hence making BCIs dramatically more reliable. Such a reliable BCI could positively change man-machine interaction as BCIs have promised but failed to do so far.</p>
          </li>
        </sanspuceslist>
      </subsection>
      <subsection id="uid154" level="2">
        <bodyTitle>Collaborations in European Programs, Except FP7 &amp; H2020</bodyTitle>
        <sanspuceslist>
          <li id="uid155">
            <p noindent="true">Program: ERASMUS+</p>
          </li>
          <li id="uid156">
            <p noindent="true">Project acronym: VISTE</p>
          </li>
          <li id="uid157">
            <p noindent="true">Project title: Empowering spatial thinking of students with visual impairment</p>
          </li>
          <li id="uid158">
            <p noindent="true">Duration: 2016-2019</p>
          </li>
          <li id="uid159">
            <p noindent="true">Coordinator: National Technical University of Athens (Greece)</p>
          </li>
          <li id="uid160">
            <p noindent="true">Other partners: Intrasoft International SA (Greece), Casa Corpolui Didatic Cluj (Romania), Liceul Special pentru Deficienti de Vedere Cluj-Napoca (Romania), Eidiko Dimotiko Sxolio Tiflon Kallitheas (Greece)</p>
          </li>
          <li id="uid161">
            <p noindent="true">Abstract: VISTE addresses inclusion and diversity through an innovative, integrated approach for enhancing spatial thinking focusing on the unique needs of students with blindness or visual impairment. However, since spatial thinking is a critical competence for all students, the VISTE framework and associated resources and tools will focus on cultivating this competence through collaborative learning of spatial concepts and skills both for sighted and visually impaired students to foster inclusion within mainstream education. The VISTE project will introduce innovative educational practices for empowering students with blindness or visual impairment with spatial skills through specially designed educational scenarios and learning activities as well as through a spatial augmented reality prototype to support collaborative learning of spatial skills both for sighted and visually impaired students.</p>
          </li>
        </sanspuceslist>
      </subsection>
    </subsection>
    <subsection id="uid162" level="1">
      <bodyTitle>International Initiatives</bodyTitle>
      <subsection id="uid163" level="2">
        <bodyTitle>Inria International Partners</bodyTitle>
        <subsection id="uid164" level="3">
          <bodyTitle>Informal International Partners</bodyTitle>
          <sanspuceslist>
            <li id="uid165">
              <p noindent="true">Prof. James Landay and Dr. Jessica Cauchard at the Stanford HCI Group (USA) on interaction with maps projected from drones</p>
            </li>
            <li id="uid166">
              <p noindent="true">Prof. Niels Henze (University Stuttgart,Germany) and Prof. Katrin Wolf (Hamburg University of Applied Science, Germany) on mobile applications for visually impaired people</p>
            </li>
            <li id="uid167">
              <p noindent="true">Prof. Pierre Dillenbourg (EPFL, Switzerland) on HCI for Education</p>
            </li>
          </sanspuceslist>
        </subsection>
      </subsection>
      <subsection id="uid168" level="2">
        <bodyTitle>Participation in Other International Programs</bodyTitle>
        <sanspuceslist>
          <li id="uid169">
            <p noindent="true">DGA-DSTL Project with UK, “Assessing and Optimising Human-Machine Symbiosis through Neural signals for Big Data Analytics”, 2014-2018</p>
          </li>
        </sanspuceslist>
      </subsection>
    </subsection>
    <subsection id="uid170" level="1">
      <bodyTitle>International Research Visitors</bodyTitle>
      <subsection id="uid171" level="2">
        <bodyTitle>Visits of International Scientists</bodyTitle>
        <sanspuceslist>
          <li id="uid172">
            <p noindent="true">Andreas Meinel, University of Freiburg, Germany, Apr. and Dec. 2016</p>
          </li>
          <li id="uid173">
            <p noindent="true">Katrin Wolf, University of Art and Design, Berlin, Germany, Jul. 2016</p>
          </li>
        </sanspuceslist>
      </subsection>
      <subsection id="uid174" level="2">
        <bodyTitle>Visits to International Teams</bodyTitle>
        <subsection id="uid175" level="3">
          <bodyTitle>Research Stays Abroad</bodyTitle>
          <sanspuceslist>
            <li id="uid176">
              <p noindent="true">Fabien Lotte - Visting scientist At RIKEN Brain Science Institute, Cichocki's advanced Brain Signal Processing Laboratory, Wakoshi, Japan, October-November 2016</p>
            </li>
            <li id="uid177">
              <p noindent="true">Camille Jeunet - Uniersity of Sussex (Brigthon - UK) 01/11/2015 - 30/01/2016</p>
            </li>
            <li id="uid178">
              <p noindent="true">Camille Jeunet - UQAM (Montréal - CA) 10/06/2016 - 10/07/2016</p>
            </li>
          </sanspuceslist>
        </subsection>
      </subsection>
    </subsection>
  </partenariat>
  <diffusion id="uid179">
    <bodyTitle>Dissemination</bodyTitle>
    <subsection id="uid180" level="1">
      <bodyTitle>Promoting Scientific Activities</bodyTitle>
      <subsection id="uid181" level="2">
        <bodyTitle>Scientific Events Organisation</bodyTitle>
        <subsection id="uid182" level="3">
          <bodyTitle>General Chair, Scientific Chair</bodyTitle>
          <sanspuceslist>
            <li id="uid183">
              <p noindent="true">“2nd International OpenViBE workshop”, International BCI meeting 2016, Asilomar, CA, USA,2016 (Fabien Lotte)</p>
            </li>
          </sanspuceslist>
        </subsection>
        <subsection id="uid184" level="3">
          <bodyTitle>Member of the Organizing Committees</bodyTitle>
          <sanspuceslist>
            <li id="uid185">
              <p noindent="true">”IHM et Education”, workshop at IHM conference, Fribourg, Switzerland, Nov. 2016 (Martin Hachet, Anke Brock)</p>
            </li>
            <li id="uid186">
              <p noindent="true">“2nd InternationalOpenViBE workshop”, International BCI meeting 2016, Asilomar, CA, USA,2016 (Fabien Lotte, Camille Jeunet, Jérémy Frey)</p>
            </li>
            <li id="uid187">
              <p noindent="true">“What’s wrong with us? Roadblocks and pitfalls in designing BCI applications”, International BCI meeting, Asilomar, CA, USA, 2016 (Fabien Lotte)</p>
            </li>
            <li id="uid188">
              <p noindent="true">Special session “Human Factors and performance metrics for BMI Training and Operation”,IEEE SMC 2016, Budapest, Hungary, (Fabien Lotte, Camille Jeunet)</p>
            </li>
            <li id="uid189">
              <p noindent="true">Diversity Co-Chair at the ACM CHI’16 conference, San José, USA, 05/2016 (Anke Brock)</p>
            </li>
            <li id="uid190">
              <p noindent="true">Microsoft Student Research Competition at the ACM ASSETS’16 conference, Reno,USA, 10/2016 (Anke Brock)</p>
            </li>
          </sanspuceslist>
        </subsection>
      </subsection>
      <subsection id="uid191" level="2">
        <bodyTitle>Scientific Events Selection</bodyTitle>
        <subsection id="uid192" level="3">
          <bodyTitle>Member of the Conference Program Committees</bodyTitle>
          <sanspuceslist>
            <li id="uid193">
              <p noindent="true">IEEE VR 2017 (Martin Hachet)</p>
            </li>
            <li id="uid194">
              <p noindent="true">Eurographics STAR 2017 (Martin Hachet)</p>
            </li>
            <li id="uid195">
              <p noindent="true">IHM 2016 (Martin Hachet)</p>
            </li>
            <li id="uid196">
              <p noindent="true">Mobile and Ubiquitous Multimedia MUM 2016 (Anke Brock)</p>
            </li>
            <li id="uid197">
              <p noindent="true">Mobile and Ubiquitous Multimedia MUM 2016 Poster Committee (David Furió, Anke Brock)</p>
            </li>
            <li id="uid198">
              <p noindent="true">1st International Neuroadaptive Technology Conference 2017 (Fabien Lotte)</p>
            </li>
            <li id="uid199">
              <p noindent="true">7th International Brain-Computer Interface Conference, 2017 (Fabien Lotte)</p>
            </li>
            <li id="uid200">
              <p noindent="true">International Conference on Systems, Man and Cybernetics, Brain-MachineInterface Workshop (IEEE SMC) 2016 (Fabien Lotte, Camille Jeunet)</p>
            </li>
            <li id="uid201">
              <p noindent="true">International workshop on Pattern Recognition in NeuroImaging (PRNI) 2016 (Fabien Lotte)</p>
            </li>
            <li id="uid202">
              <p noindent="true">International Brain-Computer Interface Meeting 2016 (publicity committee+ review committee) (Fabien Lotte)</p>
            </li>
            <li id="uid203">
              <p noindent="true">7th Augmented Human International Conference, 2016 (Fabien Lotte)</p>
            </li>
            <li id="uid204">
              <p noindent="true">8th Augmented Human International Conference, 2017 (Fabien Lotte)</p>
            </li>
            <li id="uid205">
              <p noindent="true">ACM ASSETS 2016 (Anke Brock)</p>
            </li>
            <li id="uid206">
              <p noindent="true">Computer Applications and Quantitive Methods in Archaeology 2016 (CAA) (Pascal Guitton)</p>
            </li>
            <li id="uid207">
              <p noindent="true">8th Augmented Human International Conference, 2017 (Fabien Lotte)</p>
            </li>
            <li id="uid208">
              <p noindent="true">7th International Brain-Computer Interface Conference, 2017 (Camille Jeunet)</p>
            </li>
          </sanspuceslist>
        </subsection>
        <subsection id="uid209" level="3">
          <bodyTitle>Reviewer</bodyTitle>
          <sanspuceslist>
            <li id="uid210">
              <p noindent="true">ACM SIGGRAPH 2016 (Martin Hachet)</p>
            </li>
            <li id="uid211">
              <p noindent="true">IEEE 3DUI 2017 (Martin Hachet)</p>
            </li>
            <li id="uid212">
              <p noindent="true">ACM ISS 2016 (Joan Sol Roo)</p>
            </li>
            <li id="uid213">
              <p noindent="true">ACM CHI 2016 (Fabien Lotte, Anke Brock, Camille Jeunet, Jérémy Frey)</p>
            </li>
            <li id="uid214">
              <p noindent="true">ACM CHI 2017 (Fabien Lotte, Camille Jeunet, Anke Brock, David Furió, Camille Jeunet, Jérémy Frey)</p>
            </li>
            <li id="uid215">
              <p noindent="true">Augmented Humans 2016 (Fabien Lotte)</p>
            </li>
            <li id="uid216">
              <p noindent="true">International BCI Meeting 2016 (Fabien Lotte)</p>
            </li>
            <li id="uid217">
              <p noindent="true">EICS 2016 (Fabien Lotte)</p>
            </li>
            <li id="uid218">
              <p noindent="true">IJCNN 2016 (Fabien Lotte)</p>
            </li>
            <li id="uid219">
              <p noindent="true">PRNI 2016 (Fabien Lotte)</p>
            </li>
            <li id="uid220">
              <p noindent="true">IEEE SMC 2016 (Fabien Lotte, Camille Jeunet)</p>
            </li>
            <li id="uid221">
              <p noindent="true">Eurohaptics 2016 (Anke Brock)</p>
            </li>
            <li id="uid222">
              <p noindent="true">Handicap 2016 (Anke Brock)</p>
            </li>
            <li id="uid223">
              <p noindent="true">HapticsSymposium 2016 (Anke Brock)</p>
            </li>
            <li id="uid224">
              <p noindent="true">ACM IHM 2016 (Anke Brock)</p>
            </li>
            <li id="uid225">
              <p noindent="true">ACM MobileHCI 2016 (Anke Brock)</p>
            </li>
            <li id="uid226">
              <p noindent="true">ACM NordiCHI 2016 (Anke Brock)</p>
            </li>
            <li id="uid227">
              <p noindent="true">ACM TEI 2016 (Anke Brock)</p>
            </li>
            <li id="uid228">
              <p noindent="true">ACM Ubicomp 2016 (Anke Brock)</p>
            </li>
            <li id="uid229">
              <p noindent="true">ACM UIST 2016 (Anke Brock)</p>
            </li>
          </sanspuceslist>
        </subsection>
      </subsection>
      <subsection id="uid230" level="2">
        <bodyTitle>Journal</bodyTitle>
        <subsection id="uid231" level="3">
          <bodyTitle>Member of the Editorial Boards</bodyTitle>
          <sanspuceslist>
            <li id="uid232">
              <p noindent="true">Associate Editor in Brain Computer Interfaces (Fabien Lotte)</p>
            </li>
            <li id="uid233">
              <p noindent="true">Associate Editor in Journal of Neural Engineering (Fabien Lotte)</p>
            </li>
            <li id="uid234">
              <p noindent="true">Review Editor for Frontiers in Robotics and AI (Martin Hachet)</p>
            </li>
            <li id="uid235">
              <p noindent="true">Review Editor for Frontiers in Neuroprosthetics (Fabien Lotte)</p>
            </li>
            <li id="uid236">
              <p noindent="true">Review Editor for Frontiers in Human-Media Interaction (Fabien Lotte)</p>
            </li>
            <li id="uid237">
              <p noindent="true">Guest Associate Editor, Frontiers in Robotics and AI, with D. Friedman, on “Brain-Computer Interfaces Technologies forRobotics and Virtual Reality”, 2016 (Fabien Lotte)</p>
            </li>
            <li id="uid238">
              <p noindent="true">TACCESS Special Issue for ASSETS'17 conference (Anke Brock)</p>
            </li>
          </sanspuceslist>
        </subsection>
        <subsection id="uid239" level="3">
          <bodyTitle>Reviewer - Reviewing Activities</bodyTitle>
          <sanspuceslist>
            <li id="uid240">
              <p noindent="true">Computer and Graphics (Martin Hachet)</p>
            </li>
            <li id="uid241">
              <p noindent="true">Computers and Education (David Furió)</p>
            </li>
            <li id="uid242">
              <p noindent="true">Computational Intelligence and Neurosciences (Fabien Lotte)</p>
            </li>
            <li id="uid243">
              <p noindent="true">Journal of Neural Engineering (Fabien Lotte)</p>
            </li>
            <li id="uid244">
              <p noindent="true">Frontiers in Neurosciences / Frontiers in ICT (Fabien Lotte)</p>
            </li>
            <li id="uid245">
              <p noindent="true">IEEE Transactions on Biomedical Engineering (Fabien Lotte)</p>
            </li>
            <li id="uid246">
              <p noindent="true">IEEE Transactions on Neural Systems and Rehabilitation Engineering (Fabien Lotte)</p>
            </li>
            <li id="uid247">
              <p noindent="true">Le Travail Humain (Fabien Lotte)</p>
            </li>
            <li id="uid248">
              <p noindent="true">ACM TOCHI (Fabien Lotte)</p>
            </li>
            <li id="uid249">
              <p noindent="true">Nature Scientific Reports (Fabien Lotte)</p>
            </li>
            <li id="uid250">
              <p noindent="true">ACM TACCESS (Anke Brock)</p>
            </li>
            <li id="uid251">
              <p noindent="true">Journal of Psychophysiology (Camille Jeunet)</p>
            </li>
            <li id="uid252">
              <p noindent="true">PLOS One (Camille Jeunet)</p>
            </li>
            <li id="uid253">
              <p noindent="true">Progress in Brain Research (Camille Jeunet)</p>
            </li>
            <li id="uid254">
              <p noindent="true">Transaction in Human Machine Systems (Camille Jeunet)</p>
            </li>
            <li id="uid255">
              <p noindent="true">Brain Science (Camille Jeunet)</p>
            </li>
          </sanspuceslist>
        </subsection>
      </subsection>
      <subsection id="uid256" level="2">
        <bodyTitle>Invited Talks</bodyTitle>
        <sanspuceslist>
          <li id="uid257">
            <p noindent="true">”Tangible Interaction and Spatial Augmented Reality for Education”, University of Sussex, Jan. 2016 (Martin Hachet).</p>
          </li>
          <li id="uid258">
            <p noindent="true">"Vers des interfaces cerveau-ordinateur populaires", Conférence What’s Up In Your Mind, Paris, Jun 2016 (Jérémy Frey)</p>
          </li>
          <li id="uid259">
            <p noindent="true">”Interaction Homme-Machine pour l’Education : au-delà de la souris et de l’écran”, Colloque Robotique et Education, Bordeaux, Juin 2016 (Martin Hachet).</p>
          </li>
          <li id="uid260">
            <p noindent="true">"Human Learning and Alternative Applications Towards Usable Electroencephalography-based Brain-Computer Interfaces", Max Planck Institute, Tuebingen, Germany, December 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid261">
            <p noindent="true">"The birth and scope of the BrainConquest ERC starting grant project", European Research Day 2016, Tokyo, Japan, November 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid262">
            <p noindent="true">"Towards Usable EEG-based Brain-Computer Interfaces", Tokyo University of Agriculture and Technology, Tokyo, Japan, November 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid263">
            <p noindent="true">“Principles and promises of EEG-based Brain-Computer Interface technologies”, 1st Iranian IBRO/APRC School of Cognitive Neuroscience, Tehran, Iran, September 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid264">
            <p noindent="true">“When Brain-Computer Interaction meets Educational Sciences”, LaBRI general assembly, Bordeaux,France, July 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid265">
            <p noindent="true">“Toward Usable Mental Imagery-based Brain-Computer Interfaces”, Brain and Spine Institute, Paris, France, July 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid266">
            <p noindent="true">« From Neurofeedback to Brain-Computer Interfaces », Neurofeedback workshop in Bordeaux, France, July 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid267">
            <p noindent="true">“Brain-Computer Interaction and Spatial Augmented Reality Research in Potioc team”, Concordia University, Montreal, Canada, June 2016 (Fabien Lotte, Camille Jeunet)</p>
          </li>
          <li id="uid268">
            <p noindent="true">“Latest research results in Brain-Computer Interfaces and Augmented Reality”, Brain and Computers Digital Media Conference, Center for Digital Media, Vancouver, Canada, June 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid269">
            <p noindent="true">« Educational Science Principles for Brain-Computer Interface Design”, Inserm Lyon, France, April 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid270">
            <p noindent="true">"Considering User Training and Alternative Applications to Design Usable EEG-based BCI Technologies”, EPFL, Center for Neuroprosthetics, Geneva, Switzerland, March 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid271">
            <p noindent="true">"Traitement des signaux cérébraux et classification des états mentaux", Journée scientifique de l'IFRATH "Interfaces Cerveau-Ordinateur", Paris, France, February 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid272">
            <p noindent="true">"Reciprocal learning between machines and humans for neurofeedback and BCI", Première Journée Nationale sur le Neurofeedback, Paris, France, January 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid273">
            <p noindent="true">“Interacting with spatial information” , Stanford HCI Group,Stanford University, USA, May 2016 (Anke Brock)</p>
          </li>
          <li id="uid274">
            <p noindent="true">“Interacting with spatial information” , HERE, Berkeley, USA , May 2016 (Anke Brock)</p>
          </li>
          <li id="uid275">
            <p noindent="true">“Interaction avec des cartes géographiques pour tous”, Immersion, Bordeaux, France, April 2016 (Anke Brock, Julia Chatain)</p>
          </li>
          <li id="uid276">
            <p noindent="true">“Interacting with spatial information” , University of Sussex, UK, February 2016 (Anke Brock)</p>
          </li>
          <li id="uid277">
            <p noindent="true">Animation table ronde, Journée URFIST « Vers de nouveaux paradigmes pour l’édition scientifique », Bordeaux, March 2016 (Pascal Guitton)</p>
          </li>
          <li id="uid278">
            <p noindent="true">"L’éthique en Sciences du numérique", Ecole du Management Inria, Paris, September 2016 (Pascal Guitton)</p>
          </li>
          <li id="uid279">
            <p noindent="true">"Physiological computing and spatial augmented reality: reflecting on inner state", Paris Open Source Summit, Paris, November 2016 (Jérémy Frey)</p>
          </li>
          <li id="uid280">
            <p noindent="true">"Transparence algorithmique et éthique", Journée nouveaux arrivants Inria, Saclay, December 2016 (Pascal Guitton)</p>
          </li>
          <li id="uid281">
            <p noindent="true">"Interfaces cerveau-ordinateur : quoi, pourquoi et comment ?", ENSCBP - Media Sciences, Bordeaux, Février 2016 (Camille Jeunet)</p>
          </li>
          <li id="uid282">
            <p noindent="true">"How Cognitive Sciences Can Contribute to Research in Brain-Computer Interaction", National Cognitive Science Conference 2016, San Diego (Camille Jeunet)</p>
          </li>
          <li id="uid283">
            <p noindent="true">"Understanding and Improving Mental-Imagery based Brain-Computer Interface User Training: Towards Efficient, Reliable and Accessible BCIs", University of Oldenburg, October 2016 (Camille Jeunet)</p>
          </li>
          <li id="uid284">
            <p noindent="true">"Understanding and Improving MI-BCI User-Training", University of Freiburg, Germany, November 2016 (Camille Jeunet)</p>
          </li>
        </sanspuceslist>
      </subsection>
      <subsection id="uid285" level="2">
        <bodyTitle>Leadership within the Scientific Community</bodyTitle>
        <sanspuceslist>
          <li id="uid286">
            <p noindent="true">IEEE 3DUI Steering committe - Leader (Martin Hachet)</p>
          </li>
        </sanspuceslist>
      </subsection>
      <subsection id="uid287" level="2">
        <bodyTitle>Scientific Expertise</bodyTitle>
        <sanspuceslist>
          <li id="uid288">
            <p noindent="true">Member of Jury for recruitment of Researcher (CR2-CR1) Inria Bordeaux (Martin Hachet)</p>
          </li>
          <li id="uid289">
            <p noindent="true">Expert for the Millennium Science Initiative research group evaluation, Chile (Fabien Lotte)</p>
          </li>
          <li id="uid290">
            <p noindent="true">Expert for the « Sapienza »,University of Rome, research projects, Italy (Fabien Lotte)</p>
          </li>
          <li id="uid291">
            <p noindent="true">Expert for the Partenariats Hubert-Curien (PHC) Germaine deStaël, France-Switzerland research projects (Fabien Lotte)</p>
          </li>
          <li id="uid292">
            <p noindent="true">Etude "Panorama du cyberespace dans 3 à 5 ans" - Workshop "Evolutions technologiques", CEIS, CREC (Fabien Lotte)</p>
          </li>
          <li id="uid293">
            <p noindent="true">Member of Inria Cellule de veille et de prospective (Pascal Guitton)</p>
          </li>
          <li id="uid294">
            <p noindent="true">Expert for Credit Impot Recherche (Martin Hachet)</p>
          </li>
          <li id="uid295">
            <p noindent="true">Member of the scientific committee of SCRIME (Martin Hachet)</p>
          </li>
        </sanspuceslist>
      </subsection>
      <subsection id="uid296" level="2">
        <bodyTitle>Research Administration</bodyTitle>
        <sanspuceslist>
          <li id="uid297">
            <p noindent="true">Member of Inria Bordeaux Sustainable Development Committee (Martin Hachet)</p>
          </li>
          <li id="uid298">
            <p noindent="true">Member of Inria Ethical Committee (COERLE) (Pascal Guitton)</p>
          </li>
          <li id="uid299">
            <p noindent="true">Member of Inria International Chairs Committee (Pascal Guitton)</p>
          </li>
          <li id="uid300">
            <p noindent="true">Responsable of Inria RA2020 Committee (new annual Activity Report) (Pascal Guitton)</p>
          </li>
          <li id="uid301">
            <p noindent="true">Member of Comité de Pilotage de Software Heritage (Pascal Guitton)</p>
          </li>
          <li id="uid302">
            <p noindent="true">Member of Comité de Pilotage Responsabilité Sociétale de l'Université, Université de Bordeaux (Pascal Guitton)</p>
          </li>
          <li id="uid303">
            <p noindent="true">Member of Conseil d'administration Institut d'Optique Graduate School (Pascal Guitton)</p>
          </li>
          <li id="uid304">
            <p noindent="true">Member of Commission de recrutement des Inspecteurs Généraux de l'Education Nationale (IGEN) (Pascal Guitton)</p>
          </li>
          <li id="uid305">
            <p noindent="true">Member of Inria Bordeaux Committee for Technological Developement (Fabien Lotte)</p>
          </li>
          <li id="uid306">
            <p noindent="true">Member of Inria Bordeaux Young Researchers Committe (Anke Brock)</p>
          </li>
        </sanspuceslist>
      </subsection>
    </subsection>
    <subsection id="uid307" level="1">
      <bodyTitle>Teaching - Supervision - Juries</bodyTitle>
      <subsection id="uid308" level="2">
        <bodyTitle>Teaching</bodyTitle>
        <sanspuceslist>
          <li id="uid309">
            <p noindent="true">Licence : Jérémy Frey, Unix and Programming, CM-TD, 74.67h eqtd, L1 Computer Science, University of Bordeaux, France</p>
          </li>
          <li id="uid310">
            <p noindent="true">Licence : Damien Clergeaud, Algorithme et Programmation, TD et TP, 32h eqtd, L1 Computer Science, University of Bordeaux, France</p>
          </li>
          <li id="uid311">
            <p noindent="true">Licence : Damien Clergeaud, Algorithmique des structures de données, TD et TP, 32h eqtd, L2 Computer Science, University of Bordeaux, France</p>
          </li>
          <li id="uid312">
            <p noindent="true">Licence : Camille Jeunet, Sciences humaines et méthodes, CM-TD, 18h eqtd, Licence MIASHS, University of Bordeaux, Franc</p>
          </li>
          <li id="uid313">
            <p noindent="true">Master : Jérémy Frey, Programming projects, TD, 18h eqtd, M1 Computer Science, University of Bordeaux, France</p>
          </li>
          <li id="uid314">
            <p noindent="true">Master : Pascal Guitton, Virtual and Augmented Realities, CM, 36h eqtd, M2 Computer Science, University of Bordeaux, France</p>
          </li>
          <li id="uid315">
            <p noindent="true">Master : Pascal Guitton, Digital accessibility, CM, 12h eqtd, M1 Cognitive Science, University of Bordeaux, France</p>
          </li>
          <li id="uid316">
            <p noindent="true">Master : Jérémy Frey, Programming projects, TD, 10h eqtd, M2 Computer Science, University of Bordeaux, France</p>
          </li>
          <li id="uid317">
            <p noindent="true">Master : Pascal Guitton, Assistive technologies, CM, 30h eqtd, M2 Cognitive Science, University of Bordeaux, France</p>
          </li>
          <li id="uid318">
            <p noindent="true">Master : Anke Brock, Virtual Reality and 3D Interaction, CM-TD, 7,5h eqtd, M2 Cognitive Science, University of Bordeaux, France</p>
          </li>
          <li id="uid319">
            <p noindent="true">Master : Martin Hachet, Virtual Reality and 3D Interaction, CM, 12h eqtd, M2 Cognitive Science, University of Bordeaux, France</p>
          </li>
          <li id="uid320">
            <p noindent="true">Master : Fabien Lotte, Virtual Reality and 3D Interaction, CM, 4h eqtd, M2 Cognitive Science, University of Bordeaux, France</p>
          </li>
          <li id="uid321">
            <p noindent="true">Master : Anke Brock, Interaction and Ergonomics, CM-TD, 10h eqtd, 3rd year (M2), Enseirb, Bordeaux, France</p>
          </li>
          <li id="uid322">
            <p noindent="true">Master : Martin Hachet, Interaction and Ergonomics, CM-TD, 8h eqtd, 3rd year (M2), Enseirb, Bordeaux, France</p>
          </li>
          <li id="uid323">
            <p noindent="true">Master: Fabien Lotte, Virtual Reality, Accesibility and Brain-Computer Interfaces, 4h eqtd, 3rd year (M2), ENSSAT, Lannion, France</p>
          </li>
          <li id="uid324">
            <p noindent="true">Master: Fabien Lotte, Brain Computer Interfaces, 6h eqtd, 3rd year (M2), ESIEA, Laval, France</p>
          </li>
          <li id="uid325">
            <p noindent="true">Master : Anke Brock, Human-Computer Interaction, CM-TD, 12h eqtd, M2 SRI, Upsitech Toulouse, France</p>
          </li>
          <li id="uid326">
            <p noindent="true">Master: Fabien Lotte, Human-Computer Interactions, CM-TD, 7.5 eqtd, M1 Cognitive Sciences and Ergonomy, University of Bordeaux, France</p>
          </li>
          <li id="uid327">
            <p noindent="true">Master : Anke Brock, Accessibility of interactive systems, CM-TD, 6h eqtd, M2 IHM, ENAC and University Toulouse, France</p>
          </li>
          <li id="uid328">
            <p noindent="true">Master : Anke Brock, Accessibility of interactive systems, CM-TD, 6h eqtd, M2 Systèmes Mobiles Autonomes Communicants / Internet des Objets (Mobiles), University Bordeaux, France</p>
          </li>
          <li id="uid329">
            <p noindent="true">Master : Camille Jeunet, HCI and Human factors, CM-TD, 18h eqtd, M1 Sciences Cognitives and Ergonomie, University of Bordeaux, France</p>
          </li>
        </sanspuceslist>
        <sanspuceslist>
          <li id="uid330">
            <p noindent="true">MOOC : Pascal Guitton and Hélène Sauzéon, "Comment favoriser l'accessibilité numérique", 5 weeks, Plate-forme France Université Numérique (FUN), large audience, initial and continuous training, about 4000 registered people.</p>
          </li>
        </sanspuceslist>
      </subsection>
      <subsection id="uid331" level="2">
        <bodyTitle>Supervision</bodyTitle>
        <sanspuceslist>
          <li id="uid332">
            <p noindent="true">PhD: Camille Jeunet, “Improving User training approaches for Brain-Computer Interface", University of Bordeaux, Defense on December 2nd, 2016 (Martin Hachet, Fabien Lotte, co-supervision with Bernard N'Kaoua, and Sriram Subramanian)</p>
          </li>
          <li id="uid333">
            <p noindent="true">PhD in progress: Julia Chatain, "Design and evaluation of augmented geographic maps", University of Bordeaux, since September 2015 (Anke Brock and Martin Hachet)</p>
          </li>
          <li id="uid334">
            <p noindent="true">PhD in progress: Damien Clergeaud, "Collaborative interaction for aerospace scenarios", University of Bordeaux, since November 2014 (Pascal Guitton)</p>
          </li>
          <li id="uid335">
            <p noindent="true">PhD in progress: Joan Sol Roo, "Interaction with Spatial Augmented Reality", University of Bordeaux, since December 2014 (Martin Hachet)</p>
          </li>
          <li id="uid336">
            <p noindent="true">PhD in progress: Jelena Mladenovic,"User Modeling for Adaptive BCI training and operation", University of Bordeaux, since December 2015 (Fabien Lotte, co-supervised with Jérémie Mattout)</p>
          </li>
          <li id="uid337">
            <p noindent="true">PhD in progress: Pierre-Antoine Cinquin,"Design and Experimental Validation of Accessible E-learning systems for people with cognitive
disabilities", University of Bordeaux, since September 2016 (Hélène Sauzéon, Pascal Guitton)</p>
          </li>
          <li id="uid338">
            <p noindent="true">PhD in progress: Léa Pillette, "Redefining Formative Feedback in Brain-Computer Interface User Training", University of Bordeaux, since September 2016 (Fabien Lotte, Bernard N'Kaoua)</p>
          </li>
          <li id="uid339">
            <p noindent="true">PhD in progress: Lorraine Perronnet, “Neurofeedback and Brain Rehabilitation based on EEG and fMRI”, Rennes University, since January 2014 (Fabien Lotte, co-supervision with Anatole Lécuyer, Christian Barillot, Inria Rennes and Maureen Clerc, Inria Sophia Antipolis)</p>
          </li>
          <li id="uid340">
            <p noindent="true">PhD in progress: Stephanie Lees, “Assessing and Optimising Human-Machine Symbiosis through Neural signals for Big Data Analytics”, Ulster University, since February 2014 (Fabien Lotte, co-supervision with Damien Coyle, Paul McCullagh and Liam Maguire, Ulster University)</p>
          </li>
        </sanspuceslist>
      </subsection>
      <subsection id="uid341" level="2">
        <bodyTitle>Juries</bodyTitle>
        <sanspuceslist>
          <li id="uid342">
            <p noindent="true">PhD (Rapporteur): Elizabeth Rousset, INP Grenoble, February 2016 (Pascal Guitton)</p>
          </li>
          <li id="uid343">
            <p noindent="true">PhD (Rapporteur): Sareh Saeedi, Ecole Polytechnique Fédérale de Lausanne (EPFL), Switzerland, March 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid344">
            <p noindent="true">PhD (Rapporteur): Hind Gacem, Telecom ParisTech, April 2016 (Martin Hachet)</p>
          </li>
          <li id="uid345">
            <p noindent="true">PhD (Rapporteur): Honyun Cho, Gwangju Institute of Science and Technology, South Korea, June 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid346">
            <p noindent="true">PhD (Rapporteur): Sebastien Pelurson, Université Grenoble Alpes, August 2016 (Martin Hachet)</p>
          </li>
          <li id="uid347">
            <p noindent="true">PhD (Président): Brett Ridel, Université de Bordeaux, October 2016 (Pascal Guitton)</p>
          </li>
          <li id="uid348">
            <p noindent="true">PhD (Président): Carlos Zubiaga, Université de Bordeaux, November 2016 (Pascal Guitton)</p>
          </li>
          <li id="uid349">
            <p noindent="true">PhD (Examinateur): Emeric Baldisser, Université de Bordeaux, March 2016 (Pascal Guitton)</p>
          </li>
          <li id="uid350">
            <p noindent="true">PhD (Examinateur): Guillaume Claude, INSA Rennes, July 2016 (Pascal Guitton)</p>
          </li>
          <li id="uid351">
            <p noindent="true">PhD (Examinateur): Benoit Bossavit, Universidad de Navarra, Nov. 2016 (Martin Hachet)</p>
          </li>
          <li id="uid352">
            <p noindent="true">PhD (Examinateur): Liming Yang, Ecole Centrale de Nantes, December 2016 (Pascal Guitton)</p>
          </li>
          <li id="uid353">
            <p noindent="true">Thesis Advisory Committee: Lonni Besançon, Université Paris Saclay, June 2016 (Martin Hachet)</p>
          </li>
          <li id="uid354">
            <p noindent="true">Thesis Advisory Committee: Sarah Buchanan, University Central Florida, July 2016 (Martin Hachet)</p>
          </li>
        </sanspuceslist>
      </subsection>
    </subsection>
    <subsection id="uid355" level="1">
      <bodyTitle>Popularization</bodyTitle>
      <object id="uid356">
        <table>
          <tr>
            <td>
              <ressource xlink:href="IMG/teegi_on_stage.jpg" type="float" width="341.6013pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
          </tr>
        </table>
        <caption>Teegi was demonstrated during several public events over the year, including “Fête de la Science” in La Cité des Sciences in Paris.</caption>
      </object>
      <subsection id="uid357" level="2">
        <bodyTitle>Science Festivals</bodyTitle>
        <sanspuceslist>
          <li id="uid358">
            <p noindent="true">Science Agora, Miraikan, Tokyo, Japan, November 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid359">
            <p noindent="true">Cartopartie, Fête de la Science, Bordeaux, October 2016 (Anke Brock)</p>
          </li>
          <li id="uid360">
            <p noindent="true">Démonsration de Teegi, Cité des Sciences, Paris, retransmission en direct sur l'Esprit Sorcier, October 2016 (Jérémy Frey, Jelena Mladenovic, Thibault Lainé)</p>
          </li>
          <li id="uid361">
            <p noindent="true">"Contrôler par la pensée: Apprenez comment fonctionne une interface cerveau-ordinateur en jouant à Tux Race et découvrez Teegi", Cap science, October 2016 ( Jelena Mladenovic, Jérémy Frey, Thibault Lainé)</p>
          </li>
        </sanspuceslist>
      </subsection>
      <subsection id="uid362" level="2">
        <bodyTitle>Popularization Talks</bodyTitle>
        <sanspuceslist>
          <li id="uid363">
            <p noindent="true">“Les Interfaces Cerveau-Ordinateur”, CogTalk, Bordeaux, October 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid364">
            <p noindent="true">TEDx UTC (Compiegne, France, 01/2016): ”Toucher et entendre les cartes géographiques” <ref xlink:href="https://www.youtube.com/watch?v=sr2l8PQg_2E&amp;feature=youtu.be" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>www.<allowbreak/>youtube.<allowbreak/>com/<allowbreak/>watch?v=sr2l8PQg_2E&amp;feature=youtu.<allowbreak/>be</ref>, (Anke Brock)</p>
          </li>
          <li id="uid365">
            <p noindent="true">"Comment le numérique nous aide à changer", Séminaire Science et développement durable, Bordeaux, June 2016 (Pascal Guitton)</p>
          </li>
          <li id="uid366">
            <p noindent="true">"Réalité virtuelle et réalité augmentée : quelles réalités et quels futurs ?", Séminaire Photonique et réalité virtuelle, Bordeaux, November 2016 (Pascal Guitton)</p>
          </li>
          <li id="uid367">
            <p noindent="true">"Le numérique et ses sciences dans le réel", Séminaire national « Enseigner l’option Informatique et création numérique au cycle terminal », ISENESR (Futuroscope), November 2016 (Pascal Guitton)</p>
          </li>
          <li id="uid368">
            <p noindent="true">Pint of Science, "Interfaces cerveau-ordinateur : Entre mythes et réalité", Bordeaux, May 2016 (Camille Jeunet)</p>
          </li>
        </sanspuceslist>
      </subsection>
      <subsection id="uid369" level="2">
        <bodyTitle>Popularization Articles</bodyTitle>
        <sanspuceslist>
          <li id="uid370">
            <p noindent="true">"Mythes et réalités sur l’interaction cerveau-ordinateur", Livre "5 jeunes chercheurs d'avenir" (Prix de Thèse le Monde), Editions Le Pommier (Fabien Lotte)</p>
          </li>
        </sanspuceslist>
      </subsection>
      <subsection id="uid371" level="2">
        <bodyTitle>Demonstrations</bodyTitle>
        <sanspuceslist>
          <li id="uid372">
            <p noindent="true">Inner Garden, Bordeaux Geek Festival (BGF), May 2016 (Joan Sol Roo, Julia Chatain).</p>
          </li>
          <li id="uid373">
            <p noindent="true">Augmented Michelson Interferometer, Bordeaux Geek Festival (BGF), May 2016 (Benoit Coulais, David Furio)</p>
          </li>
          <li id="uid374">
            <p noindent="true">Augmented Michelson Interferometer, Hall of ALPC region, June 2016 (David Furio)</p>
          </li>
          <li id="uid375">
            <p noindent="true">Demonstration of Teegi, Colloque Robotique et Education, Bordeaux, Juin 2016 (Jérémy Frey, Thibault Lainé).</p>
          </li>
          <li id="uid376">
            <p noindent="true">Demonstration of Teegi,, Bordeaux Geek Festival (BGF), May 2016 (Thibault Lainé)</p>
          </li>
        </sanspuceslist>
      </subsection>
      <subsection id="uid377" level="2">
        <bodyTitle>Women In Science</bodyTitle>
        <sanspuceslist>
          <li id="uid378">
            <p noindent="true">Femmes et Sciences Deputy Board Member (« suppléante au conseil d’administration »), since 2016 (Anke Brock)</p>
          </li>
          <li id="uid379">
            <p noindent="true">Intervention in a high school in Valence d'Agen to present our research projects and career paths , March 2016 (Anke Brock with fellow members of Femmes et Sciences Aquitaine).</p>
          </li>
          <li id="uid380">
            <p noindent="true">"Digit’elles -témoignages de femmes scientifiques" , Fête de la Science, Bordeaux, October 2016 (Anke Brock with fellow members of Femmes et Sciences Aquitaine)</p>
          </li>
          <li id="uid381">
            <p noindent="true">Django girls, Django workshops for young participants, April and June 2016 (Julia Chatain)</p>
          </li>
          <li id="uid382">
            <p noindent="true">Filles et Maths, Speed meeting with female highschool students ti speak about careers in mathematics, May 2016 (Julia Chatain)</p>
          </li>
          <li id="uid383">
            <p noindent="true">Member of Inria Comité Parité et Egalité (Pascal Guitton)</p>
          </li>
        </sanspuceslist>
      </subsection>
      <subsection id="uid384" level="2">
        <bodyTitle>Other</bodyTitle>
        <sanspuceslist>
          <li id="uid385">
            <p noindent="true">Conference on Brain-Computer Interfaces and how to become a research scientist, in a High School in Tulles, December 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid386">
            <p noindent="true">Radio interview on BCI for "L'oeuf ou la poule", on CHOQ, a Montréal Radio from UQAM (Université du Québec à Montréal), Montreal, Canada, June 2016 (Fabien Lotte, Camille Jeunet)</p>
          </li>
          <li id="uid387">
            <p noindent="true">Radio interview on BCI and VR on Radio Canada, in Vancouver, Canada, June 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid388">
            <p noindent="true">Radio interview about BCI and the Brain and Computers Digital Media Conference on the Vancouver-based Round House Radio, June 2016 (Fabien Lotte)</p>
          </li>
          <li id="uid389">
            <p noindent="true">Nuit des Chercheurs, Cap Sciences, Bordeaux, Septembre 2016 (Camille Jeunet)</p>
          </li>
        </sanspuceslist>
      </subsection>
    </subsection>
  </diffusion>
  <biblio id="bibliography" html="bibliography" numero="10" titre="Bibliography">
    
    <biblStruct id="potioc-2016-bid51" type="article" rend="refer" n="refercite:brock:hal-01077434">
      <identifiant type="doi" value="10.1080/07370024.2014.924412"/>
      <identifiant type="hal" value="hal-01077434"/>
      <analytic>
        <title level="a">Interactivity Improves Usability of Geographic Maps for Visually Impaired People</title>
        <author>
          <persName key="potioc-2014-idp63920">
            <foreName>Anke</foreName>
            <surname>Brock</surname>
            <initial>A.</initial>
          </persName>
          <persName>
            <foreName>Philippe</foreName>
            <surname>Truillet</surname>
            <initial>P.</initial>
          </persName>
          <persName>
            <foreName>Bernard</foreName>
            <surname>Oriola</surname>
            <initial>B.</initial>
          </persName>
          <persName>
            <foreName>Delphine</foreName>
            <surname>Picard</surname>
            <initial>D.</initial>
          </persName>
          <persName>
            <foreName>Christophe</foreName>
            <surname>Jouffrais</surname>
            <initial>C.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes">
        <title level="j">Human-Computer Interaction</title>
        <imprint>
          <biblScope type="volume">30</biblScope>
          <biblScope type="number">2</biblScope>
          <dateStruct>
            <year>2015</year>
          </dateStruct>
          <biblScope type="pages">156-194</biblScope>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01077434" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01077434</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid48" type="inproceedings" rend="refer" n="refercite:frey:hal-01251014">
      <identifiant type="doi" value="10.1145/2858036.2858525"/>
      <identifiant type="hal" value="hal-01251014"/>
      <analytic>
        <title level="a">Framework for Electroencephalography-based Evaluation of User Experience</title>
        <author>
          <persName key="potioc-2014-idp92000">
            <foreName>Jérémy</foreName>
            <surname>Frey</surname>
            <initial>J.</initial>
          </persName>
          <persName key="potioc-2015-idp87608">
            <foreName>Maxime</foreName>
            <surname>Daniel</surname>
            <initial>M.</initial>
          </persName>
          <persName>
            <foreName>Julien</foreName>
            <surname>Castet</surname>
            <initial>J.</initial>
          </persName>
          <persName key="potioc-2014-idp62512">
            <foreName>Martin</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr>
        <editor role="editor">
          <persName>
            <foreName/>
            <surname>ACM</surname>
            <initial/>
          </persName>
        </editor>
        <title level="m">CHI '16 - SIGCHI Conference on Human Factors in Computing System</title>
        <loc>San Jose, United States</loc>
        <imprint>
          <dateStruct>
            <month>May</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01251014" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01251014</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid52" subtype="nonparu-n" type="inproceedings" rend="refer" n="refercite:frey:hal-01025621">
      <identifiant type="hal" value="hal-01025621"/>
      <analytic>
        <title level="a">Teegi: Tangible EEG Interface</title>
        <author>
          <persName key="potioc-2014-idp92000">
            <foreName>Jérémy</foreName>
            <surname>Frey</surname>
            <initial>J.</initial>
          </persName>
          <persName key="potioc-2014-idp93232">
            <foreName>Renaud</foreName>
            <surname>Gervais</surname>
            <initial>R.</initial>
          </persName>
          <persName>
            <foreName>Stéphanie</foreName>
            <surname>Fleck</surname>
            <initial>S.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
          <persName key="potioc-2014-idp62512">
            <foreName>Martin</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">UIST-ACM User Interface Software and Technology Symposium</title>
        <loc>Honolulu, United States</loc>
        <imprint>
          <publisher>
            <orgName>ACM</orgName>
          </publisher>
          <dateStruct>
            <month>October</month>
            <year>2014</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01025621" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01025621</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid49" type="inproceedings" rend="refer" n="refercite:gervais:hal-01215499">
      <identifiant type="doi" value="10.1145/2839462.2839486"/>
      <identifiant type="hal" value="hal-01215499"/>
      <analytic>
        <title level="a">TOBE: Tangible Out-of-Body Experience</title>
        <author>
          <persName key="potioc-2014-idp93232">
            <foreName>Renaud</foreName>
            <surname>Gervais</surname>
            <initial>R.</initial>
          </persName>
          <persName key="potioc-2014-idp92000">
            <foreName>Jérémy</foreName>
            <surname>Frey</surname>
            <initial>J.</initial>
          </persName>
          <persName key="potioc-2015-idp91536">
            <foreName>Alexis</foreName>
            <surname>Gay</surname>
            <initial>A.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
          <persName key="potioc-2014-idp62512">
            <foreName>Martin</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="no" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">TEI’16 - Tangible, Embedded and Embodied Interaction</title>
        <loc>Eindhoven, Netherlands</loc>
        <imprint>
          <publisher>
            <orgName>ACM</orgName>
          </publisher>
          <dateStruct>
            <month>February</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01215499" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01215499</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid50" type="inproceedings" rend="refer" n="refercite:gervais:hal-01215502">
      <identifiant type="hal" value="hal-01215502"/>
      <analytic>
        <title level="a">Tangible Viewports: Getting Out of Flatland in Desktop Environments</title>
        <author>
          <persName key="potioc-2014-idp93232">
            <foreName>Renaud</foreName>
            <surname>Gervais</surname>
            <initial>R.</initial>
          </persName>
          <persName>
            <foreName>Joan</foreName>
            <surname>Sol Roo</surname>
            <initial>J.</initial>
          </persName>
          <persName key="potioc-2014-idp62512">
            <foreName>Martin</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="no" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">Tangible, Embedded and Embodied Interaction (TEI)</title>
        <loc>Eindhoven, Netherlands</loc>
        <imprint>
          <dateStruct>
            <month>February</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01215502" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01215502</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid53" type="article" rend="refer" n="refercite:hachet:hal-00789500">
      <identifiant type="doi" value="10.1109/MCG.2013.34"/>
      <identifiant type="hal" value="hal-00789500"/>
      <analytic>
        <title level="a">Touch-Based Interfaces for Interacting with 3D Content in Public Exhibitions</title>
        <author>
          <persName key="potioc-2014-idp62512">
            <foreName>Martin</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
          <persName>
            <foreName>Jean-Baptiste</foreName>
            <surname>De La Rivière</surname>
            <initial>J.-B.</initial>
          </persName>
          <persName key="potioc-2014-idp69016">
            <foreName>Jérémy</foreName>
            <surname>Laviole</surname>
            <initial>J.</initial>
          </persName>
          <persName>
            <foreName>Aurélie</foreName>
            <surname>Cohé</surname>
            <initial>A.</initial>
          </persName>
          <persName>
            <foreName>Sebastien</foreName>
            <surname>Cursan</surname>
            <initial>S.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-editorial-board="yes" x-international-audience="yes">
        <title level="j">IEEE Computer Graphics and Applications</title>
        <imprint>
          <biblScope type="volume">33</biblScope>
          <biblScope type="number">2</biblScope>
          <dateStruct>
            <month>March</month>
            <year>2013</year>
          </dateStruct>
          <biblScope type="pages">80-85</biblScope>
          <ref xlink:href="http://hal.inria.fr/hal-00789500" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-00789500</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid55" type="inproceedings" rend="refer" n="refercite:jankowski:hal-00789413">
      <identifiant type="hal" value="hal-00789413"/>
      <analytic>
        <title level="a">A Survey of Interaction Techniques for Interactive 3D Environments</title>
        <author>
          <persName key="potioc-2014-idp71512">
            <foreName>Jacek</foreName>
            <surname>Jankowski</surname>
            <initial>J.</initial>
          </persName>
          <persName key="potioc-2014-idp62512">
            <foreName>Martin</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr>
        <title level="m">Eurographics 2013 - STAR</title>
        <loc>Girona, Spain</loc>
        <imprint>
          <dateStruct>
            <month>May</month>
            <year>2013</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-00789413" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-00789413</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid54" type="article" rend="refer" n="refercite:lotte:hal-00862716">
      <identifiant type="doi" value="10.3389/fnhum.2013.00568"/>
      <identifiant type="hal" value="hal-00862716"/>
      <analytic>
        <title level="a">Flaws in current human training protocols for spontaneous Brain-Computer Interfaces: lessons learned from instructional design</title>
        <author>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
          <persName>
            <foreName>Florian</foreName>
            <surname>Larrue</surname>
            <initial>F.</initial>
          </persName>
          <persName key="potioc-2014-idp72880">
            <foreName>Christian</foreName>
            <surname>Mühl</surname>
            <initial>C.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-editorial-board="yes" x-international-audience="yes">
        <title level="j">Frontiers in Human Neurosciences</title>
        <imprint>
          <biblScope type="volume">7</biblScope>
          <biblScope type="number">568</biblScope>
          <dateStruct>
            <month>September</month>
            <year>2013</year>
          </dateStruct>
          <ref xlink:href="http://hal.inria.fr/hal-00862716" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-00862716</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid18" type="book" rend="year" n="cite:clerc:hal-01408991">
      <identifiant type="hal" value="hal-01408991"/>
      <monogr x-scientific-popularization="no" x-international-audience="yes">
        <title level="m">Brain-Computer Interfaces 1: Foundations and Methods</title>
        <editor role="editor">
          <persName key="athena-2014-idm29272">
            <foreName>Maureen</foreName>
            <surname>Clerc</surname>
            <initial>M.</initial>
          </persName>
          <persName key="neurosys-2014-idm28696">
            <foreName>Laurent</foreName>
            <surname>Bougrain</surname>
            <initial>L.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </editor>
        <imprint>
          <publisher>
            <orgName>Wiley-ISTE</orgName>
          </publisher>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01408991" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01408991</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid19" type="book" rend="year" n="cite:clerc:hal-01408998">
      <identifiant type="hal" value="hal-01408998"/>
      <monogr x-scientific-popularization="no" x-international-audience="yes">
        <title level="m">Brain-Computer Interfaces 2: Technology and Applications</title>
        <editor role="editor">
          <persName key="athena-2014-idm29272">
            <foreName>Maureen</foreName>
            <surname>Clerc</surname>
            <initial>M.</initial>
          </persName>
          <persName key="neurosys-2014-idm28696">
            <foreName>Laurent</foreName>
            <surname>Bougrain</surname>
            <initial>L.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </editor>
        <imprint>
          <publisher>
            <orgName>Wiley-ISTE</orgName>
          </publisher>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01408998" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01408998</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid0" type="book" rend="year" n="cite:clerc:hal-01402539">
      <identifiant type="hal" value="hal-01402539"/>
      <monogr x-scientific-popularization="no" x-international-audience="no">
        <title level="m">Les interfaces Cerveau-Ordinateur 1 : Fondements et méthodes</title>
        <editor role="editor">
          <persName key="athena-2014-idm29272">
            <foreName>Maureen</foreName>
            <surname>Clerc</surname>
            <initial>M.</initial>
          </persName>
          <persName key="neurosys-2014-idm28696">
            <foreName>Laurent</foreName>
            <surname>Bougrain</surname>
            <initial>L.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </editor>
        <imprint>
          <publisher>
            <orgName>ISTE</orgName>
          </publisher>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01402539" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01402539</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid1" type="book" rend="year" n="cite:clerc:hal-01402544">
      <identifiant type="hal" value="hal-01402544"/>
      <monogr x-scientific-popularization="no" x-international-audience="no">
        <title level="m">Les interfaces cerveau-ordinateur 2 : Technologie et applications</title>
        <editor role="editor">
          <persName key="athena-2014-idm29272">
            <foreName>Maureen</foreName>
            <surname>Clerc</surname>
            <initial>M.</initial>
          </persName>
          <persName key="neurosys-2014-idm28696">
            <foreName>Laurent</foreName>
            <surname>Bougrain</surname>
            <initial>L.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </editor>
        <imprint>
          <publisher>
            <orgName>ISTE</orgName>
          </publisher>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01402544" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01402544</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid40" type="hdrthesis" rend="year" n="cite:lotte:tel-01416980">
      <identifiant type="hal" value="tel-01416980"/>
      <monogr>
        <title level="m">Towards Usable Electroencephalography-based Brain-Computer Interfaces</title>
        <author>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </author>
        <imprint>
          <publisher>
            <orgName type="school">Univ. Bordeaux</orgName>
          </publisher>
          <dateStruct>
            <month>September</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/tel-01416980" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>tel-01416980</ref>
        </imprint>
      </monogr>
      <note type="typdoc">Habilitation à diriger des recherches</note>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid47" type="incollection" rend="year" n="cite:andreev:hal-01366873">
      <identifiant type="hal" value="hal-01366873"/>
      <analytic>
        <title level="a">Recreational Applications of OpenViBE: Brain Invaders and Use-the-Force</title>
        <author>
          <persName key="necs-2014-idp106448">
            <foreName>Anton</foreName>
            <surname>Andreev</surname>
            <initial>A.</initial>
          </persName>
          <persName>
            <foreName>Alexandre</foreName>
            <surname>Barachant</surname>
            <initial>A.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
          <persName>
            <foreName>Marco</foreName>
            <surname>Congedo</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no">
        <editor role="editor">
          <persName key="athena-2014-idm29272">
            <foreName>Maureen</foreName>
            <surname>Clerc</surname>
            <initial>M.</initial>
          </persName>
          <persName key="neurosys-2014-idm28696">
            <foreName>Laurent</foreName>
            <surname>Bougrain</surname>
            <initial>L.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </editor>
        <title level="m">Brain-Computer Interfaces 2: Technology and Applications</title>
        <imprint>
          <biblScope type="volume">chap. 14</biblScope>
          <publisher>
            <orgName>John Wiley</orgName>
          </publisher>
          <dateStruct>
            <month>August</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">241-257</biblScope>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01366873" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01366873</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid15" type="article" rend="year" n="cite:arns:hal-01415897">
      <identifiant type="hal" value="hal-01415897"/>
      <analytic>
        <title level="a">Neurofeedback: one of today's techniques in psychiatry?</title>
        <author>
          <persName>
            <foreName>Martijn</foreName>
            <surname>Arns</surname>
            <initial>M.</initial>
          </persName>
          <persName key="visages-2016-idp242880">
            <foreName>Jean-Marie</foreName>
            <surname>Batail</surname>
            <initial>J.-M.</initial>
          </persName>
          <persName>
            <foreName>Stéphanie</foreName>
            <surname>Bioulac</surname>
            <initial>S.</initial>
          </persName>
          <persName>
            <foreName>Marco</foreName>
            <surname>Congedo</surname>
            <initial>M.</initial>
          </persName>
          <persName>
            <foreName>Christophe</foreName>
            <surname>Daudet</surname>
            <initial>C.</initial>
          </persName>
          <persName>
            <foreName>Dominique</foreName>
            <surname>Drapier</surname>
            <initial>D.</initial>
          </persName>
          <persName>
            <foreName>Thomas</foreName>
            <surname>Fovet</surname>
            <initial>T.</initial>
          </persName>
          <persName>
            <foreName>Renaud</foreName>
            <surname>Jardri</surname>
            <initial>R.</initial>
          </persName>
          <persName>
            <foreName>Le</foreName>
            <surname>Van Quyen</surname>
            <initial>L.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
          <persName>
            <foreName>David</foreName>
            <surname>Mehler</surname>
            <initial>D.</initial>
          </persName>
          <persName>
            <foreName>Jean-Arthur</foreName>
            <surname>Micoulaud</surname>
            <initial>J.-A.</initial>
          </persName>
          <persName>
            <foreName>Diane</foreName>
            <surname>Purper-Ouakil</surname>
            <initial>D.</initial>
          </persName>
          <persName>
            <foreName>François Benoît</foreName>
            <surname>Vialatte</surname>
            <initial>F. B.</initial>
          </persName>
          <persName>
            <foreName/>
            <surname>the NExT group</surname>
            <initial/>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid01319">
        <idno type="issn">0013-7006</idno>
        <title level="j">L'Encéphale</title>
        <imprint>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01415897" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01415897</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid3" type="article" rend="year" n="cite:berthaut:hal-01374911">
      <identifiant type="doi" value="10.1109/MCG.2016.96"/>
      <identifiant type="hal" value="hal-01374911"/>
      <analytic>
        <title level="a">Spatial Interfaces and Interactive 3D Environments for Immersive Musical Performances</title>
        <author>
          <persName key="mint-2015-idp63368">
            <foreName>Florent</foreName>
            <surname>Berthaut</surname>
            <initial>F.</initial>
          </persName>
          <persName key="potioc-2014-idp62512">
            <foreName>Martin</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00680">
        <idno type="issn">0272-1716</idno>
        <title level="j">IEEE Computer Graphics and Applications</title>
        <imprint>
          <biblScope type="volume">36</biblScope>
          <biblScope type="number">5</biblScope>
          <dateStruct>
            <month>September</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">82 - 87</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01374911" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01374911</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid11" type="article" rend="year" n="cite:chavarriaga:hal-01415906">
      <identifiant type="hal" value="hal-01415906"/>
      <analytic>
        <title level="a">Heading for new shores! Overcoming pitfalls in BCI design</title>
        <author>
          <persName>
            <foreName>Ricardo</foreName>
            <surname>Chavarriaga</surname>
            <initial>R.</initial>
          </persName>
          <persName>
            <foreName>Melanie</foreName>
            <surname>Fried-Oken</surname>
            <initial>M.</initial>
          </persName>
          <persName>
            <foreName>Sonja</foreName>
            <surname>Kleih</surname>
            <initial>S.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
          <persName>
            <foreName>Reinhold</foreName>
            <surname>Scherer</surname>
            <initial>R.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid02647">
        <idno type="issn">2326-263X</idno>
        <title level="j">Brain-Computer Interfaces</title>
        <imprint>
          <dateStruct>
            <month>December</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01415906" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01415906</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid37" type="incollection" rend="year" n="cite:clerc:hal-01409032">
      <identifiant type="hal" value="hal-01409032"/>
      <analytic>
        <title level="a">Conclusion and Perspectives</title>
        <author>
          <persName key="athena-2014-idm29272">
            <foreName>Maureen</foreName>
            <surname>Clerc</surname>
            <initial>M.</initial>
          </persName>
          <persName key="neurosys-2014-idm28696">
            <foreName>Laurent</foreName>
            <surname>Bougrain</surname>
            <initial>L.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no">
        <title level="m">Brain-Computer Interfaces 2</title>
        <imprint>
          <publisher>
            <orgName>Wiley-ISTE</orgName>
          </publisher>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01409032" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01409032</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid38" type="incollection" rend="year" n="cite:clerc:hal-01408972">
      <identifiant type="hal" value="hal-01408972"/>
      <analytic>
        <title level="a">Conclusion et perspectives</title>
        <author>
          <persName key="athena-2014-idm29272">
            <foreName>Maureen</foreName>
            <surname>Clerc</surname>
            <initial>M.</initial>
          </persName>
          <persName key="neurosys-2014-idm28696">
            <foreName>Laurent</foreName>
            <surname>Bougrain</surname>
            <initial>L.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no">
        <title level="m">Les interfaces cerveau-ordinateur 2</title>
        <imprint>
          <publisher>
            <orgName>ISTE</orgName>
          </publisher>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01408972" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01408972</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid36" type="incollection" rend="year" n="cite:clerc:hal-01409001">
      <identifiant type="hal" value="hal-01409001"/>
      <analytic>
        <title level="a">Introduction</title>
        <author>
          <persName key="athena-2014-idm29272">
            <foreName>Maureen</foreName>
            <surname>Clerc</surname>
            <initial>M.</initial>
          </persName>
          <persName key="neurosys-2014-idm28696">
            <foreName>Laurent</foreName>
            <surname>Bougrain</surname>
            <initial>L.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no">
        <editor role="editor">
          <persName key="athena-2014-idm29272">
            <foreName>Maureen</foreName>
            <surname>Clerc</surname>
            <initial>M.</initial>
          </persName>
          <persName key="neurosys-2014-idm28696">
            <foreName>Laurent</foreName>
            <surname>Bougrain</surname>
            <initial>L.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </editor>
        <title level="m">Brain-Computer Interfaces 1</title>
        <imprint>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01409001" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01409001</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid39" type="incollection" rend="year" n="cite:clerc:hal-01402594">
      <identifiant type="hal" value="hal-01402594"/>
      <analytic>
        <title level="a">Introduction</title>
        <author>
          <persName key="athena-2014-idm29272">
            <foreName>Maureen</foreName>
            <surname>Clerc</surname>
            <initial>M.</initial>
          </persName>
          <persName key="neurosys-2014-idm28696">
            <foreName>Laurent</foreName>
            <surname>Bougrain</surname>
            <initial>L.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no">
        <editor role="editor">
          <persName key="athena-2014-idm29272">
            <foreName>Maureen</foreName>
            <surname>Clerc</surname>
            <initial>M.</initial>
          </persName>
          <persName key="neurosys-2014-idm28696">
            <foreName>Laurent</foreName>
            <surname>Bougrain</surname>
            <initial>L.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </editor>
        <title level="m">Les interfaces cerveau-ordinateur 1</title>
        <title level="s">Fondements et méthodes</title>
        <imprint>
          <publisher>
            <orgName>ISTE</orgName>
          </publisher>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01402594" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01402594</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid2" type="article" rend="year" n="cite:fleck:hal-01411182">
      <identifiant type="doi" value="10.3389/fict.2016.00030"/>
      <identifiant type="hal" value="hal-01411182"/>
      <analytic>
        <title level="a">Making tangible the intangible: Hybridization of the real and the virtual to enhance learning of abstract phenomena</title>
        <author>
          <persName>
            <foreName>Stéphanie</foreName>
            <surname>Fleck</surname>
            <initial>S.</initial>
          </persName>
          <persName key="potioc-2014-idp62512">
            <foreName>Martin</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid02918">
        <idno type="issn">2297-198X</idno>
        <title level="j">Frontiers in ICT</title>
        <imprint>
          <biblScope type="volume">3</biblScope>
          <dateStruct>
            <month>November</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">30</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01411182" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01411182</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid46" type="article" rend="year" n="cite:frey:hal-01222045">
      <identifiant type="doi" value="10.1155/2016/2758103"/>
      <identifiant type="hal" value="hal-01222045"/>
      <analytic>
        <title level="a">Classifying EEG Signals during Stereoscopic Visualization to Estimate Visual Comfort</title>
        <author>
          <persName key="potioc-2014-idp92000">
            <foreName>Jérémy</foreName>
            <surname>Frey</surname>
            <initial>J.</initial>
          </persName>
          <persName key="potioc-2014-idp79200">
            <foreName>Aurélien</foreName>
            <surname>Appriou</surname>
            <initial>A.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
          <persName key="potioc-2014-idp62512">
            <foreName>Martin</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00376">
        <idno type="issn">1687-5265</idno>
        <title level="j">Computational Intelligence and Neuroscience</title>
        <imprint>
          <biblScope type="volume">2016</biblScope>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01222045" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01222045</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid29" type="article" rend="year" n="cite:frey:hal-01288542">
      <identifiant type="hal" value="hal-01288542"/>
      <analytic>
        <title level="a">Émersions sensorielles</title>
        <author>
          <persName key="potioc-2014-idp92000">
            <foreName>Jérémy</foreName>
            <surname>Frey</surname>
            <initial>J.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="no" id="rid03048">
        <idno type="issn">1954-1228</idno>
        <title level="j">CORPS : Revue Interdisciplinaire</title>
        <imprint>
          <biblScope type="volume">13</biblScope>
          <dateStruct>
            <month>January</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01288542" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01288542</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid5" type="article" rend="year" n="cite:frey:hal-01394254">
      <identifiant type="hal" value="hal-01394254"/>
      <analytic>
        <title level="a">EEG-based neuroergonomics for 3D user interfaces: opportunities and challenges</title>
        <author>
          <persName key="potioc-2014-idp92000">
            <foreName>Jérémy</foreName>
            <surname>Frey</surname>
            <initial>J.</initial>
          </persName>
          <persName key="potioc-2014-idp62512">
            <foreName>Martin</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid01878">
        <idno type="issn">1243-1370</idno>
        <title level="j">Le travail humain</title>
        <imprint>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01394254" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01394254</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid14" type="article" rend="year" n="cite:jeunet:hal-01302154">
      <identifiant type="hal" value="hal-01302154"/>
      <analytic>
        <title level="a">Why Standard Brain-Computer Interface (BCI) Training Protocols Should be Changed: An Experimental Study</title>
        <author>
          <persName key="potioc-2014-idp94448">
            <foreName>Camille</foreName>
            <surname>Jeunet</surname>
            <initial>C.</initial>
          </persName>
          <persName key="potioc-2015-idp92824">
            <foreName>Emilie</foreName>
            <surname>Jahanpour</surname>
            <initial>E.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid01216">
        <idno type="issn">1741-2560</idno>
        <title level="j">Journal of Neural Engineering</title>
        <imprint>
          <dateStruct>
            <month>April</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01302154" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01302154</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid13" type="incollection" rend="year" n="cite:jeunet:hal-01414106">
      <identifiant type="hal" value="hal-01414106"/>
      <analytic>
        <title level="a">Apprentissage humain pour les interfaces cerveau-ordinateur</title>
        <author>
          <persName key="potioc-2014-idp94448">
            <foreName>Camille</foreName>
            <surname>Jeunet</surname>
            <initial>C.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
          <persName key="phoenix-2014-idp102184">
            <foreName>Bernard</foreName>
            <surname>N'Kaoua</surname>
            <initial>B.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no">
        <title level="m">Les Interfaces Cerveau-Ordinateur</title>
        <title level="s">Fondements &amp; Méthodes</title>
        <imprint>
          <biblScope type="volume">1</biblScope>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01414106" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01414106</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid12" type="article" rend="year" n="cite:jeunet:hal-01302138">
      <identifiant type="hal" value="hal-01302138"/>
      <analytic>
        <title level="a">Advances in User-Training for Mental-Imagery Based BCI Control: Psychological and Cognitive Factors and their Neural Correlates</title>
        <author>
          <persName key="potioc-2014-idp94448">
            <foreName>Camille</foreName>
            <surname>Jeunet</surname>
            <initial>C.</initial>
          </persName>
          <persName key="phoenix-2014-idp102184">
            <foreName>Bernard</foreName>
            <surname>N'Kaoua</surname>
            <initial>B.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid03031">
        <idno type="issn">0079-6123</idno>
        <title level="j">Progress in brain research</title>
        <imprint>
          <dateStruct>
            <month>February</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01302138" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01302138</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid24" type="incollection" rend="year" n="cite:lotte:hal-01417017">
      <identifiant type="hal" value="hal-01417017"/>
      <analytic>
        <title level="a">Illustration de phénomènes électrophysiologiques avec OpenViBE</title>
        <author>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
          <persName key="potioc-2014-idp66400">
            <foreName>Alison</foreName>
            <surname>Cellard</surname>
            <initial>A.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no">
        <editor role="editor">
          <persName key="athena-2014-idm29272">
            <foreName>Maureen</foreName>
            <surname>Clerc</surname>
            <initial>M.</initial>
          </persName>
          <persName key="neurosys-2014-idm28696">
            <foreName>Laurent</foreName>
            <surname>Bougrain</surname>
            <initial>L.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </editor>
        <title level="m">Les Interfaces Cerveau-Ordinateur 2 : technologie et applications</title>
        <imprint>
          <publisher>
            <orgName>ISTE-Wiley</orgName>
          </publisher>
          <dateStruct>
            <month>August</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01417017" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01417017</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid25" type="incollection" rend="year" n="cite:lotte:hal-01417027">
      <identifiant type="hal" value="hal-01417027"/>
      <analytic>
        <title level="a">Extraction de Caractéristiques du signal EEG</title>
        <author>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
          <persName>
            <foreName>Marco</foreName>
            <surname>Congedo</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no">
        <editor role="editor">
          <persName key="athena-2014-idm29272">
            <foreName>Maureen</foreName>
            <surname>Clerc</surname>
            <initial>M.</initial>
          </persName>
          <persName key="neurosys-2014-idm28696">
            <foreName>Laurent</foreName>
            <surname>Bougrain</surname>
            <initial>L.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </editor>
        <title level="m">Les Interfaces Cerveau-Ordinateur 1 : fondements et méthodes</title>
        <imprint>
          <publisher>
            <orgName>ISTE-Wiley</orgName>
          </publisher>
          <dateStruct>
            <month>August</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01417027" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01417027</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid35" type="incollection" rend="year" n="cite:perronnet:hal-01413424">
      <identifiant type="hal" value="hal-01413424"/>
      <analytic>
        <title level="a">Brain training with neurofeedback</title>
        <author>
          <persName key="visages-2014-idp143576">
            <foreName>Lorraine</foreName>
            <surname>Perronnet</surname>
            <initial>L.</initial>
          </persName>
          <persName key="hybrid-2014-idm28656">
            <foreName>Anatole</foreName>
            <surname>Lécuyer</surname>
            <initial>A.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
          <persName key="athena-2014-idm29272">
            <foreName>Maureen</foreName>
            <surname>Clerc</surname>
            <initial>M.</initial>
          </persName>
          <persName key="visages-2014-idp101432">
            <foreName>Christian</foreName>
            <surname>Barillot</surname>
            <initial>C.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no">
        <title level="m">Brain-Computer Interfaces 1</title>
        <imprint>
          <publisher>
            <orgName>Wiley-ISTE</orgName>
          </publisher>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01413424" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01413424</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid33" type="incollection" rend="year" n="cite:perronnet:hal-01413408">
      <identifiant type="hal" value="hal-01413408"/>
      <analytic>
        <title level="a">Entraîner son cerveau avec le neurofeedback</title>
        <author>
          <persName key="visages-2014-idp143576">
            <foreName>Lorraine</foreName>
            <surname>Perronnet</surname>
            <initial>L.</initial>
          </persName>
          <persName key="hybrid-2014-idm28656">
            <foreName>Anatole</foreName>
            <surname>Lécuyer</surname>
            <initial>A.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
          <persName key="athena-2014-idm29272">
            <foreName>Maureen</foreName>
            <surname>Clerc</surname>
            <initial>M.</initial>
          </persName>
          <persName key="visages-2014-idp101432">
            <foreName>Christian</foreName>
            <surname>Barillot</surname>
            <initial>C.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no">
        <editor role="editor">
          <persName key="athena-2014-idm29272">
            <foreName>Maureen</foreName>
            <surname>Clerc</surname>
            <initial>M.</initial>
          </persName>
          <persName key="neurosys-2014-idm28696">
            <foreName>Laurent</foreName>
            <surname>Bougrain</surname>
            <initial>L.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </editor>
        <title level="m">Les interfaces cerveau-ordinateur 1</title>
        <imprint>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01413408" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01413408</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid22" type="incollection" rend="year" n="cite:roy:hal-01413448">
      <identifiant type="hal" value="hal-01413448"/>
      <analytic>
        <title level="a">Marqueurs neurophysiologiques pour les interfaces cerveau-ordinateur passives</title>
        <author>
          <persName>
            <foreName>Raphaëlle N.</foreName>
            <surname>Roy</surname>
            <initial>R. N.</initial>
          </persName>
          <persName key="potioc-2014-idp92000">
            <foreName>Jérémy</foreName>
            <surname>Frey</surname>
            <initial>J.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no">
        <title level="m">Les interfaces cerveau-ordinateur 1</title>
        <imprint>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01413448" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01413448</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid23" type="incollection" rend="year" n="cite:roy:hal-01413462">
      <identifiant type="doi" value="10.1002/9781119144977.ch5"/>
      <identifiant type="hal" value="hal-01413462"/>
      <analytic>
        <title level="a">Neurophysiological Markers for Passive Brain–Computer Interfaces</title>
        <author>
          <persName>
            <foreName>Raphaëlle N.</foreName>
            <surname>Roy</surname>
            <initial>R. N.</initial>
          </persName>
          <persName key="potioc-2014-idp92000">
            <foreName>Jérémy</foreName>
            <surname>Frey</surname>
            <initial>J.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no">
        <editor role="editor">
          <persName key="athena-2014-idm29272">
            <foreName>Maureen</foreName>
            <surname>Clerc</surname>
            <initial>M.</initial>
          </persName>
          <persName key="neurosys-2014-idm28696">
            <foreName>Laurent</foreName>
            <surname>Bougrain</surname>
            <initial>L.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </editor>
        <title level="m">Brain–Computer Interfaces 1: Foundations and Methods</title>
        <imprint>
          <publisher>
            <orgName>Wiley-ISTE</orgName>
          </publisher>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01413462" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01413462</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid10" type="article" rend="year" n="cite:yger:hal-01394253">
      <identifiant type="hal" value="hal-01394253"/>
      <analytic>
        <title level="a">Riemannian approaches in Brain-Computer Interfaces: a review</title>
        <author>
          <persName>
            <foreName>Florian</foreName>
            <surname>Yger</surname>
            <initial>F.</initial>
          </persName>
          <persName>
            <foreName>Maxime</foreName>
            <surname>Berar</surname>
            <initial>M.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00745">
        <idno type="issn">1534-4320</idno>
        <title level="j">IEEE Transactions on Neural Systems and Rehabilitation Engineering</title>
        <imprint>
          <dateStruct>
            <year>2017</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01394253" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01394253</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid44" type="inproceedings" rend="year" n="cite:brock:hal-01279207">
      <identifiant type="hal" value="hal-01279207"/>
      <analytic>
        <title level="a">A Method Story about Brainstorming with Visually Impaired People for Designing an Accessible Route Calculation System</title>
        <author>
          <persName key="potioc-2014-idp63920">
            <foreName>Anke M.</foreName>
            <surname>Brock</surname>
            <initial>A. M.</initial>
          </persName>
          <persName>
            <foreName>Emeline</foreName>
            <surname>Brulé</surname>
            <initial>E.</initial>
          </persName>
          <persName>
            <foreName>Bernard</foreName>
            <surname>Oriola</surname>
            <initial>B.</initial>
          </persName>
          <persName>
            <foreName>Philippe</foreName>
            <surname>Truillet</surname>
            <initial>P.</initial>
          </persName>
          <persName>
            <foreName>Annie</foreName>
            <surname>Gentes</surname>
            <initial>A.</initial>
          </persName>
          <persName>
            <foreName>Christophe</foreName>
            <surname>Jouffrais</surname>
            <initial>C.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="no" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">ACM CHI 2016 - chi4good</title>
        <loc>San José, United States</loc>
        <title level="s">CHI'16 Workshop on Sharing Methods for Involving People with Impairments in Design: Exploring the Method Story Approach</title>
        <imprint>
          <dateStruct>
            <month>May</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01279207" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01279207</ref>
        </imprint>
        <meeting id="cid34258">
          <title>Annual SIGCHI Conference on Human Factors in Computing Systems</title>
          <num>34</num>
          <abbr type="sigle">CHI</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid4" type="inproceedings" rend="year" n="cite:brule:hal-01263056">
      <identifiant type="hal" value="hal-01263056"/>
      <analytic>
        <title level="a">MapSense: Multi-Sensory Interactive Maps for Children Living with Visual Impairments</title>
        <author>
          <persName>
            <foreName>Emeline</foreName>
            <surname>Brulé</surname>
            <initial>E.</initial>
          </persName>
          <persName>
            <foreName>Gilles</foreName>
            <surname>Bailly</surname>
            <initial>G.</initial>
          </persName>
          <persName key="potioc-2014-idp63920">
            <foreName>Anke M.</foreName>
            <surname>Brock</surname>
            <initial>A. M.</initial>
          </persName>
          <persName key="nachos-2014-idp91952">
            <foreName>Frédéric</foreName>
            <surname>Valentin</surname>
            <initial>F.</initial>
          </persName>
          <persName>
            <foreName>Grégoire</foreName>
            <surname>Denis</surname>
            <initial>G.</initial>
          </persName>
          <persName>
            <foreName>Christophe</foreName>
            <surname>Jouffrais</surname>
            <initial>C.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">ACM CHI 2016 - chi4good</title>
        <loc>San José, United States</loc>
        <title level="s">Proceedings of the Annual ACM Conference on Human Factors in Computing Systems</title>
        <imprint>
          <publisher>
            <orgName>ACM</orgName>
          </publisher>
          <dateStruct>
            <month>May</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01263056" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01263056</ref>
        </imprint>
        <meeting id="cid34258">
          <title>Annual SIGCHI Conference on Human Factors in Computing Systems</title>
          <num>34</num>
          <abbr type="sigle">CHI</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid26" type="inproceedings" rend="year" n="cite:clergeaud:hal-01417208">
      <identifiant type="hal" value="hal-01417208"/>
      <analytic>
        <title level="a">3D Collaborative Interaction for Aerospace Industry</title>
        <author>
          <persName key="potioc-2014-idp89488">
            <foreName>Damien</foreName>
            <surname>Clergeaud</surname>
            <initial>D.</initial>
          </persName>
          <persName>
            <foreName>François</foreName>
            <surname>Guillaume</surname>
            <initial>F.</initial>
          </persName>
          <persName key="potioc-2015-idm26120">
            <foreName>Pascal</foreName>
            <surname>Guitton</surname>
            <initial>P.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">3D CVE Workshop (IEEE VR)</title>
        <loc>Greenville, United States</loc>
        <imprint>
          <dateStruct>
            <month>March</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">2</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01417208" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01417208</ref>
        </imprint>
        <meeting id="cid86390">
          <title>IEEE International Conference on Virtual Reality</title>
          <num>2016</num>
          <abbr type="sigle">IEEE VR</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid34" type="inproceedings" rend="year" n="cite:clergeaud:hal-01417415">
      <identifiant type="hal" value="hal-01417415"/>
      <analytic>
        <title level="a">Collaboration Interactive en Réalité Virtuelle pour l'industrie Aérospatiale</title>
        <author>
          <persName key="potioc-2014-idp89488">
            <foreName>Damien</foreName>
            <surname>Clergeaud</surname>
            <initial>D.</initial>
          </persName>
          <persName key="potioc-2015-idm26120">
            <foreName>Pascal</foreName>
            <surname>Guitton</surname>
            <initial>P.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="no" x-proceedings="no" x-invited-conference="no" x-editorial-board="no">
        <title level="m">AFRV 2016 - 11èmes journées de l'association française de réalité virtuelle</title>
        <loc>Brest, France</loc>
        <imprint>
          <publisher>
            <orgName type="organisation">AFRV</orgName>
          </publisher>
          <dateStruct>
            <month>October</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01417415" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01417415</ref>
        </imprint>
        <meeting id="cid348547">
          <title>Journées de l'Association Francaise de Réalité Virtuelle, Augmentée, Mixte et Interaction 3D</title>
          <num>11</num>
          <abbr type="sigle">AFRV</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid21" type="inproceedings" rend="year" n="cite:frey:hal-01251014">
      <identifiant type="doi" value="10.1145/2858036.2858525"/>
      <identifiant type="hal" value="hal-01251014"/>
      <analytic>
        <title level="a">Framework for Electroencephalography-based Evaluation of User Experience</title>
        <author>
          <persName key="potioc-2014-idp92000">
            <foreName>Jérémy</foreName>
            <surname>Frey</surname>
            <initial>J.</initial>
          </persName>
          <persName key="potioc-2015-idp87608">
            <foreName>Maxime</foreName>
            <surname>Daniel</surname>
            <initial>M.</initial>
          </persName>
          <persName>
            <foreName>Julien</foreName>
            <surname>Castet</surname>
            <initial>J.</initial>
          </persName>
          <persName key="potioc-2014-idp62512">
            <foreName>Martin</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <editor role="editor">
          <persName>
            <foreName/>
            <surname>ACM</surname>
            <initial/>
          </persName>
        </editor>
        <title level="m">CHI '16 - SIGCHI Conference on Human Factors in Computing System</title>
        <loc>San Jose, United States</loc>
        <imprint>
          <dateStruct>
            <month>May</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01251014" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01251014</ref>
        </imprint>
        <meeting id="cid34258">
          <title>Annual SIGCHI Conference on Human Factors in Computing Systems</title>
          <num>34</num>
          <abbr type="sigle">CHI</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid8" type="inproceedings" rend="year" n="cite:frey:hal-01278245">
      <identifiant type="hal" value="hal-01278245"/>
      <analytic>
        <title level="a">Comparison of a consumer grade EEG amplifier with medical grade equipment in BCI applications</title>
        <author>
          <persName key="potioc-2014-idp92000">
            <foreName>Jérémy</foreName>
            <surname>Frey</surname>
            <initial>J.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">International BCI meeting</title>
        <loc>Asilomar, United States</loc>
        <imprint>
          <dateStruct>
            <month>May</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01278245" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01278245</ref>
        </imprint>
        <meeting id="cid105860">
          <title>International Brain-Computer Interface Workshop</title>
          <num>2013</num>
          <abbr type="sigle">BCI</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid7" type="inproceedings" rend="year" n="cite:frey:hal-01328427">
      <identifiant type="hal" value="hal-01328427"/>
      <analytic>
        <title level="a">Comparison of an open-hardware electroencephalography amplifier with medical grade device in brain-computer interface applications</title>
        <author>
          <persName key="potioc-2014-idp92000">
            <foreName>Jérémy</foreName>
            <surname>Frey</surname>
            <initial>J.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">PhyCS - International Conference on Physiological Computing Systems</title>
        <loc>Lisbon, Portugal</loc>
        <imprint>
          <publisher>
            <orgName>SCITEPRESS</orgName>
          </publisher>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01328427" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01328427</ref>
        </imprint>
        <meeting id="cid624239">
          <title>International Conference on Physiological Computing Systems</title>
          <num>2015</num>
          <abbr type="sigle">PhyCS</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid42" type="inproceedings" rend="year" n="cite:frey:hal-01273938">
      <identifiant type="doi" value="10.1145/2851581.2892391"/>
      <identifiant type="hal" value="hal-01273938"/>
      <analytic>
        <title level="a">Remote Heart Rate Sensing and Projection to Renew Traditional Board Games and Foster Social Interactions</title>
        <author>
          <persName key="potioc-2014-idp92000">
            <foreName>Jérémy</foreName>
            <surname>Frey</surname>
            <initial>J.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">CHI '16 Extended Abstracts</title>
        <loc>San Jose, United States</loc>
        <imprint>
          <dateStruct>
            <month>May</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01273938" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01273938</ref>
        </imprint>
        <meeting id="cid34258">
          <title>Annual SIGCHI Conference on Human Factors in Computing Systems</title>
          <num>34</num>
          <abbr type="sigle">CHI</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid9" type="inproceedings" rend="year" n="cite:frey:hal-01305799">
      <identifiant type="hal" value="hal-01305799"/>
      <analytic>
        <title level="a">VIF: Virtual Interactive Fiction (with a twist)</title>
        <author>
          <persName key="potioc-2014-idp92000">
            <foreName>Jérémy</foreName>
            <surname>Frey</surname>
            <initial>J.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="no" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">Pervasive Play - CHI '16 Workshop</title>
        <loc>San Jose, United States</loc>
        <imprint>
          <dateStruct>
            <month>May</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01305799" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01305799</ref>
        </imprint>
        <meeting id="cid625299">
          <title>CHI Workshop on Pervasive Play</title>
          <num>2016</num>
          <abbr type="sigle"/>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid6" type="inproceedings" rend="year" n="cite:frey:hal-01394255">
      <identifiant type="hal" value="hal-01394255"/>
      <analytic>
        <title level="a">Recent advances in EEG-based neuroergonomics for Human-Computer Interaction</title>
        <author>
          <persName key="potioc-2014-idp92000">
            <foreName>Jérémy</foreName>
            <surname>Frey</surname>
            <initial>J.</initial>
          </persName>
          <persName key="potioc-2014-idp62512">
            <foreName>Martin</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">1st International Neuroergonomics conference</title>
        <loc>Paris, France</loc>
        <imprint>
          <dateStruct>
            <month>October</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01394255" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01394255</ref>
        </imprint>
        <meeting id="cid625297">
          <title>International Neuroergonomics conference</title>
          <num>1</num>
          <abbr type="sigle"/>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid43" type="inproceedings" rend="year" n="cite:gervais:hal-01215499">
      <identifiant type="doi" value="10.1145/2839462.2839486"/>
      <identifiant type="hal" value="hal-01215499"/>
      <analytic>
        <title level="a">TOBE: Tangible Out-of-Body Experience</title>
        <author>
          <persName key="potioc-2014-idp93232">
            <foreName>Renaud</foreName>
            <surname>Gervais</surname>
            <initial>R.</initial>
          </persName>
          <persName key="potioc-2014-idp92000">
            <foreName>Jérémy</foreName>
            <surname>Frey</surname>
            <initial>J.</initial>
          </persName>
          <persName key="potioc-2015-idp91536">
            <foreName>Alexis</foreName>
            <surname>Gay</surname>
            <initial>A.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
          <persName key="potioc-2014-idp62512">
            <foreName>Martin</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">TEI’16 - Tangible, Embedded and Embodied Interaction</title>
        <loc>Eindhoven, Netherlands</loc>
        <imprint>
          <publisher>
            <orgName>ACM</orgName>
          </publisher>
          <dateStruct>
            <month>February</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01215499" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01215499</ref>
        </imprint>
        <meeting id="cid302129">
          <title>International Conference on Tangible and Embedded Interaction</title>
          <num>2016</num>
          <abbr type="sigle">TEI</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid28" type="inproceedings" rend="year" n="cite:gervais:hal-01288336">
      <identifiant type="hal" value="hal-01288336"/>
      <analytic>
        <title level="a">Introspectibles: Tangible Interaction to Foster Introspection</title>
        <author>
          <persName key="potioc-2014-idp93232">
            <foreName>Renaud</foreName>
            <surname>Gervais</surname>
            <initial>R.</initial>
          </persName>
          <persName key="potioc-2014-idp95672">
            <foreName>Joan Sol</foreName>
            <surname>Roo</surname>
            <initial>J. S.</initial>
          </persName>
          <persName key="potioc-2014-idp92000">
            <foreName>Jérémy</foreName>
            <surname>Frey</surname>
            <initial>J.</initial>
          </persName>
          <persName key="potioc-2014-idp62512">
            <foreName>Martin</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="no" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">Computing and Mental Health - CHI '16 Workshop</title>
        <loc>San Jose, United States</loc>
        <imprint>
          <dateStruct>
            <month>May</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01288336" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01288336</ref>
        </imprint>
        <meeting id="cid625298">
          <title>CHI Workshop on Computing and Mental Health</title>
          <num>2016</num>
          <abbr type="sigle"/>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid41" type="inproceedings" rend="year" n="cite:gervais:hal-01215502">
      <identifiant type="hal" value="hal-01215502"/>
      <analytic>
        <title level="a">Tangible Viewports: Getting Out of Flatland in Desktop Environments</title>
        <author>
          <persName key="potioc-2014-idp93232">
            <foreName>Renaud</foreName>
            <surname>Gervais</surname>
            <initial>R.</initial>
          </persName>
          <persName>
            <foreName>Joan</foreName>
            <surname>Sol Roo</surname>
            <initial>J.</initial>
          </persName>
          <persName key="potioc-2014-idp62512">
            <foreName>Martin</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">TEI'16</title>
        <loc>Eindhoven, Netherlands</loc>
        <imprint>
          <dateStruct>
            <month>February</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01215502" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01215502</ref>
        </imprint>
        <meeting id="cid302129">
          <title>International Conference on Tangible and Embedded Interaction</title>
          <num>2016</num>
          <abbr type="sigle">TEI</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid16" type="inproceedings" rend="year" n="cite:jeunet:hal-01285369">
      <identifiant type="hal" value="hal-01285369"/>
      <analytic>
        <title level="a">Spatial Abilities Play a Major Role in BCI Performance</title>
        <author>
          <persName key="potioc-2014-idp94448">
            <foreName>Camille</foreName>
            <surname>Jeunet</surname>
            <initial>C.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
          <persName key="potioc-2014-idp62512">
            <foreName>M</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
          <persName>
            <foreName>S</foreName>
            <surname>Subramanian</surname>
            <initial>S.</initial>
          </persName>
          <persName key="phoenix-2014-idp102184">
            <foreName>Bernard</foreName>
            <surname>N'Kaoua</surname>
            <initial>B.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="no" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">6th International BCI Meeting</title>
        <loc>Asilomar, United States</loc>
        <imprint>
          <dateStruct>
            <month>May</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01285369" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01285369</ref>
        </imprint>
        <meeting id="cid105860">
          <title>International Brain-Computer Interface Workshop</title>
          <num>2016</num>
          <abbr type="sigle">BCI</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid32" type="inproceedings" rend="year" n="cite:jeunet:hal-01285365">
      <identifiant type="hal" value="hal-01285365"/>
      <analytic>
        <title level="a">Why and How to Use Intelligent Tutoring Systems to Adapt MI-BCI Training to Each User</title>
        <author>
          <persName key="potioc-2014-idp94448">
            <foreName>Camille</foreName>
            <surname>Jeunet</surname>
            <initial>C.</initial>
          </persName>
          <persName key="phoenix-2014-idp102184">
            <foreName>Bernard</foreName>
            <surname>N'Kaoua</surname>
            <initial>B.</initial>
          </persName>
          <persName>
            <foreName>R</foreName>
            <surname>N'Kambou</surname>
            <initial>R.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="no" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">6th International BCI Meeting</title>
        <loc>Asilomar, United States</loc>
        <imprint>
          <dateStruct>
            <month>May</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01285365" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01285365</ref>
        </imprint>
        <meeting id="cid105860">
          <title>International Brain-Computer Interface Workshop</title>
          <num>2016</num>
          <abbr type="sigle">BCI</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid17" type="inproceedings" rend="year" n="cite:teillet:hal-01341042">
      <identifiant type="hal" value="hal-01341042"/>
      <analytic>
        <title level="a">Towards a Spatial Ability Training to Improve Mental Imagery based Brain-Computer Interface (MI-BCI) Performance: a Pilot Study</title>
        <author>
          <persName key="potioc-2016-idp159232">
            <foreName>Suzy</foreName>
            <surname>Teillet</surname>
            <initial>S.</initial>
          </persName>
          <persName key="potioc-2014-idp65160">
            <foreName>Fabien</foreName>
            <surname>Lotte</surname>
            <initial>F.</initial>
          </persName>
          <persName key="phoenix-2014-idp102184">
            <foreName>Bernard</foreName>
            <surname>N'Kaoua</surname>
            <initial>B.</initial>
          </persName>
          <persName key="potioc-2014-idp94448">
            <foreName>Camille</foreName>
            <surname>Jeunet</surname>
            <initial>C.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">IEEE International Conference on Systems, Man, and Cybernetics (SMC 2016)</title>
        <loc>Budapest, Hungary</loc>
        <imprint>
          <dateStruct>
            <month>October</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">6</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01341042" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01341042</ref>
        </imprint>
        <meeting id="cid623918">
          <title>IEEE international conference on systems, man, and cybernetics</title>
          <num>2016</num>
          <abbr type="sigle">SMC</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid45" type="misc" rend="year" n="cite:avila:hal-01330496">
      <identifiant type="hal" value="hal-01330496"/>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" x-proceedings="no" x-invited-conference="no">
        <title level="m">Remote Assistance for Blind Users in Daily Life: A Survey about Be My Eyes</title>
        <author>
          <persName>
            <foreName>Mauro</foreName>
            <surname>Avila</surname>
            <initial>M.</initial>
          </persName>
          <persName>
            <foreName>Katrin</foreName>
            <surname>Wolf</surname>
            <initial>K.</initial>
          </persName>
          <persName key="potioc-2014-idp63920">
            <foreName>Anke</foreName>
            <surname>Brock</surname>
            <initial>A.</initial>
          </persName>
          <persName>
            <foreName>Niels</foreName>
            <surname>Henze</surname>
            <initial>N.</initial>
          </persName>
        </author>
        <imprint>
          <publisher>
            <orgName>ACM</orgName>
          </publisher>
          <dateStruct>
            <month>June</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01330496" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01330496</ref>
        </imprint>
      </monogr>
      <note type="howpublished">The 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments - PETRA'16</note>
      <note type="bnote">Poster</note>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid27" type="unpublished" rend="year" n="cite:chatain:hal-01266202">
      <identifiant type="hal" value="hal-01266202"/>
      <monogr>
        <title level="m">SyMAPse: Design and Evaluation of an Augmented Reality Map</title>
        <author>
          <persName key="potioc-2015-idp74944">
            <foreName>Julia</foreName>
            <surname>Chatain</surname>
            <initial>J.</initial>
          </persName>
          <persName key="potioc-2014-idp63920">
            <foreName>Anke M.</foreName>
            <surname>Brock</surname>
            <initial>A. M.</initial>
          </persName>
          <persName key="potioc-2014-idp62512">
            <foreName>Martin</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
        </author>
        <imprint>
          <dateStruct>
            <month>January</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01266202" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01266202</ref>
        </imprint>
      </monogr>
      <note type="bnote">working paper or preprint</note>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid31" type="unpublished" rend="year" n="cite:roo:hal-01284005">
      <identifiant type="hal" value="hal-01284005"/>
      <monogr>
        <title level="m">Interacting with Spatial Augmented Reality</title>
        <author>
          <persName key="potioc-2014-idp95672">
            <foreName>Joan Sol</foreName>
            <surname>Roo</surname>
            <initial>J. S.</initial>
          </persName>
          <persName key="potioc-2014-idp62512">
            <foreName>Martin</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
        </author>
        <imprint>
          <dateStruct>
            <month>March</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01284005" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01284005</ref>
        </imprint>
      </monogr>
      <note type="bnote">working paper or preprint</note>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid20" type="misc" rend="year" n="cite:serpa:hal-01302385">
      <identifiant type="hal" value="hal-01302385"/>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" x-proceedings="no" x-invited-conference="no">
        <title level="m">Conception et évaluation de techniques d'interaction non-visuelles sur tablettes numériques : impact sur l'exploration haptique et la mémorisation</title>
        <author>
          <persName>
            <foreName>Antonio</foreName>
            <surname>Serpa</surname>
            <initial>A.</initial>
          </persName>
          <persName>
            <foreName>Mathieu</foreName>
            <surname>Simonnet</surname>
            <initial>M.</initial>
          </persName>
          <persName key="potioc-2014-idp63920">
            <foreName>Anke</foreName>
            <surname>Brock</surname>
            <initial>A.</initial>
          </persName>
          <persName>
            <foreName>Bernard</foreName>
            <surname>Oriola</surname>
            <initial>B.</initial>
          </persName>
          <persName>
            <foreName>Christophe</foreName>
            <surname>Jouffrais</surname>
            <initial>C.</initial>
          </persName>
        </author>
        <imprint>
          <dateStruct>
            <month>March</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01302385" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01302385</ref>
        </imprint>
      </monogr>
      <note type="howpublished">INSHEA INTERNATIONAL CONFERENCE Sensory issues and Disability - Touch to learn, touch to communicate </note>
      <note type="bnote">Poster</note>
    </biblStruct>
    
    <biblStruct id="potioc-2016-bid30" type="misc" rend="year" n="cite:solroo:hal-01237378">
      <identifiant type="doi" value="10.1145/2839462.2856532"/>
      <identifiant type="hal" value="hal-01237378"/>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" x-proceedings="no" x-invited-conference="no">
        <title level="m">Inner Garden: an Augmented Sandbox Designed for Self-Reflection</title>
        <author>
          <persName>
            <foreName>Joan</foreName>
            <surname>Sol Roo</surname>
            <initial>J.</initial>
          </persName>
          <persName key="potioc-2014-idp93232">
            <foreName>Renaud</foreName>
            <surname>Gervais</surname>
            <initial>R.</initial>
          </persName>
          <persName key="potioc-2014-idp62512">
            <foreName>Martin</foreName>
            <surname>Hachet</surname>
            <initial>M.</initial>
          </persName>
        </author>
        <imprint>
          <dateStruct>
            <month>February</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01237378" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01237378</ref>
        </imprint>
      </monogr>
      <note type="howpublished">TEI'16 - Tenth International Conference on Tangible, Embedded, and Embodied Interaction</note>
      <note type="bnote">Poster</note>
    </biblStruct>
  </biblio>
</raweb>
