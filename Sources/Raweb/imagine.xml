<?xml version="1.0" encoding="utf-8"?>
<raweb xmlns:xlink="http://www.w3.org/1999/xlink" xml:lang="en" year="2016">
  <identification id="imagine" isproject="true">
    <shortname>IMAGINE</shortname>
    <projectName>Intuitive Modeling and Animation for Interactive Graphics &amp; Narrative Environments</projectName>
    <theme-de-recherche>Interaction and visualization</theme-de-recherche>
    <domaine-de-recherche>Perception, Cognition and Interaction</domaine-de-recherche>
    <urlTeam>https://team.inria.fr/imagine/</urlTeam>
    <structure_exterieure type="Labs">
      <libelle>Laboratoire Jean Kuntzmann (LJK)</libelle>
    </structure_exterieure>
    <structure_exterieure type="Organism">
      <libelle>CNRS</libelle>
    </structure_exterieure>
    <structure_exterieure type="Organism">
      <libelle>Institut polytechnique de Grenoble</libelle>
    </structure_exterieure>
    <structure_exterieure type="Organism">
      <libelle>Université Grenoble Alpes</libelle>
    </structure_exterieure>
    <header_dates_team>Creation of the Team: 2012 January 01, updated into Project-Team: 2013 January 01</header_dates_team>
    <LeTypeProjet>Project-Team</LeTypeProjet>
    <keywordsSdN>
      <term>5. - Interaction, multimedia and robotics</term>
      <term>5.5. - Computer graphics</term>
      <term>5.5.1. - Geometrical modeling</term>
      <term>5.5.3. - Computational photography</term>
      <term>5.5.4. - Animation</term>
      <term>5.7. - Audio modeling and processing</term>
      <term>8.3. - Signal analysis</term>
    </keywordsSdN>
    <keywordsSecteurs>
      <term>2. - Health</term>
      <term>2.2. - Physiology and diseases</term>
      <term>3. - Environment and planet</term>
      <term>3.3. - Geosciences</term>
      <term>5. - Industry of the future</term>
      <term>5.2. - Design and manufacturing</term>
      <term>5.7. - 3D printing</term>
      <term>9.1. - Education</term>
      <term>9.2.2. - Cinema, Television</term>
      <term>9.2.3. - Video games</term>
      <term>9.2.4. - Theater</term>
      <term>9.5.6. - Archeology, History</term>
    </keywordsSecteurs>
    <UR name="Grenoble"/>
  </identification>
  <team id="uid1">
    <person key="imagine-2015-idm27664">
      <firstname>Marie Paule</firstname>
      <lastname>Cani</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Grenoble INP, Professor, ENSIMAG</moreinfo>
      <hdr>oui</hdr>
    </person>
    <person key="prima-2014-idp64856">
      <firstname>Frederic</firstname>
      <lastname>Devernay</lastname>
      <categoryPro>Chercheur</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Inria, Senior Researcher</moreinfo>
    </person>
    <person key="imagine-2014-idp103248">
      <firstname>Remi</firstname>
      <lastname>Ronfard</lastname>
      <categoryPro>Chercheur</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Inria, Senior Researcher, Team leader</moreinfo>
      <hdr>oui</hdr>
    </person>
    <person key="imagine-2014-idp104680">
      <firstname>Francois</firstname>
      <lastname>Faure</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Anatoscope, INCUB-RAL, Professor</moreinfo>
      <hdr>oui</hdr>
    </person>
    <person key="imagine-2014-idp106136">
      <firstname>Stefanie</firstname>
      <lastname>Hahmann</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Grenoble INP, Professor, ENSIMAG</moreinfo>
      <hdr>oui</hdr>
    </person>
    <person key="imagine-2015-idp68840">
      <firstname>Jean Claude</firstname>
      <lastname>Leon</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Grenoble INP, Professor, ENSE3</moreinfo>
      <hdr>oui</hdr>
    </person>
    <person key="imagine-2014-idp109032">
      <firstname>Olivier</firstname>
      <lastname>Palombi</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>UJF, Professor in Anatomy and Neurosurgery, Anatomy Laboratory</moreinfo>
      <hdr>oui</hdr>
    </person>
    <person key="imagine-2014-idp110512">
      <firstname>Damien</firstname>
      <lastname>Rohmer</lastname>
      <categoryPro>Enseignant</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>CPE Lyon, Associate Professor</moreinfo>
    </person>
    <person key="imagine-2014-idp111768">
      <firstname>Antoine</firstname>
      <lastname>Begault</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>INP, March 2013 - March 2017, ERC Expressive</moreinfo>
    </person>
    <person key="imagine-2014-idp115616">
      <firstname>Estelle</firstname>
      <lastname>Charleroy</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>INP, Computer Artist, September 2013 - March 2017, ERC Expressive</moreinfo>
    </person>
    <person key="prima-2014-idp81720">
      <firstname>Alexandre</firstname>
      <lastname>Gauthier-Foichat</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Inria, January 2016 - December 2017</moreinfo>
    </person>
    <person key="nano-d-2014-idp78168">
      <firstname>Gabriel</firstname>
      <lastname>Gonzalez</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>UGA, November 2015 - October 2016</moreinfo>
    </person>
    <person key="imagine-2014-idp119488">
      <firstname>Thomas</firstname>
      <lastname>Lemaire</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Inria, September 2013 – April 2017, Piper</moreinfo>
    </person>
    <person key="imagine-2014-idp120768">
      <firstname>Matthieu</firstname>
      <lastname>Nesme</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Inria, September 2012 - September 2016, Dynam'it</moreinfo>
    </person>
    <person key="imagine-2016-idp148240">
      <firstname>Ole-Andre</firstname>
      <lastname>Rodlie</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Inria, December 2015 - November 2016</moreinfo>
    </person>
    <person key="imagine-2014-idp123320">
      <firstname>Romain</firstname>
      <lastname>Testylier</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Inria, October 2013 – Sept 2016, Collodi</moreinfo>
    </person>
    <person key="imagine-2015-idp87256">
      <firstname>Harold</firstname>
      <lastname>Vilmart</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Grenoble INP, May 2016 – December 2018</moreinfo>
    </person>
    <person key="imagine-2016-idp155840">
      <firstname>Youna</firstname>
      <lastname>Le Vaou</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Grenoble INP Grenoble, from November 2016</moreinfo>
    </person>
    <person key="imagine-2015-idp79432">
      <firstname>Boris</firstname>
      <lastname>Gallet</lastname>
      <categoryPro>Technique</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Floralys, February 2015 - July 2016</moreinfo>
    </person>
    <person key="maverick-2014-idp117664">
      <firstname>Leo</firstname>
      <lastname>Allemand-Giorgis</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Grenoble University, October 2012 - April 2016, alloc MENSR, 50% with MAVERICK</moreinfo>
    </person>
    <person key="imagine-2014-idp127136">
      <firstname>Armelle</firstname>
      <lastname>Bauer</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>UJF, October 2013 - October 2016, Labex Persyval</moreinfo>
    </person>
    <person key="prima-2014-idp103120">
      <firstname>Romain</firstname>
      <lastname>Bregier</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>SILEANE, January 2016 - September 2017, granted by CIFRE</moreinfo>
    </person>
    <person key="imagine-2015-idp91096">
      <firstname>Guillaume</firstname>
      <lastname>Cordonnier</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Univ. Grenoble I, October 2015 - September 2018, alloc MENSR</moreinfo>
    </person>
    <person key="imagine-2015-idp92368">
      <firstname>Pablo</firstname>
      <lastname>Coves</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>INP Grenoble, April 2015 - March 2018, ARC6 POTASSE</moreinfo>
    </person>
    <person key="imagine-2015-idp93624">
      <firstname>Sébastien</firstname>
      <lastname>Crozet</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>CEA, December 2014 - December 2017</moreinfo>
    </person>
    <person key="imagine-2014-idp132208">
      <firstname>Even</firstname>
      <lastname>Entem</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>INP Grenoble, November 2013 - November 2016, ERC Expressive</moreinfo>
    </person>
    <person key="graphdeco-2016-idp153648">
      <firstname>Amelie</firstname>
      <lastname>Fondevilla</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Grenoble University, October 2016 - September 2019</moreinfo>
    </person>
    <person key="imagine-2016-idp180624">
      <firstname>Maxime</firstname>
      <lastname>Garcia</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>UGA, October 2016 - September 2019</moreinfo>
    </person>
    <person key="imagine-2015-idp98664">
      <firstname>Geoffrey</firstname>
      <lastname>Guingo</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>INP, October 2015 - September 2018, ERC Expressive, 50% with U. Strasbourg</moreinfo>
    </person>
    <person key="imagine-2014-idp137312">
      <firstname>Aarohi Singh</firstname>
      <lastname>Johal</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>EDF, October 2013 - September 2016, granted by CIFRE</moreinfo>
    </person>
    <person key="imagine-2015-idp103776">
      <firstname>Pierre Luc</firstname>
      <lastname>Manteaux</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Grenoble University, October 2012 - September 2016, ERC Expressive</moreinfo>
    </person>
    <person key="prima-2015-idp101808">
      <firstname>Sandra</firstname>
      <lastname>Nabil Mahrous Yacoub</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Inria, October 2015 - September 2018</moreinfo>
    </person>
    <person key="prima-2014-idp109400">
      <firstname>Gregoire</firstname>
      <lastname>Nieto</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Inria, January 2016 - September 2019</moreinfo>
    </person>
    <person key="imagine-2015-idp105048">
      <firstname>Robin</firstname>
      <lastname>Roussel</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Grenoble University, October 2015 - October 2018, ERC Expressive, 50% with UCL London</moreinfo>
    </person>
    <person key="imagine-2014-idp142424">
      <firstname>Camille</firstname>
      <lastname>Schreck</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Grenoble INP, October 2013 - October 2016, ERC Expressive</moreinfo>
    </person>
    <person key="imagine-2014-idp143696">
      <firstname>Tibor</firstname>
      <lastname>Stanko</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Grenoble University and CEA, October 2014 - October 2017, Bourse CEA, 50% with Maverick</moreinfo>
    </person>
    <person key="imagine-2014-idp144992">
      <firstname>Ulysse</firstname>
      <lastname>Vimont</lastname>
      <categoryPro>PhD</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Grenoble INP, October 2013 - November 2016, ERC Expressive</moreinfo>
    </person>
    <person key="imagine-2014-idp125880">
      <firstname>Adela</firstname>
      <lastname>Barbulescu</lastname>
      <categoryPro>PostDoc</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>INP Grenoble, December 2015 - November 2016</moreinfo>
    </person>
    <person key="imagine-2014-idp147544">
      <firstname>Thomas</firstname>
      <lastname>Delame</lastname>
      <categoryPro>PostDoc</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Grenoble INP, September 2014 - September 2016, ERC Expressive</moreinfo>
    </person>
    <person key="imagine-2016-idp210448">
      <firstname>James</firstname>
      <lastname>Gain</lastname>
      <categoryPro>Visiteur</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>University of Cape Town, June 2016 - September 2016</moreinfo>
    </person>
    <person key="imagine-2014-idp152680">
      <firstname>Catherine</firstname>
      <lastname>Bessiere</lastname>
      <categoryPro>Assistant</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>50% Inria, until October 2016</moreinfo>
    </person>
    <person key="imagine-2016-idp215424">
      <firstname>Sanie</firstname>
      <lastname>Claraz</lastname>
      <categoryPro>Assistant</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>ERC Expressive, from March 2016</moreinfo>
    </person>
    <person key="imagine-2014-idp153912">
      <firstname>Fatima</firstname>
      <lastname>Kassimi</lastname>
      <categoryPro>Assistant</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>ERC Expressive, until March 2016</moreinfo>
    </person>
    <person key="exmo-2014-idp111040">
      <firstname>Marion</firstname>
      <lastname>Ponsot</lastname>
      <categoryPro>Assistant</categoryPro>
      <research-centre>Grenoble</research-centre>
      <moreinfo>Inria, from October 2016</moreinfo>
    </person>
  </team>
  <presentation id="uid2">
    <bodyTitle>Overall Objectives</bodyTitle>
    <subsection id="uid3" level="1">
      <bodyTitle>Context</bodyTitle>
      <p>With the fast increase of computational power and of memory space, increasingly complex and detailed 3D content is expected for virtual environments. Unfortunately, 3D modeling methodologies did not evolve as fast: most users still use standard CAD or 3D modeling software (such as Maya, 3DS or Blender) to design each 3D shape, to animate them and to manually control cameras for movie production. This is highly time consuming when large amounts of detailed content need to be produced. Moreover the quality of results is fully left in the user's hand, which restricts applicability to skilled professional artists.
More intuitive software such as Z-Brush are restricted to shape design and still require a few months for being mastered by sculpture practitioners. Reducing user load can be done by capturing and re-using real objects or motions, at the price of restricting the range of possible content. Lastly, procedural generation methods can be used in specific cases to automatically get some detailed, plausible content. Although they save user's time, these procedural methods typically come at the price of control: indirect parameters need to be tuned during a series of trial and errors until the desired result is reached. Stressing that even skilled digital artists tend to prefer pen and paper than 3D computerized tools during the design stages of shapes, motion, and stories, Rob Cook, vice president of technology at Pixar animation studios recently stated (key-note talk, Siggraph Asia 2009): <i>new grand challenge in Computer Graphics is to make tools as transparent to the artists as special effects were made transparent to the general public</i>.</p>
      <p><b>Could digital modeling be turned into a tool, even more expressive and simpler to use than a pen, to quickly convey and refine shapes, motions and stories?</b>
This is the long term vision towards which we would like to advance.</p>
    </subsection>
    <subsection id="uid4" level="1">
      <bodyTitle>Scientific goals</bodyTitle>
      <p>The goal of the IMAGINE project is to develop <b>a new generation of models, algorithms and interactive environments for the interactive creation of animated 3D content and its communication through virtual cinematography</b>.</p>
      <p>Our insight is to revisit models for shapes, motion, and narration from a user-centred perspective, i.e. to give models an intuitive, predictable behaviour from the user's view-point. This will ease both semi-automatic generation of animated 3D content and fine tuning of the results.
The three main fields will be addressed:</p>
      <orderedlist>
        <li id="uid5">
          <p noindent="true"><b>Shape design</b>: We aim to develop intuitive tools for designing and editing 3D shapes and their assemblies, from arbitrary ones to shapes that obey application-dependent constraints - such as, for instance, developable surfaces representing cloth or paper, or shape assemblies used for CAD of mechanical prototypes.</p>
        </li>
        <li id="uid6">
          <p noindent="true"><b>Motion synthesis</b>: Our goal is to ease the interactive generation and control of 3D motion and deformations, in particular by enabling intuitive, coarse to fine design of animations. The applications range from the simulation of passive objects to the control of virtual creatures.</p>
        </li>
        <li id="uid7">
          <p noindent="true"><b>Narrative design</b>: The aim is to help users to express, refine and convey temporal narrations, from stories to educational or industrial scenarios. We develop both virtual direction tools such as interactive storyboarding frameworks, and high-level models for virtual cinematography, such as rule-based cameras able to automatically follow the ongoing action and automatic film editing techniques.</p>
        </li>
      </orderedlist>
      <p>In addition to addressing specific needs of digital artists, this research contributes to the development of new expressive media for 3D content. The long term goal would be to enable any professional or scientist to model and interact with their object of study, to provide educators with ways to quickly express and convey their ideas, and to give the general public the ability to directly create animated 3D content.</p>
    </subsection>
  </presentation>
  <fondements id="uid8">
    <bodyTitle>Research Program</bodyTitle>
    <subsection id="uid9" level="1">
      <bodyTitle>Methodology</bodyTitle>
      <p>As already stressed, thinking of future digital modeling technologies as an Expressive Virtual Pen enabling to seamlessly design, refine and convey animated 3D content, leads to revisit models for shapes, motions and stories from a user-centered perspective. More specifically, inspiring from the user-centered interfaces developed in the Human Computer Interaction domain, we introduced the new concept of user-centered graphical models. Ideally, such models should be designed to behave, under any user action, the way a human user would have predicted. In our case, user's actions may include creation gestures such as sketching to draft a shape or direct a motion, deformation gestures such as stretching a shape in space or a motion in time, or copy-paste gestures to transfer some of the features from existing models to other ones. User-centered graphical models need to incorporate knowledge in order to seamlessly generate the appropriate content from such actions. We are using the following methodology to advance towards these goals:</p>
      <simplelist>
        <li id="uid10">
          <p noindent="true">Develop high-level models for shapes, motion and stories that embed the necessary knowledge to respond as expected to user actions. These models should provide the appropriate handles for conveying the user's intent while embedding procedural methods that seamlessly take care of the appropriate details and constraints.</p>
        </li>
        <li id="uid11">
          <p noindent="true">Combine these models with expressive design and control tools such as gesture-based control through sketching, sculpting, or acting, towards interactive environments where users can create a new virtual scene, play with it, edit or refine it, and semi-automatically convey it through a video.</p>
        </li>
      </simplelist>
    </subsection>
    <subsection id="uid12" level="1">
      <bodyTitle>Validation</bodyTitle>
      <p>Validation is a major challenge when developing digital creation tools: there is no ideal result to compare with, in contrast with more standard problems such as reconstructing existing shapes or motions. Therefore, we had to think ahead about our validation strategy: new models for geometry or animation can be validated, as usually done in Computer Graphics, by showing that they solve a problem never tackled before or that they provide a more general or more efficient solution than previous methods. The interaction methods we are developing for content creation and editing rely as much as possible on existing interaction design principles already validated within the HCI community. We also occasionally develop new interaction tools, most often in collaboration with this community, and validate them through user studies. Lastly, we work with expert users from various application domains through our collaborations with professional artists, scientists from other domains, and industrial partners: these expert users validate the use of our new tools compared to their usual pipeline.</p>
    </subsection>
    <subsection id="uid13" level="1">
      <bodyTitle>Application Domains</bodyTitle>
      <p>This research can be applied to any situation where users need to create new, imaginary, 3D content. Our work should be instrumental, in the long term, for the visual arts, from the creation of 3D films and games to the development of new digital planning tools for theater or cinema directors. Our models can also be used in interactive prototyping environments for engineering. They can help promoting interactive digital design to scientists, as a tool to quickly express, test and refine models, as well as an efficient way for conveying them to other people. Lastly, we expect our new methodology to put digital modeling within the reach of the general public, enabling educators, media and other practitioners to author their own 3D content.</p>
      <p>Our current application domains are:</p>
      <simplelist>
        <li id="uid14">
          <p noindent="true">Visual arts</p>
          <simplelist>
            <li id="uid15">
              <p noindent="true">Modeling and animation for 3D films and games.</p>
            </li>
            <li id="uid16">
              <p noindent="true">Virtual cinematography and tools for theater directors.</p>
            </li>
          </simplelist>
        </li>
        <li id="uid17">
          <p noindent="true">Engineering</p>
          <simplelist>
            <li id="uid18">
              <p noindent="true">Industrial design.</p>
            </li>
            <li id="uid19">
              <p noindent="true">Mechanical &amp; civil engineering.</p>
            </li>
          </simplelist>
        </li>
        <li id="uid20">
          <p noindent="true">Natural Sciences</p>
          <simplelist>
            <li id="uid21">
              <p noindent="true">Virtual functional anatomy.</p>
            </li>
            <li id="uid22">
              <p noindent="true">Virtual plants.</p>
            </li>
          </simplelist>
        </li>
        <li id="uid23">
          <p noindent="true">Education and Creative tools</p>
          <simplelist>
            <li id="uid24">
              <p noindent="true">Sketch-based teaching.</p>
            </li>
            <li id="uid25">
              <p noindent="true">Creative environments for novice users.</p>
            </li>
          </simplelist>
        </li>
      </simplelist>
      <p>The diversity of users these domains bring, from digital experts to other professionals and novices, gives us excellent opportunities to validate our general methodology with different categories of users. Our ongoing projects in these various application domains are listed in Section 6.</p>
    </subsection>
  </fondements>
  <highlights id="uid26">
    <bodyTitle>Highlights of the Year</bodyTitle>
    <subsection id="uid27" level="1">
      <bodyTitle>Highlights of the Year</bodyTitle>
      <simplelist>
        <li id="uid28">
          <p noindent="true">We had one paper accepted to EUROGRAPHICS <ref xlink:href="#imagine-2016-bid0" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        </li>
        <li id="uid29">
          <p noindent="true">Our work on virtual paper crumpling, published in ACM TOG paper in Dec. 2015 <ref xlink:href="#imagine-2016-bid1" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>, was presented at ACM SIGGRAPH 2016 in Anaheim (July 2016). Moreover, our paper on the sound of virtual paper <ref xlink:href="#imagine-2016-bid2" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/> received the best paper award at the ACM-EG Symposium on Computer Animation (SCA) 2016.</p>
        </li>
        <li id="uid30">
          <p noindent="true">We participated to two state of the art papers published in Computer Graphics Forum, respectively on Adaptive physically based models in computer graphics <ref xlink:href="#imagine-2016-bid3" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>, and on 3D Skeletons <ref xlink:href="#imagine-2016-bid4" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        </li>
        <li id="uid31">
          <p noindent="true">The paper The 2D Shape Structure Dataset: A User Annotated Open Access Database. Axel Carlier, Kathryn Leonard, Stefanie Hahmann, Geraldine Morin, Misha Collins. SMI’16, Computer &amp; Graphics 58, pp. 23-30 (2016).received the "Reproducability Award" (<ref xlink:href="http://www.reproducibilitystamp.com" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>www.<allowbreak/>reproducibilitystamp.<allowbreak/>com</ref>).</p>
        </li>
        <li id="uid32">
          <p noindent="true">Four students defended their PhD within the team.</p>
        </li>
        <li id="uid33">
          <p noindent="true">Anatoscope, the start-up founded by François Faure and Olivier Palombi, was selected by <i>Sud De France Dévelopement</i> to have a booth at the CES, Las Vegas, in January. They featured a live demonstration of the Living Book of Anatomy.</p>
        </li>
        <li id="uid34">
          <p noindent="true">The first FUI project Collodi with TeamTo and Mercenaries engineering terminated this year. We have successfully delivered the physics simulation engine for cloth and hair to include it in the commercial distribution of the project. A a second FUI project Collodi 2 focusing on animation is starting in December 2016.</p>
        </li>
      </simplelist>
      <subsection id="uid35" level="2">
        <bodyTitle>Awards</bodyTitle>
        <best>
          <ref xlink:href="#imagine-2016-bid2" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>
        </best>
      </subsection>
    </subsection>
  </highlights>
  <logiciels id="uid36">
    <bodyTitle>New Software and Platforms</bodyTitle>
    <subsection id="uid37" level="1">
      <bodyTitle>Expressive</bodyTitle>
      <p>Expressive is a new C++ library created in 2013 for gathering and sharing the models and algorithms developed within the ERC Expressive project. It enables us to make our latest research results on new creative tools - such as high level models with intuitive, sketching or sculpting interfaces - soon available to the rest of the group and easily usable for our collaborators, such as Evelyne Hubert (Inria, Galaad) or Loic Barthe (IRIT, Toulouse). The most advanced part is a new version of Convol, a library dedicated to implicit modeling, with a main focus on integral surfaces along skeletons. Convol incorporates all the necessary material for constructive implicit modeling, a variety of blending operators and several methods for tessellating an implicit surface into a mesh, and for refining it in highly curved regions. The creation of new solid geometry can be performed by direct manipulation of skeletal primitives or through sketch-based modeling and multi-touch deformations.</p>
      <simplelist>
        <li id="uid38">
          <p noindent="true">Participants: Marie Paule Cani, Antoine Begault, Even Entem, Thomas Delame, Ulysse Vimont</p>
        </li>
        <li id="uid39">
          <p noindent="true">Contact: Marie Paule Cani</p>
        </li>
      </simplelist>
    </subsection>
    <subsection id="uid40" level="1">
      <bodyTitle>MyCF</bodyTitle>
      <object id="uid41">
        <table>
          <tr>
            <td>
              <ressource xlink:href="IMG/mycf_sofa.jpg" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
          </tr>
        </table>
        <caption>Left: My Corporis Fabrica is an anatomical knowledge database developed in our team. Right: SOFA is an open source simulator for physically based modeling.</caption>
      </object>
      <p><ref xlink:href="http://www.mycorporisfabrica.org/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">My Corporis Fabrica (<b>MyCF</b>)</ref> is an anatomical knowledge ontology developed in our group. It relies on FMA (Foundational Model of Anatomy), developed under Creative Commons license (CC-by). MyCF browser is available on line, and is already in use for education and research in anatomy. Moreover, the MyCf's generic programming framework can be used for other domains, since the link it provides between semantic and 3D models matches several other research applications at IMAGINE.</p>
      <simplelist>
        <li id="uid42">
          <p noindent="true">Participants: Olivier Palombi, Armelle Bauer, François Faure, Ali Hamadi Dicko</p>
        </li>
        <li id="uid43">
          <p noindent="true">Contact: Olivier Palombi</p>
        </li>
        <li id="uid44">
          <p noindent="true">URL: <ref xlink:href="http://www.mycorporisfabrica.org" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>www.<allowbreak/>mycorporisfabrica.<allowbreak/>org</ref></p>
        </li>
      </simplelist>
    </subsection>
    <subsection id="uid45" level="1">
      <bodyTitle>SOFA</bodyTitle>
      <p>Simulation Open Framework Architecture</p>
      <p noindent="true">SOFA is an Open Source framework primarily targeted at real-time simulation, with an emphasis on medical simulation. It is mostly intended for the research community to help develop new algorithms, but can also be used as an efficient prototyping tool. Based on an advanced software architecture, it allows : the creation of complex and evolving simulations by combining new algorithms with algorithms already included in SOFA, the modification of most parameters of the simulation (deformable behavior, surface representation, solver, constraints, collision algorithm, etc. ) by simply editing an XML file, the building of complex models from simpler ones using a scene-graph description, the efficient simulation of the dynamics of interacting objects using abstract equation solvers, the reuse and easy comparison of a variety of available methods.</p>
      <p noindent="true">Sofa is extensively used by Anatoscope, who add proprietary plugins and helps maintaining the public plugins.</p>
      <simplelist>
        <li id="uid46">
          <p noindent="true">Participants: François Faure, Armelle Bauer, Matthieu Nesme, Romain Testylier.</p>
        </li>
        <li id="uid47">
          <p noindent="true">Contact: François Faure</p>
        </li>
        <li id="uid48">
          <p noindent="true">URL: <ref xlink:href="http://www.sofa-framework.org" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>www.<allowbreak/>sofa-framework.<allowbreak/>org</ref></p>
        </li>
      </simplelist>
    </subsection>
    <subsection id="uid49" level="1">
      <bodyTitle>Natron</bodyTitle>
      <object id="uid50">
        <table>
          <tr>
            <td>
              <ressource xlink:href="IMG/natron.jpg" type="float" width="298.8987pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
            </td>
          </tr>
        </table>
        <caption>Video compositing using the Natron interface.</caption>
      </object>
      <p>Natron (<ref xlink:href="http://natron.fr" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>natron.<allowbreak/>fr</ref>) is a professional-quality video post-production software specialized in compositing and visual effects. Compositing is the combining of visual elements from separate sources into single images, often to create the illusion that all those elements are parts of the same scene. The math behind compositing was formalized by Porter &amp; Duff (1984) after the preliminary work by Wallace (1981).</p>
      <p>Typical examples of compositing are, for example:</p>
      <p>- The superimposition of a character filmed on a green background over a scene shot in another place, at another time, or a computer-generated scene;
- The manual detouring (also called rotoscopy) of an element in a video to embed it in another video, possibly with a different motion;
- Artistic modifications of a video, after shooting a live-action scene or rendering a CGI scene, in order to modify its lighting, colors, depth of field, camera motion, or to remove noise or add film grain.</p>
      <p>A video compositing software is not a 3D computer graphics software, like Blender or Maya, but it is perfectly suited for combining computer-generated elements produced by other software with live-action video or 2D animation. Rather than rendering a full 3D scene with the 3D software, which may cost many hours of computation, the video compositing software can assemble the elements produced separately with a much more reactive interface and an almost instantaneous visual feedback.</p>
      <simplelist>
        <li id="uid51">
          <p noindent="true">Participants: Frédéric Devernay, Alexandre Gauthier-Foichat.</p>
        </li>
        <li id="uid52">
          <p noindent="true">Contact: Frédéric Devernay</p>
        </li>
        <li id="uid53">
          <p noindent="true">URL: <ref xlink:href="http://natron.fr" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>natron.<allowbreak/>fr</ref></p>
        </li>
      </simplelist>
    </subsection>
  </logiciels>
  <resultats id="uid54">
    <bodyTitle>New Results</bodyTitle>
    <subsection id="uid55" level="1">
      <bodyTitle>User-centered Models for Shapes and Shape Assemblies</bodyTitle>
      <simplelist>
        <li id="uid56">
          <p noindent="true"><b>Scientist in charge</b>: Stefanie Hahmann.</p>
        </li>
        <li id="uid57">
          <p noindent="true"><b>Other permanent researchers</b>: Marie-Paule Cani, Jean-Claude Léon, Damien Rohmer.</p>
        </li>
      </simplelist>
      <p>Our goal, is to develop responsive shape models, i.e. 3D models that respond in the expected way under any user action, by maintaining specific application-dependent constraints (such as a volumetric objects keeping their volume when bent, or cloth-like surfaces remaining developable during deformation, etc). We are extending this approach to composite objects made of distributions and/or combination of sub-shapes of various dimensions.</p>
      <subsection id="uid58" level="2">
        <bodyTitle>Shape analysis</bodyTitle>
        <object id="uid59">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/1_1_shape_analysis.jpg" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>Left: Illustration of comparative study of 3D medial axis quality in <ref xlink:href="#imagine-2016-bid5" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. Right: Hierarchies for similar shapes (dancers) in different poses to show that the proposed hierarchy is stable under articulation <ref xlink:href="#imagine-2016-bid6" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. Coarser levels of the hierarchy are consistent even if finer levels are added in the presence of finer details. Also, note that the hierarchy is retained even with occlusion: The pink level of the left arm of the first dancer is occluded, but the blue level begins as it should.</caption>
        </object>
        <p>Within the post-doc of Thomas Delame a comparative study between 3D skeletonization methods has been achieved. This work has been summarized as a Eurographics State of the Art <ref xlink:href="#imagine-2016-bid4" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. Moreover, a comparative study of the quality between 3D medial axis was assessed and published in Vision, Modeling and Visualization <ref xlink:href="#imagine-2016-bid5" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        <p>We developed a multilevel analysis method of 2D shapes and used it to find similarities between the different parts of a shape <ref xlink:href="#imagine-2016-bid6" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. Such an analysis is important for many applications such as shape comparison, editing, and compression. Our robust and stable method decomposes a shape into parts, determines a parts hierarchy, and measures similarity between parts based on a salience measure on the medial axis, the Weighted Extended Distance Function, providing a multi-resolution partition of the shape that is stable across scale and articulation. Comparison with our extensive user study on the MPEG-7 database, see below, demonstrates that our geometric results are consistent with user perception. This work has been accomplished within a collaboration between S. Hahmann, Kathryn Leonard (CSUCI), and Geraldine Morin and Axel Carlier (IRIT, ENSEEIHT). K. Leonard was visiting the Imagine team during several month in 2016 as an invited professor funded by the ERC Expressive grant.</p>
        <p>We also conducted a large user-study and made the results available throughout an open access data base: The 2D Shape Structure database <ref xlink:href="#imagine-2016-bid7" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/> is a public, user-generated dataset of 2D shape decompositions into a hierarchy of shape parts with geometric relationships retained. It is the outcome of a large-scale user study obtained by crowdsourcing, involving over 1200 shapes in 70 shape classes, and 2861 participants. A total of 41953 annotations has been collected with at least 24 annotations per shape. For each shape, user decompositions into main shape, one or more levels of parts, and a level of details are available. This database reinforces a philosophy that understanding shape structure as a whole, rather than in the separated categories of parts decomposition, parts hierarchy, and analysis of relationships between parts, is crucial for full shape understanding. We provide initial statistical explorations of the data to determine representative (“mean”) shape annotations and to determine the number of modes in the annotations. The primary goal of this work is to make this rich and complex database openly available (through the website <ref xlink:href="http://2dshapesstructure.github.io" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>2dshapesstructure.<allowbreak/>github.<allowbreak/>io</ref>), providing the shape community with a ground truth of human perception of holistic shape structure. This paper has received the « Reproducibility Award » (<ref xlink:href="http://www.reproducibilitystamp.com" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>www.<allowbreak/>reproducibilitystamp.<allowbreak/>com</ref>).</p>
      </subsection>
      <subsection id="uid60" level="2">
        <bodyTitle>Surface design</bodyTitle>
        <object id="uid61">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/1_2_1_surface_design.jpg" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>Left: Illustration of results of <ref xlink:href="#imagine-2016-bid8" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</caption>
        </object>
        <p>Recent surface acquisition technologies based on micro-sensors produce three-space tangential curve data which can be transformed into a network of space curves with surface normals. In the thesis of Tibor Stanko, which is funded by the CEA-LETI, we dispose such a mobile device equipped with several micro-sensors. The goal of the thesis is to develop surface acquisitions methods using this equipped mobile device. As a first step, we address the theoretical and algorithmic problem of surfacing an arbitrary closed 3D curve network with given surface normals. Thanks to the normal vector input, the patch finding problem can be solved unambiguously and an initial piecewise smooth triangle mesh is computed. The input normals are propagated throughout the mesh. Together with the initial mesh, the propagated normals are used to compute mean curvature vectors. We then compute the final mesh as the solution of a new variational optimization method based on the mean curvature vectors. The intuition behind this original approach is to guide the standard Laplacian-based variational methods by the curvature information extracted from the input normals. The normal input increases shape fidelity and allows to achieve globally smooth and visually pleasing shapes. This work has been presented at Eurographics 2016 as a short paper <ref xlink:href="#imagine-2016-bid9" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/> and GTMG 2016 <ref xlink:href="#imagine-2016-bid10" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/> and has been published as a journal paper <ref xlink:href="#imagine-2016-bid8" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        <object id="uid62">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/1_2_2_surface_design.jpg" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>The terrain data set of Mt Rainier: Surface reconstruction (c) with contour lines (b) from the MS complex with 69 critical points(a) <ref xlink:href="#imagine-2016-bid11" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</caption>
        </object>
        <p>Morse-Smale complexes have been proposed to visualize topological features of scalar fields defined on manifold domains. Herein, three main problems have been addressed in the past: (a) efficient computation of the initial combinatorial structure connecting the critical points; (b) simplification of these combinatorial structures; (c) reconstruction of a scalar field in accordance to the simplified Morse-Smale complex. The PhD thesis of Leo Allemand-Giorgis faces the third problem by proposing a novel approach for computing a scalar field coherent with a given simplified MS complex that privileges the use of piecewise polynomial functions <ref xlink:href="#imagine-2016-bid11" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. Based on techniques borrowed from shape preserving design in Computer Aided Geometric Design, our method constructs the surface cell by cell using piecewise polynomial curves and surfaces.</p>
      </subsection>
    </subsection>
    <subsection id="uid63" level="1">
      <bodyTitle>Motion &amp; Sound Synthesis</bodyTitle>
      <simplelist>
        <li id="uid64">
          <p noindent="true"><b>Scientist in charge</b>: François Faure.</p>
        </li>
        <li id="uid65">
          <p noindent="true"><b>Other permanent researchers</b>: Marie-Paule Cani, Damien Rohmer, Rémi Ronfard.</p>
        </li>
      </simplelist>
      <p>Animating objects in real-time is mandatory to enable user interaction during motion design. Physically-based models, an excellent paradigm for generating motions that a human user would expect, tend to lack efficiency for complex shapes due to their use of low-level geometry (such as fine meshes). Our goal is therefore two-folds: first, develop efficient physically-based models and collisions processing methods for arbitrary passive objects, by decoupling deformations from the possibly complex, geometric representation; second, study the combination of animation models with geometric responsive shapes, enabling the animation of complex constrained shapes in real-time. The last goal is to start developing coarse to fine animation models for virtual creatures, towards easier authoring of character animation for our work on narrative design.</p>
      <subsection id="uid66" level="2">
        <bodyTitle>Physically-based models</bodyTitle>
        <p>We proposed a survey on the exhisting adaptative physically based models in Computer Graphics in collaboration with IST Austria, University of Minnesota, and NANO-D Inria team. Models where classified according to the strategy they use for adaptation, from time-stepping and freezing techniques to geometric adaptivity in the form of structured grids, meshes, and particles. Applications range from fluids, through deformable bodies, to articulated solids. The survey has been published as a Eurographics state of the art <ref xlink:href="#imagine-2016-bid3" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
        <p>In collaboration with the <i>Reproduction et Développement des Plantes</i> Lab (ENS Lyon), we proposed a realistic three-dimensional mechanical model of the indentation of a flower bud using the SOFA library, in order to provide a framework for the analysis of force-displacement curves obtained experimentally <ref xlink:href="#imagine-2016-bid12" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
      </subsection>
      <subsection id="uid67" level="2">
        <bodyTitle>Simulating paper material with sound</bodyTitle>
        <object id="uid68">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/2_2_simulating_paper_material.jpg" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>Left: Geometrical deformation using our geometrical model from <ref xlink:href="#imagine-2016-bid1" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. Right: Various paper deformation and type leading to different synthesized sounds <ref xlink:href="#imagine-2016-bid2" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</caption>
        </object>
        <p>We developed within the PhD from Camille Schreck a dedicated approach to model a real time deforming virtual sheet of paper. First we developed a geometrical model interleaving physically based elastic deformation with a dedicated geometrical correction and remeshing. The key idea consists in modeling the surface using a set of generalized cones able to model developable ruled surfaces instead of the more traditional set of triangles. This surface can handle length preservation with respect to the 2D pattern, and permanent non smooth crumpling appearance. This geometrical model published in ACM Transactions on Graphics in Dec. 2015 <ref xlink:href="#imagine-2016-bid1" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/> has been presented at ACM SIGGRAPH this summer and is currently under investigation to be part of Inria Showroom.
This model has then been extended to real time sound synthesis of crumpled paper within the collaboration with Doug James (Stanford University). This method was the first to handle real-time shape dependent sound synthesis. During the interactive deformation, sudden curvature changes and friction are detected. These sound generating events are then associated to a geometrical region where the sound resonates and defined efficiently using previous geometrical model. Finally, the sound is synthesized using a pre-recorded sound data base of crumple and friction events sorted with respect to the resonator region size. This work has been published at Symposium on Computer Animation <ref xlink:href="#imagine-2016-bid2" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/> and received the best paper award.</p>
      </subsection>
      <subsection id="uid69" level="2">
        <bodyTitle>Human motion</bodyTitle>
        <object id="uid70">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/2_3.png" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>Live tracking and visualization of a plausible anatomical skeleton following the pose the subject <ref xlink:href="#imagine-2016-bid13" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</caption>
        </object>
        <p>Armelle Bauer defended her PhD in November, co-advised with TIMC (Jocelyne Troccaz as principal advisor), on Augmented Reality for the interactive visualization of human anatomy. This is one of the main achievements of the Living Book of Anatomy project, funded by Labex Persyval.
This work was partly published at the Motion in Games conference (MIG 2016) <ref xlink:href="#imagine-2016-bid13" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.
It served as a basis for the follow-up ANR project Anatomy2020 involving Anatoscope, TIMC and LIG laboratories, and Univ Lyon 2.</p>
      </subsection>
    </subsection>
    <subsection id="uid71" level="1">
      <bodyTitle>Knowledge-based Models for Narrative Design</bodyTitle>
      <simplelist>
        <li id="uid72">
          <p noindent="true"><b>Scientist in charge</b>: Rémi Ronfard.</p>
        </li>
        <li id="uid73">
          <p noindent="true"><b>Other permanent researchers</b>: Marie-Paule Cani, Frédéric Devernay, François Faure, Jean-Claude Léon, Olivier Palombi.</p>
        </li>
      </simplelist>
      <p>Our long term goal is to develop high-level models helping users to express and convey their own narrative content (from fiction stories to more practical educational or demonstrative scenarios). Before being able to specify the narration, a first step is to define models able to express some a priori knowledge on the background scene and on the object(s) or character(s) of interest. Our first goal is to develop 3D ontologies able to express such knowledge. The second goal is to define a representation for narration, to be used in future storyboarding frameworks and virtual direction tools. Our last goal is to develop high-level models for virtual cinematography such as rule-based cameras able to automatically follow the ongoing action and semi-automatic editing tools enabling to easily convey the narration via a movie.</p>
      <subsection id="uid74" level="2">
        <bodyTitle>Virtual cameras</bodyTitle>
        <p>Filming live action requires a coincidence of many factors: actors of course, but also lighting, sound capture, set design, and finally the camera (position, frame, and motion). Some of these, such as sound and lighting, can be more or less reworked in post-production, but the camera parameters are usually considered to be fixed at shooting time. We developed two kinds of image-based rendering technique, which allows to change in post-production either the camera frame (in terms of pan, tilt, and zoom), or the camera position.</p>
        <p>To be able to change the camera frame after shooting, we developed techniques to construct a video panorama from a set of cameras placed roughly at the same position. Video panorama exhibits a specific problem, which is not present in photo panorama: because the projection centers of the cameras can not physically be at the same location, there is residual parallax between the video sequences, which produce artifacts when the videos are stitched together. Sandra Nabil has worked during her PhD on producing video panoramas without visible artifacts, which can be used to freely pick the camera frame in terms of pan, tilt and zoom during the post-production phase.</p>
        <p>Modifying the camera position itself is an even greater challenge, since it either requires a perfect 3D reconstruction of the scene or a dense sampling of the 4D space of optical rays at each time (called the 4D lightfield). During the PhD of Gregoire Nieto, we developed image-based rendering (IBR) techniques which are designed to work in cases where the 3D reconstruction cannot be obtained with a high precision, and the number of cameras used to capture the scene is low, resulting in a sparse sampling of the 4D lightfield.</p>
      </subsection>
      <subsection id="uid75" level="2">
        <bodyTitle>Virtual actors</bodyTitle>
        <object id="uid76">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/3_2_virtual_actors.jpg" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>Left: Examples of video and animation frames for a dramatic attitude (seductive) played by two semi-professional actors. Right: Prosodic contours for 8 dramatic attitudes, showing evidence that "scandalized" and "thinking" strongly stand out from other attitudes.</caption>
        </object>
        <p>Following up on Adela Barbelescu's PhD thesis, we tested the capability of audiovisual parameters (voice frequency, rhythm, head motion and facial expressions) to discriminate among different dramatic attitudes in both real actors (video) and virtual actors (3D animation). Using Linear Discriminant Analysis classifiers, we showed that sentence-level features present a higher discriminating rate among the attitudes and are less dependent on the speaker than frame and sylable features. We also performed perceptual evaluation tests, showing that voice frequency is correlated to the perceptual results for all attitudes, while other features, such as head motion, contribute differently, depending both on the attitude and the speaker. Those new results were presented at the Interspeech conference <ref xlink:href="#imagine-2016-bid14" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</p>
      </subsection>
    </subsection>
    <subsection id="uid77" level="1">
      <bodyTitle>Creating and Interacting with Virtual Prototypes</bodyTitle>
      <simplelist>
        <li id="uid78">
          <p noindent="true"><b>Scientist in charge</b>: Jean-Claude Léon.</p>
        </li>
        <li id="uid79">
          <p noindent="true"><b>Other permanent researchers</b>: Marie-Paule Cani, Frédéric Devernay, Olivier Palombi, Damien Rohmer, Rémi Ronfard.</p>
        </li>
      </simplelist>
      <p>The challenge is to develop more effective ways to put the user in the loop during content authoring. We generally rely on sketching techniques for quickly drafting new content, and on sculpting methods (in the sense of gesture-driven, continuous distortion) for further 3D content refinement and editing. The objective is to extend these expressive modeling techniques to general content, from complex shapes and assemblies to animated content. As a complement, we are exploring the use of various 2D or 3D input devices to ease interactive 3D content creation.</p>
      <subsection id="uid80" level="2">
        <bodyTitle>Sculpting Virtual Worlds</bodyTitle>
        <object id="uid81">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/4_1_sculpting_virtual_worlds.jpg" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>Left: Generating a large-scale terrain following fluvial erosion principle from a coarse set of control parameters <ref xlink:href="#imagine-2016-bid0" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. Right: Copy of an animated drop of fluid and its effect on the underlying surface into another animation <ref xlink:href="#imagine-2016-bid15" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</caption>
        </object>
        <p>Extending expressive modeling paradigms to full virtual worlds, with complex terrains, streams and oceans, and vegetation is a challenging goal. To achieve this, we need to combine procedural methods that accurately simulate physical, geological and biological phenomena shaping the world, which high level user control. This year, our work in the area was three-folds:</p>
        <p>Firstly, in collaboration with Jean Braun, professor in geo-morphology and other colleagues, we designed the fist efficient simulation method able to take into account large-scale fluvial erosion to shape mountains. This method was published at Eurographics <ref xlink:href="#imagine-2016-bid0" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. We also designed an interactive sculpting system with multi-touch finger interaction, able to shape mountain ranges based on tectonic forces. This method, combined in real-time with our erosion simulation process, was submitted for a journal publication.</p>
        <p>Secondly, we extended the "Worldbrush" system proposed in 2015 (Emilien et al, Siggraph 2015) in order to consistently populate virtual worlds with learned statistical distributions of trees and plants. The main contributor to this project was James Gain, our visiting professor. After clustering the input terrain into a number of characteristic environmental conditions, we computed sand-box (small-scale) simulations of ecosystems (plant growth) for each of these conditions, and then used learned statistical models (an extension of worldbrush) to populate the full terrain with consistent sets of species. This work was submitted for publication.</p>
        <p>Third, we extended interactive sculpting paradigms to the sculpting of liquid simulation results, such as editing waves on a virtual ocean <ref xlink:href="#imagine-2016-bid15" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. Liquid simulations are both compute intensive and very hard to control, since they are typically edited by re-launching the simulations with slightly different initial conditions until the user is satisfied. In contrast, our method enables users to directly edit liquid animation results (coming in the form of animated meshes) in order to directly output new animations. More precisely, the method offer semi-automatic clustering methods enabling users to select features such as droplets and waves, edit them in space and time and them paste them back into the current liquid animation or to another one.</p>
      </subsection>
      <subsection id="uid82" level="2">
        <bodyTitle>Sketch based design</bodyTitle>
        <object id="uid83">
          <table>
            <tr>
              <td>
                <ressource xlink:href="IMG/4_2_sketching_virtual_worlds.jpg" type="float" width="427.0pt" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest" media="WEB"/>
              </td>
            </tr>
          </table>
          <caption>Progressive extraction of sub-parts of an input sketch in depth with automatic contour completion <ref xlink:href="#imagine-2016-bid16" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>.</caption>
        </object>
        <p>Using 2D sketches is one of the easiest way for creating 3D contents. While prior knowledge on the object being sketch can be used to retrieve the missing information, and thus consistently inferring 3D, interpreting more general sketches and generating 3D shapes from them in indeed a challenging long-term goals. This year, our work in the area was two-folds:</p>
        <p>Firstly, we participated to a course on Sketch-based Modeling, presented at both Eurographics 2016 and Siggraph Asia 2016 <ref xlink:href="#imagine-2016-bid17" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>. The parts we worked on was sketch-based modeling from prior knowledge, with the examples of our works on animals, garments (developable surfaces) and trees.</p>
        <p>Secondly, we advanced towards the interpretation of general sketches representing smooth, organic shapes. The key features of our methods are a new approach for aesthetic contour completion, and an interactive algorithm for progressively interpreting internal silhouettes (suggestive contours) in order to progressively extract sub-parts of the shape from the drawing. These parts are ordered in depth. Our first results were presented as a poster at the Siggraph 2016 conference <ref xlink:href="#imagine-2016-bid16" location="biblio" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest"/>, and then extended an submitted for publication. We are now extending them towards the inference of 3D, organic shapes from a 2D sketch.</p>
      </subsection>
    </subsection>
  </resultats>
  <partenariat id="uid84">
    <bodyTitle>Partnerships and Cooperations</bodyTitle>
    <subsection id="uid85" level="1">
      <bodyTitle>Regional Initiatives</bodyTitle>
      <subsection id="uid86" level="2">
        <bodyTitle>ARC6 PoTAsse (2015 - 2018)</bodyTitle>
        <participants>
          <person key="imagine-2015-idp92368">
            <firstname>Pablo</firstname>
            <lastname>Coves</lastname>
          </person>
          <person key="PASUSERID">
            <firstname>Jean-Claude</firstname>
            <lastname>Léon</lastname>
          </person>
          <person key="imagine-2014-idp110512">
            <firstname>Damien</firstname>
            <lastname>Rohmer</lastname>
          </person>
        </participants>
        <p>We received a doctoral grant (AdR) from the ARC6 program to generate functional CAD assemblies from scanned data (<i>PoTAsse</i>: POint clouds To ASSEmblies) as a collaboration between Imagine team (LJK/Inria) and Geomod team (LIRIS). Our PhD student Pablo Coves is advised by Jean-Claude Léon and Damien Rohmer at Imagine, Raphaëlle Chaine and Julie Digne in Geomod team.</p>
      </subsection>
    </subsection>
    <subsection id="uid87" level="1">
      <bodyTitle>National Initiatives</bodyTitle>
      <subsection id="uid88" level="2">
        <bodyTitle>FUI Collodi (October 2013 - October 2016)</bodyTitle>
        <participants>
          <person key="imagine-2014-idp104680">
            <firstname>Francois</firstname>
            <lastname>Faure</lastname>
          </person>
          <person key="imagine-2014-idp123320">
            <firstname>Romain</firstname>
            <lastname>Testylier</lastname>
          </person>
        </participants>
        <p>This 3-year contract with two industrial partners: TeamTo and Mercenaries Engineering (software for production rendering), was a follow-up and a generalization of Dynam'it.
The goal was to propose an integrated software for the animation and final rendering of high-quality movies, as an alternative to the ever-ageing Maya.
It included dynamics similarly to Dynam'it
This contract, started in October, funded 2 engineers for 3 years.</p>
        <p>This project will be pursued within the new FUI Collodi 2 between 2017 - 2018.</p>
      </subsection>
    </subsection>
    <subsection id="uid89" level="1">
      <bodyTitle>European Initiatives</bodyTitle>
      <subsection id="uid90" level="2">
        <bodyTitle>ERC Grant Expressive</bodyTitle>
        <sanspuceslist>
          <li id="uid91">
            <p noindent="true">Title: EXPloring REsponsive Shapes for Seamless desIgn of Virtual Environments.</p>
          </li>
          <li id="uid92">
            <p noindent="true">Programm: ERC Advanced Grant</p>
          </li>
          <li id="uid93">
            <p noindent="true">Duration: 04/2012 - 03/2017</p>
          </li>
          <li id="uid94">
            <p noindent="true">Inria contact: Marie-Paule Cani</p>
          </li>
          <li id="uid95">
            <p noindent="true">To make expressive and creative design possible in virtual environments, the goal is to totally move away from conventional 3D techniques, where sophisticated interfaces are used to edit the degrees of freedom of pre-existing geometric or physical models: this paradigm has failed, since even trained digital artists still create on traditional media and only use the computer to reproduce already designed content. To allow creative design in virtual environments, from early draft to progressive refinement and finalization of an idea, both interaction tools and models for shape and motion need to be revisited from a user-centred perspective. The challenge is to develop reactive 3D shapes – a new paradigm for high-level, animated 3D content – that will take form, refine, move and deform based on user intent, expressed through intuitive interaction gestures inserted in a user-knowledge context. Anchored in Computer Graphics, this work reaches the frontier of other domains, from Geometry, Conceptual Design and Simulation to Human Computer Interaction.</p>
          </li>
        </sanspuceslist>
      </subsection>
      <subsection id="uid96" level="2">
        <bodyTitle>PIPER</bodyTitle>
        <sanspuceslist>
          <li id="uid97">
            <p noindent="true">Title: Position and Personalize Advanced Human Body Models for Injury Prediction</p>
          </li>
          <li id="uid98">
            <p noindent="true">Programm: FP7</p>
          </li>
          <li id="uid99">
            <p noindent="true">Duration: November 2013 - April 2017</p>
          </li>
          <li id="uid100">
            <p noindent="true">Inria contact: F. Faure</p>
          </li>
          <li id="uid101">
            <p noindent="true">In passive safety, human variability is currently difficult to account for using crash test dummies and regulatory procedures. However, vulnerable populations such as children and elderly need to be considered in the design of safety systems in order to further reduce the fatalities by protecting all users and not only so called averages. Based on the finite element method, advanced Human Body Models for injury prediction have the potential to represent the population variability and to provide more accurate injury predictions than alternatives using global injury criteria. However, these advanced HBM are underutilized in industrial R&amp;D. Reasons include difficulties to position the models – which are typically only available in one posture – in actual vehicle environments, and the lack of model families to represent the population variability (which reduces their interest when compared to dummies). The main objective of the project will be to develop new tools to position and personalize these advanced HBM. Specifications will be agreed upon with future industrial users, and an extensive evaluation in actual applications will take place during the project. The tools will be made available by using an Open Source exploitation strategy and extensive dissemination driven by the industrial partners.Proven approaches will be combined with innovative solutions transferred from computer graphics, statistical shape and ergonomics modeling. The consortium will be balanced between industrial users (with seven European car manufacturers represented), academic users involved in injury bio-mechanics, and partners with different expertise with strong potential for transfer of knowledge. By facilitating the generation of population and subject-specific HBM and their usage in production environments, the tools will enable new applications in industrial R&amp;D for the design of restraint systems as well as new research applications.</p>
          </li>
        </sanspuceslist>
      </subsection>
    </subsection>
    <subsection id="uid102" level="1">
      <bodyTitle>International Research Visitors</bodyTitle>
      <subsection id="uid103" level="2">
        <bodyTitle>Visits of International Scientists</bodyTitle>
        <simplelist>
          <li id="uid104">
            <p noindent="true">Jean-Charles Bazin (ETH Zurich): The convergence space of visual computing.</p>
          </li>
          <li id="uid105">
            <p noindent="true">Ariel Shamir (Interdisciplinary Center, Israel): Creating visual stories.</p>
          </li>
          <li id="uid106">
            <p noindent="true">Eugene Fiume (Univ. Toronto, Canada): Procedural Speech Synchronization for Facial Animation.</p>
          </li>
          <li id="uid107">
            <p noindent="true">Rahul Narain (Univ. Minnesota, USA): Adaptivity and Optimization for Physics-Based Animation.</p>
          </li>
          <li id="uid108">
            <p noindent="true">Christian Jacquemin (Univ. Paris Sud): Arts and science: examples in computer graphics and image processing, and critical analysis.</p>
          </li>
          <li id="uid109">
            <p noindent="true">James Gain (Univ. Cape Town, South Africa): Parallel, Realistic and Controllable Terrain Synthesis.</p>
          </li>
          <li id="uid110">
            <p noindent="true">Nils Thuerey (Technical Univ. of Munich, Germany): Data-driven Fluid Simulation.</p>
          </li>
          <li id="uid111">
            <p noindent="true">Bernhard Thomaszewski (Disney Research Zurich, ETH Zurich, Switzerland): Computational Design Tools for the Age of Digital Fabrication.</p>
          </li>
        </simplelist>
      </subsection>
    </subsection>
  </partenariat>
  <diffusion id="uid112">
    <bodyTitle>Dissemination</bodyTitle>
    <subsection id="uid113" level="1">
      <bodyTitle>Promoting Scientific Activities</bodyTitle>
      <subsection id="uid114" level="2">
        <bodyTitle>Scientific Events Organisation</bodyTitle>
        <subsection id="uid115" level="3">
          <bodyTitle>Member of the Organizing Committees</bodyTitle>
          <p>Remi Ronfard was</p>
          <simplelist>
            <li id="uid116">
              <p noindent="true">co-organizer of the Eurographics workshop on intelligent cinematography and editing (WICED) in Lisbon, Portugal in May 2016.</p>
            </li>
            <li id="uid117">
              <p noindent="true">co-organizer of the Computational Modeling of Narrative (CMN) conference in Cracow, Poland in July 2016.</p>
            </li>
          </simplelist>
        </subsection>
      </subsection>
      <subsection id="uid118" level="2">
        <bodyTitle>Scientific Events Selection</bodyTitle>
        <subsection id="uid119" level="3">
          <bodyTitle>Chair of Conference Program Committees</bodyTitle>
          <simplelist>
            <li id="uid120">
              <p noindent="true">Marie-Paule Cani was chosen as Technical Paper Chair of Siggraph 2017 and started working on this since January 2016, with several meetings in the US throughout the year.</p>
            </li>
            <li id="uid121">
              <p noindent="true">Stefanie Hahmann was Paper Chair of Symposium on Solid and Physical Modeling (SPM) 2016.</p>
            </li>
          </simplelist>
        </subsection>
        <subsection id="uid122" level="3">
          <bodyTitle>Member of the Conference Program Committees</bodyTitle>
          <simplelist>
            <li id="uid123">
              <p noindent="true">Marie-Paule Cani served in the Papers Committees of Eurographics 2016 and Siggraph 2016.</p>
            </li>
            <li id="uid124">
              <p noindent="true">Frédéric Devernay served as a member of the program committee for IEEE CVPR 2016, ECCV 2016, 3DV 2016, CVMP 2016, RFIA 2016.</p>
            </li>
            <li id="uid125">
              <p noindent="true">Damien Rohmer was member of the International Program Committee for Symposium on Solid and Physical Modeling (SPM) and Shape Modeling International-Sculpting Event (SMI-FASE). He was also member of the jury of the best paper for AFIG-EGFR.</p>
            </li>
            <li id="uid126">
              <p noindent="true">Remi Ronfard was a member of the Program Committees for Motion in Games (MIG 2016), International Conference on Interactive Storytelling (ICIDS 2016) and Intelligent Narrative Technology (INT 2016).</p>
            </li>
            <li id="uid127">
              <p noindent="true">Stefanie Hahmann serves in the International Program Committee for Eurographics 2016 and Shape Modeling International (SMI) 2016.</p>
            </li>
            <li id="uid128">
              <p noindent="true">Jean-Claude Léon was member of the International Program Committee for Symposium on Solid and Physical Modeling (SPM) and Shape Modeling International-Sculpting Event (SMI-FASE)</p>
            </li>
          </simplelist>
        </subsection>
        <subsection id="uid129" level="3">
          <bodyTitle>Reviewer</bodyTitle>
          <simplelist>
            <li id="uid130">
              <p noindent="true">Damien Rohmer was reviewer for ACM SIGGRAPH Asia.</p>
            </li>
            <li id="uid131">
              <p noindent="true">Remi Ronfard was a reviewer for Computer Vision and Pattern Recognition (CVPR) and Computer Human Interface (CHI) conferences in 2016.</p>
            </li>
          </simplelist>
        </subsection>
      </subsection>
      <subsection id="uid132" level="2">
        <bodyTitle>Journal</bodyTitle>
        <subsection id="uid133" level="3">
          <bodyTitle>Member of the Editorial Boards</bodyTitle>
          <simplelist>
            <li id="uid134">
              <p noindent="true">Marie-Paule Cani is an Associate Editor of ACM Transactions on Graphics (TOG).</p>
            </li>
            <li id="uid135">
              <p noindent="true">Stefanie Hahmann was a guest Editor of the journal CAD Vol. 78 (Elsevier): Special Issue on Solid and Physical Modeling SPM’16, (eds.) Mario Botsch (Allemagne), Stefanie Hahmann, Scott Schaefer (USA).</p>
            </li>
            <li id="uid136">
              <p noindent="true">Jean-Claude Léon is an Associate Editor of CAD (Elsevier)</p>
            </li>
          </simplelist>
        </subsection>
        <subsection id="uid137" level="3">
          <bodyTitle>Reviewer - Reviewing Activities</bodyTitle>
          <simplelist>
            <li id="uid138">
              <p noindent="true">Remi Ronfard was a reviewer for the « Computers and Graphics » and « Graphical Models » journals in 2016.</p>
            </li>
            <li id="uid139">
              <p noindent="true">Stefanie Hahmann was a reviewer for the journals CAGD and CAD</p>
            </li>
            <li id="uid140">
              <p noindent="true">Jean-Claude Léon was a reviewer for the journal ASME JCISE</p>
            </li>
          </simplelist>
        </subsection>
      </subsection>
      <subsection id="uid141" level="2">
        <bodyTitle>Invited Talks</bodyTitle>
        <p>Marie-Paule Cani gave the following invited talks</p>
        <simplelist>
          <li id="uid142">
            <p noindent="true">Towards the Expressive Design of Virtual Worlds: Combining Knowledge and Control. Key-note talk, Eurographics’2016, Lisbon, Portugal, May 2016.</p>
          </li>
          <li id="uid143">
            <p noindent="true">Expressive 3D Modeling: User-centered models for seamless creation through gestures. Key-note talk, Graphics Interface’2016, Victoria, Canada June 2016</p>
          </li>
          <li id="uid144">
            <p noindent="true">Modélisation 3D expressive: du design numérique à la création de mondes virtuels animés. 3h talks for the Computer Science students of ENS Paris-Saclay (previously called ENS Cachan)</p>
          </li>
          <li id="uid145">
            <p noindent="true">Towards the Expressive Design of Virtual Worlds: Combining Knowledge and Control. Inria Sophia Antipolis colloquium series, September 2016.</p>
          </li>
          <li id="uid146">
            <p noindent="true">Modélisation 3D Expressive : du design numérique à la création de mondes virtuels animés. Invited lecture. l’Université de Corse, Corte, Octobre 2016.</p>
          </li>
          <li id="uid147">
            <p noindent="true">Expressive 3D modeling: from digital design to the creation of animated virtual worlds. Computer Science colloquium, University Paris VI, November 2016.</p>
          </li>
        </simplelist>
        <p>Rémi Ronfard gave the following invited talks</p>
        <simplelist>
          <li id="uid148">
            <p noindent="true">Directing virtual worlds, Xerox Research Center Europe, Meylan.</p>
          </li>
          <li id="uid149">
            <p noindent="true">The prose storyboard language, a tool for annotating and directing movies, Research seminar on digital images, ENS Ulm, February 11, 2016.</p>
          </li>
          <li id="uid150">
            <p noindent="true">Directing virtual worlds, Disney Research, Zurich.</p>
          </li>
          <li id="uid151">
            <p noindent="true">Génération et montage de rushes cinématographiques par analyse vidéo et application aux captations de théâtre. Séminaire en humanités numériques: Valoriser la recherche en arts performatifs par le numérique, Maison des Sciences de l’Homme, Lille, April 18, 2016.</p>
          </li>
          <li id="uid152">
            <p noindent="true">Can computers pay attention ? Journée d’étude sur Attention humaine / Exo-attention computationnelle (Human Attention / Computational Exo-Attention) at University Grenoble Alpes, October 13, 2016.</p>
          </li>
        </simplelist>
      </subsection>
      <subsection id="uid153" level="2">
        <bodyTitle>Scientific Expertise</bodyTitle>
        <simplelist>
          <li id="uid154">
            <p noindent="true">Marie-Paule Cani</p>
            <simplelist>
              <li id="uid155">
                <p noindent="true">was a reviewer for a consolidator and a starting ERC project.</p>
              </li>
              <li id="uid156">
                <p noindent="true">did some consulting for Disney Research, Zurich.</p>
              </li>
            </simplelist>
          </li>
          <li id="uid157">
            <p noindent="true">Remi Ronfard</p>
            <simplelist>
              <li id="uid158">
                <p noindent="true">was a reviewer for the AXIOM GAMMA project at the European Commission (review meetings in March and July 2016).</p>
              </li>
              <li id="uid159">
                <p noindent="true">was a member of the scientific committee at IMAGINOVE in 2016.</p>
              </li>
            </simplelist>
          </li>
          <li id="uid160">
            <p noindent="true">Stefanie Hahmann</p>
            <simplelist>
              <li id="uid161">
                <p noindent="true">was an expert for the Netherlands Organisation for Scientific Research.</p>
              </li>
              <li id="uid162">
                <p noindent="true">serves as a member of the Advisory Board (2014-2018) for the Européen Marie-Curie Training Network ARCADES.</p>
              </li>
            </simplelist>
          </li>
        </simplelist>
      </subsection>
      <subsection id="uid163" level="2">
        <bodyTitle>Research Administration</bodyTitle>
        <simplelist>
          <li id="uid164">
            <p noindent="true">Marie-Paule Cani served as first Vice-Chair and chair of the Steering Committee of the Eurographics association.</p>
          </li>
          <li id="uid165">
            <p noindent="true">Marie-Paule Cani and Rémi Ronfard are elected members of the executive board (CA) of EG-France, the french chapter of Eurographics.</p>
          </li>
          <li id="uid166">
            <p noindent="true">Marie-Paule Cani became joint director of Laboratoire Jean Kuntzmann from July 2016.</p>
          </li>
          <li id="uid167">
            <p noindent="true">Damien Rohmer is member of the Conseil d’Administration of Association Française d’Informatique Graphique (AFIG).</p>
          </li>
          <li id="uid168">
            <p noindent="true">Rémi Ronfard</p>
            <simplelist>
              <li id="uid169">
                <p noindent="true">was the Head of the Image and Geometry Department at Laboratoire Jean Kuntzmann until July 2016.</p>
              </li>
              <li id="uid170">
                <p noindent="true">is the co-organizer of the action « Visage, geste, action et comportement » at GDR ISIS.</p>
              </li>
              <li id="uid171">
                <p noindent="true">has been the head (by interim) of the Imagine team from April 2016.</p>
              </li>
            </simplelist>
          </li>
          <li id="uid172">
            <p noindent="true">Stefanie Hahmann</p>
            <simplelist>
              <li id="uid173">
                <p noindent="true">is an elected member of the Executive Committee of SMA (Solid Modeling Association) since 2013.</p>
              </li>
              <li id="uid174">
                <p noindent="true">is the head of the French working group "GTMG" (Groupe de travail en Modélisation Géométrique) part of the CNRS GDR IM and GDR IGRV.</p>
              </li>
              <li id="uid175">
                <p noindent="true">was member of the Conseil de laboratoire of the LJK lab.</p>
              </li>
            </simplelist>
          </li>
        </simplelist>
      </subsection>
    </subsection>
    <subsection id="uid176" level="1">
      <bodyTitle>Teaching - Supervision - Juries</bodyTitle>
      <subsection id="uid177" level="2">
        <bodyTitle>Teaching</bodyTitle>
        <simplelist>
          <li id="uid178">
            <p noindent="true">Marie-Paule Cani is responsible for two courses at Ensimag/Grenoble-INP: 3D Graphics (a course that attracts about 80 master 1 students per year) and IRL (Introduction à la recherche en laboratoire), a course enabling engineering students to work on a personal project in a research lab during one semester, to get an idea of what academic research is.</p>
          </li>
          <li id="uid179">
            <p noindent="true">Stefanie Hahmann is co-responsible of the department MMIS (Images and Applied Maths) at Grenoble INP with 120 students. (<ref xlink:href="http://ensimag.grenoble-inp.fr/cursus-ingenieur/modelisation-mathematique-images-simulation-124674.kjsp" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>ensimag.<allowbreak/>grenoble-inp.<allowbreak/>fr/<allowbreak/>cursus-ingenieur/<allowbreak/>modelisation-mathematique-images-simulation-124674.<allowbreak/>kjsp</ref>)</p>
            <p>Stefanie Hahmann had teaching load of 192h per year.
She is responsible of 3 courses at Ensimag/Grenoble INP: Numerical Methods (240 students, 3rd year Bachelor level), Geometric Modeling (60 students, Master 1st year) and Surface Modeling (30 students, Master 2nd year).</p>
          </li>
          <li id="uid180">
            <p noindent="true">Olivier Palombi is responsible of the French <ref xlink:href="http://campusdanatomie.org" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">Campus numérique</ref> of anatomy. He is responsible and national leader of the project SIDES (<ref xlink:href="http://side-sante.org/" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">http://<allowbreak/>side-sante.<allowbreak/>org/</ref>). All the French medical schools (43) have planed to use the same e-learning framework (SIDES) to manage evaluations (examen) and to create a large shared database of questions.</p>
          </li>
          <li id="uid181">
            <p noindent="true">François Faure was responsible of the GVR-(Graphics, Vision and Robotic) program in the MOSIG Master.</p>
          </li>
          <li id="uid182">
            <p noindent="true">Damien Rohmer is coordinator of the Math, Signal, Image program at the engineering school CPE Lyon in supervising the scientific and technical content of the program. He is also co-responsible of the <i>Image, Modeling &amp; Computing</i> specialization program attracting 35 students per year. He gives, and is responsible, for of one Computer Science class (130 student, 3rd year Bachelor level), an introductory Computer Graphics class (110 students, Master 1st year), and 5 specialization classes on C++ programming, OpenGL programming, 3D modeling, animation and rendering (35 students, Master 1st and 2nd year). He coordinates the association between CPE and the new computer graphics master program ID3D (Image, Développement et Technologie 3D) from University Lyon1. He also coordinates the association between CPE and the Gamagora computer game project.</p>
          </li>
          <li id="uid183">
            <p noindent="true">Rémi Ronfard taught courses in Computational modeling of narrative texts, movies and games, MSTII Doctoral School, University Grenoble Alpes (18 hours in March-April 2016); Game Engine Programming, M2R IMAGINA, University of Montpellier (36 hours in October-December 2016) and Advanced 3D animation, M2R MOSIG, University of Grenoble Alpes (12 hours in December 2016).</p>
          </li>
          <li id="uid184">
            <p noindent="true">Jean-Claude Léon is in charge of the module Mechanical Systems at Grenoble-INP ENSE3 (300 students, 64h, coordination of three courses)</p>
          </li>
          <li id="uid185">
            <p noindent="true">Frédéric Devernay teaches Computer Science and Algorithmics to L1 and L2 students (Cycle Préparatoire Polytechnique : CPP) at INP Grenoble (50h).</p>
          </li>
        </simplelist>
        <p>Note that MOSIG is joint master program between University Joseph Fourier (UJF) and Institut Polytechnique de Grenoble (INPG) taught in English since it hosts a number of internal students. It belongs to the doctoral school MSTII.</p>
        <p>Most of the members of our team are Professor or Assistant Professor in University where the common teaching load is about 200h per year. Rémi Ronfard who is only researcher usually perform some teaching in vacations.</p>
      </subsection>
      <subsection id="uid186" level="2">
        <bodyTitle>Supervision</bodyTitle>
        <simplelist>
          <li id="uid187">
            <p noindent="true">PhD: Léo Allemand-Giorgis. <i>Reconstruction de surfaces à partir de complexes de Morse-Smale</i>. Thèse MENRT. October 2012-Juin 2016. Stefanie Hahmann and GP Bonneau (Maverick team).</p>
          </li>
          <li id="uid188">
            <p noindent="true">PhD: Pierre-Luc Manteaux. <i>Simulation et contrôle de phénomènes physiques</i>. Grenoble University. October 2012-September 2016. Marie-Paule Cani and François Faure.</p>
          </li>
          <li id="uid189">
            <p noindent="true">PhD: Camille Schreck. <i>Interactive deformation of virtual paper</i>. Grenoble Université, October 2013 - October 2016. Stefanie Hahmann, Damien Rohmer.</p>
          </li>
          <li id="uid190">
            <p noindent="true">PhD: Ulysse Vimont. <i>Novel Methods for the Interactive Design of Complex Objects and Animations</i> October 2013 - November 2016. Marie-Paule Cani, Damien Rohmer.</p>
          </li>
          <li id="uid191">
            <p noindent="true">PhD in progress: Romain Brégier (Université de Grenoble Alpes), <i>Dévracage d'objets à l'aide de bras robotisés</i>, encadrée par Frédéric Devernay et dirigée par James Crowley (LIG, Grenoble), soutenance prévue en octobre 2017.</p>
          </li>
          <li id="uid192">
            <p noindent="true">PhD in progress: Guillaume Cordonnier. <i>Graphical simulation of mountains based on geology</i>. Grenoble university. October 2015-September 2018. Marie-Paule Cani and Eric Galin.</p>
          </li>
          <li id="uid193">
            <p noindent="true">PhD in progress: Pablo Coves, <i>From Point Cloud Data to Functional CAD Model</i>. Grenoble Universit. Jean-Claude Léon, Damien Rohmer, Raphaëlle Chaine (LIRIS), Julie Digne (LIRIS).</p>
          </li>
          <li id="uid194">
            <p noindent="true">PhD in progress: Sébastien Crozet, <i>Calcul de distance minimale entre solides B-Rep CAO pour des applications de simulations mécaniques temps réelles</i>, Janvier 2015- Décembre 2017. Frédéric Devernay.</p>
          </li>
          <li id="uid195">
            <p noindent="true">PhD in progress: Even Entem. <i>3D modelling from a sketch</i>. Grenoble University. November 2013-March 2017. Marie-Paule Cani and Loic Barthe (IRIT Toulouse).</p>
          </li>
          <li id="uid196">
            <p noindent="true">PhD in progress: Amélie Fondevilla. <i>Sculpting and animating developable surfaces with video embedding</i>, Thèse MENRT. October 2016 - September 2021. Stefanie Hahmann.</p>
          </li>
          <li id="uid197">
            <p noindent="true">PhD in progress: Geoffrey Guingo. <i>Synthesis of animated textures</i>. Grenoble university. October 2015-September 2018. Marie-Paule Cani, Jean-Michel Dischler and Basile Sauvage.</p>
          </li>
          <li id="uid198">
            <p noindent="true">PhD in progress: Sandra Nabil (Université de Grenoble Alpes), <i>Vidéo panoramique 360 dégrés à très haute résolution</i>, encadrée par Frédéric Devernay et dirigée par James Crowley (LIG, Grenoble), soutenance prévue en octobre 2018.</p>
          </li>
          <li id="uid199">
            <p noindent="true">PhD in progress: Grégoire Niéto (Université de Grenoble Alpes), <i>Dispositifs de capture de type «caméra plénoptique» pour la vision à grande distance, et algorithmes de traitement et de visualisation</i>, encadrée par Frédéric Devernay et dirigée par James Crowley (LIG, Grenoble), soutenance prévue en octobre 2017.</p>
          </li>
          <li id="uid200">
            <p noindent="true">PhD in progress: Robin Roussel. <i>Function-aware design for objects to be fabricated</i>. UCL London. Octber 2015-September 2018.Niloy Mitra, Marie-Paule Cani and Jean-Claude Léon.</p>
          </li>
          <li id="uid201">
            <p noindent="true">PhD in progress: Tibor Stanko. <i>Modélisation de surfaces lisses maillées à partir de capteurs inertiels</i>. Thèse CEA. October 2014- September 2017. Stefanie Hahmann and GP Bonneau.</p>
          </li>
          <li id="uid202">
            <p noindent="true">M2R: Thibault Blanc-Beyne, Ensimag, Géraldine Morin (ENSEEIHT), Stefanie Hahmann</p>
          </li>
          <li id="uid203">
            <p noindent="true">M2R: Amélie Fondevilla, Ensimag, Stefanie Hahmann, Damien Rohmer</p>
          </li>
          <li id="uid204">
            <p noindent="true">M2R Maxime Garcia, ENSIMAG/MOSIG, Rémi Ronfard</p>
          </li>
          <li id="uid205">
            <p noindent="true">M2R: Thibault Lejemble, Ensimag, Stefanie Hahmann, Damien Rohmer</p>
          </li>
          <li id="uid206">
            <p noindent="true">M2R: Kevin Le Run, L3, ENS Cachan, Rémi Ronfard</p>
          </li>
          <li id="uid207">
            <p noindent="true">M2R: Estelle Noé, ParisTech et KTH, Damien Rohmer, Stefanie Hahmann, Marie-Paule Cani</p>
          </li>
          <li id="uid208">
            <p noindent="true">M2R: Aymeric Séguret, M2GICAO, Jean-Claude Léon,</p>
          </li>
        </simplelist>
      </subsection>
      <subsection id="uid209" level="2">
        <bodyTitle>Juries</bodyTitle>
        <simplelist>
          <li id="uid210">
            <p noindent="true">Marie-Paule Cani was member of the PhD committees of Elisabeth Rousset (Equipe IIHM, UGA), Yoann Weber (Université de Limoges), and Hamza Chouh (CEA Saclay - Université de Lyon).</p>
          </li>
          <li id="uid211">
            <p noindent="true">Remi Ronfard was a reader (rapporteur) for the PhD thesis of Fabio Zund, Augmented reality storytelling, ETH Zurich, October 2016.</p>
          </li>
          <li id="uid212">
            <p noindent="true">Stefanie Hahmann was a reviewer (rapporteur) for the PhD thesis of Florian Canezin (Univ. Toulouse), Hoang Ha Nguyen (Université Aix-Marseille) and Ngels Cervero (UPC Universitat Politènica de Catalunya, Barcelona).</p>
          </li>
          <li id="uid213">
            <p noindent="true">Jean-Claude Léon was reviewer (apporteur) for the PhD thesis of Lei Zhang (Ecole Centrale Marseille)</p>
          </li>
        </simplelist>
      </subsection>
    </subsection>
    <subsection id="uid214" level="1">
      <bodyTitle>Popularization</bodyTitle>
      <p>Marie-Paule Cani</p>
      <simplelist>
        <li id="uid215">
          <p noindent="true">“Façonner l’Imaginaire…”: Towards the Expressive Design of Animated Virtual Worlds “Imagination Week de l’ESSEC, Paris, Janvier 2016.</p>
        </li>
        <li id="uid216">
          <p noindent="true">Formes, mouvements, et mondes virtuels… Quel média pour façonner l’imaginaire ? Forum des savoirs, Rouen, 2016. Exposé également donné à l’Institut de Biologie de Paris VI, octobre 2016.</p>
        </li>
        <li id="uid217">
          <p noindent="true">participation to a Round Table within the conference:“Mathématiques Oxygène du Numérique”, Paris, November 2016.</p>
        </li>
      </simplelist>
      <p>Damien Rohmer gave a presentation on</p>
      <simplelist>
        <li id="uid218">
          <p noindent="true">Researches and applications in Computer Graphics to ENS Lyon students.</p>
        </li>
        <li id="uid219">
          <p noindent="true">Scientific image production to mathematiciens scientists at the MMI (Maison des Mathématiques et de l’Informatique) in Lyon.</p>
        </li>
        <li id="uid220">
          <p noindent="true">Garment and developable surface modeling at the R3iLab (Réseau innovation immatérielle pour l’industrie).</p>
        </li>
      </simplelist>
      <p>Rémi Ronfard</p>
      <simplelist>
        <li id="uid221">
          <p noindent="true">Eye tracking and the arts. Invited talk at Experimenta, Grenoble, October 2016.</p>
        </li>
        <li id="uid222">
          <p noindent="true">Artificial Intelligence and the arts. Invited talk at Atelier Arts et Science, CEA/Hexagone, Grenoble, October 2016.</p>
        </li>
      </simplelist>
    </subsection>
  </diffusion>
  <biblio id="bibliography" html="bibliography" numero="10" titre="Bibliography">
    
    <biblStruct id="imagine-2016-bid33" type="article" rend="refer" n="refercite:dalstein:hal-01155246">
      <identifiant type="hal" value="hal-01155246"/>
      <analytic>
        <title level="a">Vector Graphics Animation with Time-Varying Topology</title>
        <author>
          <persName>
            <foreName>Boris</foreName>
            <surname>Dalstein</surname>
            <initial>B.</initial>
          </persName>
          <persName key="imagine-2014-idp103248">
            <foreName>Rémi</foreName>
            <surname>Ronfard</surname>
            <initial>R.</initial>
          </persName>
          <persName>
            <foreName>Michiel</foreName>
            <surname>Van De Panne</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr>
        <title level="j">ACM Transactions on Graphics</title>
        <imprint>
          <dateStruct>
            <month>August</month>
            <year>2015</year>
          </dateStruct>
          <biblScope type="pages">12</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01155246" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01155246</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid32" type="article" rend="refer" n="refercite:emilien:hal-01147913">
      <identifiant type="doi" value="10.1145/2766975"/>
      <identifiant type="hal" value="hal-01147913"/>
      <analytic>
        <title level="a">WorldBrush: Interactive Example-based Synthesis of Procedural Virtual Worlds</title>
        <author>
          <persName key="imagine-2014-idp130912">
            <foreName>Arnaud</foreName>
            <surname>Emilien</surname>
            <initial>A.</initial>
          </persName>
          <persName key="imagine-2014-idp144992">
            <foreName>Ulysse</foreName>
            <surname>Vimont</surname>
            <initial>U.</initial>
          </persName>
          <persName key="imagine-2014-idp101760">
            <foreName>Marie-Paule</foreName>
            <surname>Cani</surname>
            <initial>M.-P.</initial>
          </persName>
          <persName>
            <foreName>Pierre</foreName>
            <surname>Poulin</surname>
            <initial>P.</initial>
          </persName>
          <persName>
            <foreName>Bedrich</foreName>
            <surname>Benes</surname>
            <initial>B.</initial>
          </persName>
        </author>
      </analytic>
      <monogr>
        <title level="j">ACM Transactions on Graphics</title>
        <imprint>
          <biblScope type="volume">34</biblScope>
          <biblScope type="number">4</biblScope>
          <dateStruct>
            <month>August</month>
            <year>2015</year>
          </dateStruct>
          <biblScope type="pages">11</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01147913" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01147913</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid35" type="article" rend="refer" n="refercite:guay:hal-01153763">
      <identifiant type="doi" value="10.1145/2766893"/>
      <identifiant type="hal" value="hal-01153763"/>
      <analytic>
        <title level="a">Space-time sketching of character animation</title>
        <author>
          <persName key="imagine-2014-idp136040">
            <foreName>Martin</foreName>
            <surname>Guay</surname>
            <initial>M.</initial>
          </persName>
          <persName key="imagine-2014-idp103248">
            <foreName>Rémi</foreName>
            <surname>Ronfard</surname>
            <initial>R.</initial>
          </persName>
          <persName key="imagine-2014-idp151408">
            <foreName>Michael</foreName>
            <surname>Gleicher</surname>
            <initial>M.</initial>
          </persName>
          <persName key="imagine-2014-idp101760">
            <foreName>Marie-Paule</foreName>
            <surname>Cani</surname>
            <initial>M.-P.</initial>
          </persName>
        </author>
      </analytic>
      <monogr>
        <title level="j">ACM Transactions on Graphics</title>
        <imprint>
          <biblScope type="volume">34</biblScope>
          <biblScope type="number">4</biblScope>
          <dateStruct>
            <month>May</month>
            <year>2015</year>
          </dateStruct>
          <biblScope type="pages">1</biblScope>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01153763" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01153763</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid36" type="article" rend="refer" n="refercite:jung:hal-01152904">
      <identifiant type="hal" value="hal-01152904"/>
      <analytic>
        <title level="a">Sketching Folds: Developable Surfaces from Non-Planar Silhouettes</title>
        <author>
          <persName>
            <foreName>Amaury</foreName>
            <surname>Jung</surname>
            <initial>A.</initial>
          </persName>
          <persName key="imagine-2014-idp106136">
            <foreName>Stefanie</foreName>
            <surname>Hahmann</surname>
            <initial>S.</initial>
          </persName>
          <persName key="imagine-2014-idp110512">
            <foreName>Damien</foreName>
            <surname>Rohmer</surname>
            <initial>D.</initial>
          </persName>
          <persName key="imagine-2014-idp111768">
            <foreName>Antoine</foreName>
            <surname>Begault</surname>
            <initial>A.</initial>
          </persName>
          <persName>
            <foreName>Laurence</foreName>
            <surname>Boissieux</surname>
            <initial>L.</initial>
          </persName>
          <persName key="imagine-2014-idp101760">
            <foreName>Marie-Paule</foreName>
            <surname>Cani</surname>
            <initial>M.-P.</initial>
          </persName>
        </author>
      </analytic>
      <monogr>
        <title level="j">ACM Transactions on Graphics (TOG)</title>
        <imprint>
          <biblScope type="volume">34</biblScope>
          <biblScope type="number">5</biblScope>
          <dateStruct>
            <year>2015</year>
          </dateStruct>
          <biblScope type="pages">155:1–155:12</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01152904" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01152904</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid1" type="article" rend="refer" n="refercite:schreck:hal-01202571">
      <identifiant type="doi" value="10.1145/2829947.2829948"/>
      <identifiant type="hal" value="hal-01202571"/>
      <analytic>
        <title level="a">Non-smooth developable geometry for interactively animating paper crumpling</title>
        <author>
          <persName key="imagine-2014-idp142424">
            <foreName>Camille</foreName>
            <surname>Schreck</surname>
            <initial>C.</initial>
          </persName>
          <persName key="imagine-2014-idp110512">
            <foreName>Damien</foreName>
            <surname>Rohmer</surname>
            <initial>D.</initial>
          </persName>
          <persName key="imagine-2014-idp106136">
            <foreName>Stefanie</foreName>
            <surname>Hahmann</surname>
            <initial>S.</initial>
          </persName>
          <persName key="imagine-2014-idp101760">
            <foreName>Marie-Paule</foreName>
            <surname>Cani</surname>
            <initial>M.-P.</initial>
          </persName>
          <persName key="alice-2016-idp153072">
            <foreName>Shuo</foreName>
            <surname>Jin</surname>
            <initial>S.</initial>
          </persName>
          <persName>
            <foreName>Charlie</foreName>
            <surname>Wang</surname>
            <initial>C.</initial>
          </persName>
          <persName>
            <foreName>Jean-Francis</foreName>
            <surname>Bloch</surname>
            <initial>J.-F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr>
        <title level="j">ACM Transactions on Graphics</title>
        <imprint>
          <biblScope type="volume">35</biblScope>
          <biblScope type="number">1</biblScope>
          <dateStruct>
            <month>December</month>
            <year>2015</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01202571" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01202571</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid34" type="article" rend="refer" n="refercite:tournier:hal-01157835">
      <identifiant type="doi" value="10.1145/2766969"/>
      <identifiant type="hal" value="hal-01157835"/>
      <analytic>
        <title level="a">Stable Constrained Dynamics</title>
        <author>
          <persName key="camin-2016-idp172272">
            <foreName>Maxime</foreName>
            <surname>Tournier</surname>
            <initial>M.</initial>
          </persName>
          <persName key="imagine-2014-idp120768">
            <foreName>Matthieu</foreName>
            <surname>Nesme</surname>
            <initial>M.</initial>
          </persName>
          <persName key="demar-2014-idp79600">
            <foreName>Benjamin</foreName>
            <surname>Gilles</surname>
            <initial>B.</initial>
          </persName>
          <persName key="imagine-2014-idp104680">
            <foreName>François</foreName>
            <surname>Faure</surname>
            <initial>F.</initial>
          </persName>
        </author>
      </analytic>
      <monogr>
        <title level="j">ACM Transactions on Graphics</title>
        <imprint>
          <biblScope type="volume">34</biblScope>
          <biblScope type="number">4</biblScope>
          <dateStruct>
            <month>August</month>
            <year>2015</year>
          </dateStruct>
          <biblScope type="pages">Article No. 132</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01157835" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01157835</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid18" type="proceedings" rend="year" n="cite:botsch:hal-01342798">
      <identifiant type="hal" value="hal-01342798"/>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes">
        <title level="m">Proceedings of Solid and Physical Modeling (SPM) 2016 - Special Issue of CAD Vol. 78</title>
        <title level="s">Computer-Aided Design</title>
        <editor role="editor">
          <persName>
            <foreName>Mario</foreName>
            <surname>Botsch</surname>
            <initial>M.</initial>
          </persName>
          <persName key="imagine-2014-idp106136">
            <foreName>Stefanie</foreName>
            <surname>Hahmann</surname>
            <initial>S.</initial>
          </persName>
          <persName>
            <foreName>Schaefer</foreName>
            <surname>Scott</surname>
            <initial>S.</initial>
          </persName>
        </editor>
        <imprint>
          <biblScope type="volume">78</biblScope>
          <publisher>
            <orgName>Elsevier<address><addrLine>Germany</addrLine></address></orgName>
          </publisher>
          <dateStruct>
            <month>September</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">1-208</biblScope>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01342798" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01342798</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid21" type="proceedings" rend="year" n="cite:miller:hal-01427217">
      <identifiant type="hal" value="hal-01427217"/>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes">
        <title level="m">Proceedings of the 7th Workshop on Computational Models of Narrative</title>
        <title level="s">OASICS</title>
        <editor role="editor">
          <persName>
            <foreName>Ben</foreName>
            <surname>Miller</surname>
            <initial>B.</initial>
          </persName>
          <persName>
            <foreName>Antonio</foreName>
            <surname>Lieto</surname>
            <initial>A.</initial>
          </persName>
          <persName key="imagine-2014-idp103248">
            <foreName>Rémi</foreName>
            <surname>Ronfard</surname>
            <initial>R.</initial>
          </persName>
          <persName>
            <foreName>Stephen</foreName>
            <surname>Ware</surname>
            <initial>S.</initial>
          </persName>
          <persName>
            <foreName>Mark</foreName>
            <surname>Finlayson</surname>
            <initial>M.</initial>
          </persName>
        </editor>
        <imprint>
          <biblScope type="volume">53</biblScope>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01427217" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01427217</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid22" type="proceedings" rend="year" n="cite:ronfard:hal-01427243">
      <identifiant type="hal" value="hal-01427243"/>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes">
        <title level="m">Eurographics Workshop on Intelligent Cinematography and Editing</title>
        <title level="s">Eurographics Workshop on Intelligent Cinematography and Editing</title>
        <imprint>
          <publisher>
            <orgName type="organisation">The Eurographics Association<address><addrLine>Lisbonne, Portugal</addrLine></address></orgName>
          </publisher>
          <dateStruct>
            <month>May</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01427243" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01427243</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid23" type="phdthesis" rend="year" n="cite:bauer:tel-01412175">
      <identifiant type="hal" value="tel-01412175"/>
      <monogr>
        <title level="m">User-specific real-time registration and tracking applied to anatomy learning</title>
        <author>
          <persName key="imagine-2014-idp127136">
            <foreName>Armelle</foreName>
            <surname>Bauer</surname>
            <initial>A.</initial>
          </persName>
        </author>
        <imprint>
          <publisher>
            <orgName type="school">Université Grenoble Alpes</orgName>
          </publisher>
          <dateStruct>
            <month>November</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://tel.archives-ouvertes.fr/tel-01412175" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>tel.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>tel-01412175</ref>
        </imprint>
      </monogr>
      <note type="typdoc">Theses</note>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid26" type="phdthesis" rend="year" n="cite:schreck:tel-01427555">
      <identifiant type="hal" value="tel-01427555"/>
      <monogr>
        <title level="m">Interactive Deformation of Virtual Paper</title>
        <author>
          <persName key="imagine-2014-idp142424">
            <foreName>Camille</foreName>
            <surname>Schreck</surname>
            <initial>C.</initial>
          </persName>
        </author>
        <imprint>
          <publisher>
            <orgName type="school">Universite Grenoble Alpes</orgName>
          </publisher>
          <dateStruct>
            <month>October</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/tel-01427555" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>tel-01427555</ref>
        </imprint>
      </monogr>
      <note type="typdoc">Theses</note>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid11" type="incollection" rend="year" n="cite:allemandgiorgis:hal-01252477">
      <identifiant type="hal" value="hal-01252477"/>
      <analytic>
        <title level="a">Piecewise polynomial Reconstruction of Scalar Fields from Simplified Morse-Smale Complexes</title>
        <author>
          <persName key="maverick-2014-idp117664">
            <foreName>Léo</foreName>
            <surname>Allemand-Giorgis</surname>
            <initial>L.</initial>
          </persName>
          <persName key="maverick-2014-idp109712">
            <foreName>Georges-Pierre</foreName>
            <surname>Bonneau</surname>
            <initial>G.-P.</initial>
          </persName>
          <persName key="imagine-2014-idp106136">
            <foreName>Stefanie</foreName>
            <surname>Hahmann</surname>
            <initial>S.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no">
        <editor role="editor">
          <persName>
            <foreName>Hamish</foreName>
            <surname>Carr</surname>
            <initial>H.</initial>
          </persName>
          <persName>
            <foreName>Christoph</foreName>
            <surname>Garth</surname>
            <initial>C.</initial>
          </persName>
          <persName>
            <foreName>Tino</foreName>
            <surname>Weinkauf</surname>
            <initial>T.</initial>
          </persName>
        </editor>
        <title level="m">Topological Data Analysis</title>
        <imprint>
          <publisher>
            <orgName>Springer</orgName>
          </publisher>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01252477" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01252477</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid7" type="article" rend="year" n="cite:carlier:hal-01322964">
      <identifiant type="doi" value="10.1016/j.cag.2016.05.009"/>
      <identifiant type="hal" value="hal-01322964"/>
      <analytic>
        <title level="a">The 2D shape structure dataset: A user annotated open access database</title>
        <author>
          <persName>
            <foreName>Axel</foreName>
            <surname>Carlier</surname>
            <initial>A.</initial>
          </persName>
          <persName key="imagine-2015-idp117816">
            <foreName>Kathryn</foreName>
            <surname>Leonard</surname>
            <initial>K.</initial>
          </persName>
          <persName key="imagine-2014-idp106136">
            <foreName>Stefanie</foreName>
            <surname>Hahmann</surname>
            <initial>S.</initial>
          </persName>
          <persName>
            <foreName>Geraldine</foreName>
            <surname>Morin</surname>
            <initial>G.</initial>
          </persName>
          <persName>
            <foreName>Misha</foreName>
            <surname>Collins</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00410">
        <idno type="issn">0097-8493</idno>
        <title level="j">Computers and Graphics</title>
        <imprint>
          <biblScope type="volume">58</biblScope>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">23-30</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01322964" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01322964</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid0" type="article" rend="year" n="cite:cordonnier:hal-01262376">
      <identifiant type="hal" value="hal-01262376"/>
      <analytic>
        <title level="a">Large Scale Terrain Generation from Tectonic Uplift and Fluvial Erosion</title>
        <author>
          <persName key="imagine-2015-idp91096">
            <foreName>Guillaume</foreName>
            <surname>Cordonnier</surname>
            <initial>G.</initial>
          </persName>
          <persName>
            <foreName>Jean</foreName>
            <surname>Braun</surname>
            <initial>J.</initial>
          </persName>
          <persName key="imagine-2014-idp101760">
            <foreName>Marie-Paule</foreName>
            <surname>Cani</surname>
            <initial>M.-P.</initial>
          </persName>
          <persName>
            <foreName>Bedrich</foreName>
            <surname>Benes</surname>
            <initial>B.</initial>
          </persName>
          <persName>
            <foreName>Eric</foreName>
            <surname>Galin</surname>
            <initial>E.</initial>
          </persName>
          <persName>
            <foreName>Adrien</foreName>
            <surname>Peytavie</surname>
            <initial>A.</initial>
          </persName>
          <persName>
            <foreName>Eric</foreName>
            <surname>Guérin</surname>
            <initial>E.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00391">
        <idno type="issn">0167-7055</idno>
        <title level="j">Computer Graphics Forum (Proc. EUROGRAPHICS 2016)</title>
        <imprint>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01262376" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01262376</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid30" type="incollection" rend="year" n="cite:gagnere:hal-01389848">
      <identifiant type="hal" value="hal-01389848"/>
      <analytic>
        <title level="a">La simulation du travail théâtral et sa " notation " informatique</title>
        <author>
          <persName>
            <foreName>Georges</foreName>
            <surname>Gagneré</surname>
            <initial>G.</initial>
          </persName>
          <persName key="imagine-2014-idp103248">
            <foreName>Rémi</foreName>
            <surname>Ronfard</surname>
            <initial>R.</initial>
          </persName>
          <persName key="poset-2015-idm26664">
            <foreName>Myriam</foreName>
            <surname>Desainte-Catherine</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no">
        <editor role="editor">
          <persName>
            <foreName>Monique</foreName>
            <surname>Martinez</surname>
            <initial>M.</initial>
          </persName>
          <persName>
            <foreName>Sophie</foreName>
            <surname>Proust</surname>
            <initial>S.</initial>
          </persName>
        </editor>
        <title level="m">La notation du travail théâtral : du manuscrit au numérique</title>
        <imprint>
          <publisher>
            <orgName>Lansman</orgName>
          </publisher>
          <dateStruct>
            <month>October</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01389848" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01389848</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid28" type="article" rend="year" n="cite:leon:hal-01422764">
      <identifiant type="doi" value="10.1115/1.4033291"/>
      <identifiant type="hal" value="hal-01422764"/>
      <analytic>
        <title level="a">Dexterous Grasping Tasks Generated With an Add-on End Effector of a Haptic Feedback System</title>
        <author>
          <persName key="imagine-2014-idp107584">
            <foreName>Jean-Claude</foreName>
            <surname>Léon</surname>
            <initial>J.-C.</initial>
          </persName>
          <persName>
            <foreName>Thomas</foreName>
            <surname>Dupeux</surname>
            <initial>T.</initial>
          </persName>
          <persName>
            <foreName>Jean-Rémy</foreName>
            <surname>Chardonnet</surname>
            <initial>J.-R.</initial>
          </persName>
          <persName>
            <foreName>Jérôme</foreName>
            <surname>Perret</surname>
            <initial>J.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid01109">
        <idno type="issn">1530-9827</idno>
        <title level="j">Journal of Computing and Information Science in Engineering</title>
        <imprint>
          <biblScope type="volume">16</biblScope>
          <biblScope type="number">3</biblScope>
          <dateStruct>
            <month>June</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">10</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01422764" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01422764</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid12" type="article" rend="year" n="cite:malgat:hal-01367360">
      <identifiant type="doi" value="10.3389/fpls.2016.01351"/>
      <identifiant type="hal" value="hal-01367360"/>
      <analytic>
        <title level="a">A Mechanical Model to Interpret Cell-Scale Indentation Experiments on Plant Tissues in Terms of Cell Wall Elasticity and Turgor Pressure</title>
        <author>
          <persName key="imagine-2014-idp139848">
            <foreName>Richard</foreName>
            <surname>Malgat</surname>
            <initial>R.</initial>
          </persName>
          <persName key="imagine-2014-idp104680">
            <foreName>François</foreName>
            <surname>Faure</surname>
            <initial>F.</initial>
          </persName>
          <persName>
            <foreName>Arezki</foreName>
            <surname>Boudaoud</surname>
            <initial>A.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid02419">
        <idno type="issn">1664-462X</idno>
        <title level="j">Frontiers in Plant Science</title>
        <imprint>
          <biblScope type="volume">7</biblScope>
          <dateStruct>
            <month>September</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">1351</biblScope>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01367360" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01367360</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid3" type="article" rend="year" n="cite:manteaux:hal-01367170">
      <identifiant type="doi" value="10.1111/cgf.12941"/>
      <identifiant type="hal" value="hal-01367170"/>
      <analytic>
        <title level="a">Adaptive Physically Based Models in Computer Graphics</title>
        <author>
          <persName key="imagine-2014-idp141128">
            <foreName>Pierre-Luc</foreName>
            <surname>Manteaux</surname>
            <initial>P.-L.</initial>
          </persName>
          <persName>
            <foreName>Chris</foreName>
            <surname>Wojtan</surname>
            <initial>C.</initial>
          </persName>
          <persName>
            <foreName>Rahul</foreName>
            <surname>Narain</surname>
            <initial>R.</initial>
          </persName>
          <persName key="nano-d-2014-idm28472">
            <foreName>Stéphane</foreName>
            <surname>Redon</surname>
            <initial>S.</initial>
          </persName>
          <persName key="imagine-2014-idp104680">
            <foreName>François</foreName>
            <surname>Faure</surname>
            <initial>F.</initial>
          </persName>
          <persName key="imagine-2014-idp101760">
            <foreName>Marie-Paule</foreName>
            <surname>Cani</surname>
            <initial>M.-P.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00391">
        <idno type="issn">0167-7055</idno>
        <title level="j">Computer Graphics Forum</title>
        <imprint>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01367170" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01367170</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid29" type="incollection" rend="year" n="cite:ronfard:hal-01389847">
      <identifiant type="hal" value="hal-01389847"/>
      <analytic>
        <title level="a">Notation et reconnaissance des actions scéniques par ordinateur</title>
        <author>
          <persName key="imagine-2014-idp103248">
            <foreName>Rémi</foreName>
            <surname>Ronfard</surname>
            <initial>R.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no">
        <editor role="editor">
          <persName>
            <foreName>Monique</foreName>
            <surname>Martinez</surname>
            <initial>M.</initial>
          </persName>
          <persName>
            <foreName>Sophie</foreName>
            <surname>Proust</surname>
            <initial>S.</initial>
          </persName>
        </editor>
        <title level="m">La notation du travail théâtral : du manuscrit au numérique</title>
        <imprint>
          <dateStruct>
            <month>October</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01389847" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01389847</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid8" type="article" rend="year" n="cite:stanko:hal-01342465">
      <identifiant type="hal" value="hal-01342465"/>
      <analytic>
        <title level="a">Surfacing Curve Networks with Normal Control</title>
        <author>
          <persName key="imagine-2014-idp143696">
            <foreName>Tibor</foreName>
            <surname>Stanko</surname>
            <initial>T.</initial>
          </persName>
          <persName key="imagine-2014-idp106136">
            <foreName>Stefanie</foreName>
            <surname>Hahmann</surname>
            <initial>S.</initial>
          </persName>
          <persName key="maverick-2014-idp109712">
            <foreName>Georges-Pierre</foreName>
            <surname>Bonneau</surname>
            <initial>G.-P.</initial>
          </persName>
          <persName>
            <foreName>Nathalie</foreName>
            <surname>Saguin-Sprynski</surname>
            <initial>N.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00410">
        <idno type="issn">0097-8493</idno>
        <title level="j">Computers and Graphics</title>
        <imprint>
          <dateStruct>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01342465" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01342465</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid4" type="article" rend="year" n="cite:tagliasacchi:hal-01300281">
      <identifiant type="hal" value="hal-01300281"/>
      <analytic>
        <title level="a">3D Skeletons: A State-of-the-Art Report</title>
        <author>
          <persName>
            <foreName>Andrea</foreName>
            <surname>Tagliasacchi</surname>
            <initial>A.</initial>
          </persName>
          <persName key="imagine-2014-idp147544">
            <foreName>Thomas</foreName>
            <surname>Delame</surname>
            <initial>T.</initial>
          </persName>
          <persName>
            <foreName>Michela</foreName>
            <surname>Spagnuolo</surname>
            <initial>M.</initial>
          </persName>
          <persName>
            <foreName>Nina</foreName>
            <surname>Amenta</surname>
            <initial>N.</initial>
          </persName>
          <persName>
            <foreName>Alexandru</foreName>
            <surname>Telea</surname>
            <initial>A.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" id="rid00391">
        <idno type="issn">0167-7055</idno>
        <title level="j">Computer Graphics Forum</title>
        <imprint>
          <biblScope type="volume">35</biblScope>
          <biblScope type="number">2</biblScope>
          <dateStruct>
            <month>May</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01300281" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01300281</ref>
        </imprint>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid14" type="inproceedings" rend="year" n="cite:barbulescu:hal-01337077">
      <identifiant type="hal" value="hal-01337077"/>
      <analytic>
        <title level="a">Characterization of Audiovisual Dramatic Attitudes</title>
        <author>
          <persName key="imagine-2014-idp125880">
            <foreName>Adela</foreName>
            <surname>Barbulescu</surname>
            <initial>A.</initial>
          </persName>
          <persName key="imagine-2014-idp103248">
            <foreName>Rémi</foreName>
            <surname>Ronfard</surname>
            <initial>R.</initial>
          </persName>
          <persName>
            <foreName>Gérard</foreName>
            <surname>Bailly</surname>
            <initial>G.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">17th Annual Conference of the International Speech Communication Association (Interspeech 2016)</title>
        <loc>San Francisco, United States</loc>
        <imprint>
          <dateStruct>
            <month>September</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">585-589</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01337077" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01337077</ref>
        </imprint>
        <meeting id="cid29182">
          <title>Annual Conference of the International Speech Communication Association</title>
          <num>17</num>
          <abbr type="sigle">INTERSPEECH</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid13" type="inproceedings" rend="year" n="cite:bauer:hal-01366704">
      <identifiant type="doi" value="10.1145/2994258.2994259"/>
      <identifiant type="hal" value="hal-01366704"/>
      <analytic>
        <title level="a">Anatomical Mirroring: Real-time User-specific Anatomy in Motion Using a Commodity Depth Camera</title>
        <author>
          <persName key="imagine-2014-idp127136">
            <foreName>Armelle</foreName>
            <surname>Bauer</surname>
            <initial>A.</initial>
          </persName>
          <persName key="imagine-2015-idp113992">
            <foreName>Ali-Hamadi</foreName>
            <surname>Dicko</surname>
            <initial>A.-H.</initial>
          </persName>
          <persName key="imagine-2014-idp104680">
            <foreName>François</foreName>
            <surname>Faure</surname>
            <initial>F.</initial>
          </persName>
          <persName key="imagine-2014-idp109032">
            <foreName>Olivier</foreName>
            <surname>Palombi</surname>
            <initial>O.</initial>
          </persName>
          <persName>
            <foreName>Jocelyne</foreName>
            <surname>Troccaz</surname>
            <initial>J.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">ACM SIGGRAPH Conference on Motion in Games</title>
        <loc>San Francisco, United States</loc>
        <imprint>
          <dateStruct>
            <month>October</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01366704" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01366704</ref>
        </imprint>
        <meeting id="cid292760">
          <title>International Conference on Motion in Games</title>
          <num>6</num>
          <abbr type="sigle">MIG</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid17" type="inproceedings" rend="year" n="cite:cordier:hal-01394794">
      <identifiant type="doi" value="10.2312/egt.20161035"/>
      <identifiant type="hal" value="hal-01394794"/>
      <analytic>
        <title level="a">Sketch-based Modeling</title>
        <author>
          <persName>
            <foreName>Frederic</foreName>
            <surname>Cordier</surname>
            <initial>F.</initial>
          </persName>
          <persName>
            <foreName>Yotam</foreName>
            <surname>Gingold</surname>
            <initial>Y.</initial>
          </persName>
          <persName key="imagine-2014-idp132208">
            <foreName>Even</foreName>
            <surname>Entem</surname>
            <initial>E.</initial>
          </persName>
          <persName key="imagine-2014-idp101760">
            <foreName>Marie-Paule</foreName>
            <surname>Cani</surname>
            <initial>M.-P.</initial>
          </persName>
          <persName>
            <foreName>Karan</foreName>
            <surname>Singh</surname>
            <initial>K.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">Eurographics 2016</title>
        <loc>Lisbonne, Portugal</loc>
        <imprint>
          <biblScope type="number">T7</biblScope>
          <publisher>
            <orgName type="organisation">The Eurographics Association</orgName>
          </publisher>
          <dateStruct>
            <month>May</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01394794" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01394794</ref>
        </imprint>
        <meeting id="cid29028">
          <title>Annual Conference of the European Association for Computer Graphics</title>
          <num>37</num>
          <abbr type="sigle">EUROGRAPHICS</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid27" type="inproceedings" rend="year" n="cite:cordier:hal-01429057">
      <identifiant type="doi" value="10.1145/2988458.2988504"/>
      <identifiant type="hal" value="hal-01429057"/>
      <analytic>
        <title level="a">Sketch-based Modeling</title>
        <author>
          <persName>
            <foreName>Frederic</foreName>
            <surname>Cordier</surname>
            <initial>F.</initial>
          </persName>
          <persName>
            <foreName>Karan</foreName>
            <surname>Singh</surname>
            <initial>K.</initial>
          </persName>
          <persName>
            <foreName>Yotam</foreName>
            <surname>Gingold</surname>
            <initial>Y.</initial>
          </persName>
          <persName key="imagine-2014-idp101760">
            <foreName>Marie-Paule</foreName>
            <surname>Cani</surname>
            <initial>M.-P.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">Siggraph Asia 2016</title>
        <loc>Macao, China</loc>
        <title level="s">SIGGRAPH ASIA 2016 Courses</title>
        <imprint>
          <publisher>
            <orgName>ACM</orgName>
          </publisher>
          <dateStruct>
            <month>December</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">222</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01429057" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01429057</ref>
        </imprint>
        <meeting id="cid21164">
          <title>ACM SIGGRAPH Conference and Exhibition in Asia</title>
          <num>2016</num>
          <abbr type="sigle">SIGGRAPH Asia</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid20" type="inproceedings" rend="year" n="cite:crozet:hal-01422771">
      <identifiant type="doi" value="10.1109/IROS.2016.7759162"/>
      <identifiant type="hal" value="hal-01422771"/>
      <analytic>
        <title level="a">Fast computation of contact points for robotic simulations based on CAD models without tessellation</title>
        <author>
          <persName key="imagine-2015-idp93624">
            <foreName>Sébastien</foreName>
            <surname>Crozet</surname>
            <initial>S.</initial>
          </persName>
          <persName key="imagine-2014-idp107584">
            <foreName>Jean-Claude</foreName>
            <surname>Léon</surname>
            <initial>J.-C.</initial>
          </persName>
          <persName>
            <foreName>Xavier</foreName>
            <surname>Merlhiot</surname>
            <initial>X.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">Intelligent Robots and Systems (IROS), 2016 IEEE/RSJ International Conference on</title>
        <loc>Daejeon, South Korea</loc>
        <imprint>
          <dateStruct>
            <month>October</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01422771" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01422771</ref>
        </imprint>
        <meeting id="cid93437">
          <title>IEEE RSJ International Conference on Intelligent Robots and Systems</title>
          <num>2016</num>
          <abbr type="sigle">IROS</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid5" type="inproceedings" rend="year" n="cite:delame:hal-01359738">
      <identifiant type="hal" value="hal-01359738"/>
      <analytic>
        <title level="a">Structuring 3D Medial Skeletons: A Comparative Study</title>
        <author>
          <persName key="imagine-2014-idp147544">
            <foreName>Thomas</foreName>
            <surname>Delame</surname>
            <initial>T.</initial>
          </persName>
          <persName>
            <foreName>Jacek</foreName>
            <surname>Kustra</surname>
            <initial>J.</initial>
          </persName>
          <persName>
            <foreName>Alexandru</foreName>
            <surname>Telea</surname>
            <initial>A.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">Symposium on Vision, Modeling and Visualization</title>
        <loc>Bayreuth, Germany</loc>
        <imprint>
          <dateStruct>
            <month>October</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01359738" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01359738</ref>
        </imprint>
        <meeting id="cid398556">
          <title>Vision Modeling and Visualization</title>
          <num>2016</num>
          <abbr type="sigle"/>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid6" type="inproceedings" rend="year" n="cite:leonard:hal-01374810">
      <identifiant type="hal" value="hal-01374810"/>
      <analytic>
        <title level="a">A 2D Shape Structure for Decomposition and Part Similarity</title>
        <author>
          <persName key="imagine-2015-idp117816">
            <foreName>Kathryn</foreName>
            <surname>Leonard</surname>
            <initial>K.</initial>
          </persName>
          <persName>
            <foreName>Geraldine</foreName>
            <surname>Morin</surname>
            <initial>G.</initial>
          </persName>
          <persName key="imagine-2014-idp106136">
            <foreName>Stefanie</foreName>
            <surname>Hahmann</surname>
            <initial>S.</initial>
          </persName>
          <persName>
            <foreName>Axel</foreName>
            <surname>Carlier</surname>
            <initial>A.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">ICPR 2016 - 23rd International Conference on Pattern Recognition</title>
        <loc>Cancun, Mexico</loc>
        <imprint>
          <publisher>
            <orgName>IEEE</orgName>
          </publisher>
          <dateStruct>
            <month>December</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01374810" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01374810</ref>
        </imprint>
        <meeting id="cid295950">
          <title>International Conference on Pattern Recognition</title>
          <num>23</num>
          <abbr type="sigle">ICPR</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid15" type="inproceedings" rend="year" n="cite:manteaux:hal-01367181">
      <identifiant type="doi" value="10.1145/2994258.2994261"/>
      <identifiant type="hal" value="hal-01367181"/>
      <analytic>
        <title level="a">Space-time sculpting of liquid animation</title>
        <author>
          <persName key="imagine-2014-idp141128">
            <foreName>Pierre-Luc</foreName>
            <surname>Manteaux</surname>
            <initial>P.-L.</initial>
          </persName>
          <persName key="imagine-2014-idp144992">
            <foreName>Ulysse</foreName>
            <surname>Vimont</surname>
            <initial>U.</initial>
          </persName>
          <persName>
            <foreName>Chris</foreName>
            <surname>Wojtan</surname>
            <initial>C.</initial>
          </persName>
          <persName key="imagine-2014-idp110512">
            <foreName>Damien</foreName>
            <surname>Rohmer</surname>
            <initial>D.</initial>
          </persName>
          <persName key="imagine-2014-idp101760">
            <foreName>Marie-Paule</foreName>
            <surname>Cani</surname>
            <initial>M.-P.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">Motion In Games</title>
        <loc>San Francisco, United States</loc>
        <imprint>
          <dateStruct>
            <month>October</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01367181" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01367181</ref>
        </imprint>
        <meeting id="cid292760">
          <title>International Conference on Motion in Games</title>
          <num>2</num>
          <abbr type="sigle">MIG</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid19" type="inproceedings" rend="year" n="cite:morin:hal-01331713">
      <identifiant type="hal" value="hal-01331713"/>
      <analytic>
        <title level="a">Vessel-based brain-shift compensation using elastic registration driven by a patient-specific finite element model</title>
        <author>
          <persName>
            <foreName>Fanny</foreName>
            <surname>Morin</surname>
            <initial>F.</initial>
          </persName>
          <persName>
            <foreName>Ingerid</foreName>
            <surname>Reinertsen</surname>
            <initial>I.</initial>
          </persName>
          <persName key="mimesis-2015-idm29408">
            <foreName>Hadrien</foreName>
            <surname>Courtecuisse</surname>
            <initial>H.</initial>
          </persName>
          <persName key="imagine-2014-idp109032">
            <foreName>Olivier</foreName>
            <surname>Palombi</surname>
            <initial>O.</initial>
          </persName>
          <persName>
            <foreName>Bodil</foreName>
            <surname>Munkvold</surname>
            <initial>B.</initial>
          </persName>
          <persName>
            <foreName>Hans Kristian</foreName>
            <surname>Bø</surname>
            <initial>H. K.</initial>
          </persName>
          <persName>
            <foreName>Yohan</foreName>
            <surname>Payan</surname>
            <initial>Y.</initial>
          </persName>
          <persName>
            <foreName>Matthieu</foreName>
            <surname>Chabanas</surname>
            <initial>M.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="no" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">International Conference on Information Processing in Computer-Assisted Interventions (IPCAI)</title>
        <loc>Heidelberg, Germany</loc>
        <imprint>
          <dateStruct>
            <month>June</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01331713" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01331713</ref>
        </imprint>
        <meeting id="cid391024">
          <title>International Conference on Information Processing in Computer-Assisted Interventions, IPCAI</title>
          <num>2016</num>
          <abbr type="sigle">IPCAI</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid31" type="inproceedings" rend="year" n="cite:nieto:hal-01393942">
      <identifiant type="hal" value="hal-01393942"/>
      <analytic>
        <title level="a">Rendu basé image avec contraintes sur les gradients</title>
        <author>
          <persName key="prima-2014-idp109400">
            <foreName>Grégoire</foreName>
            <surname>Nieto</surname>
            <initial>G.</initial>
          </persName>
          <persName key="prima-2014-idp64856">
            <foreName>Frédéric</foreName>
            <surname>Devernay</surname>
            <initial>F.</initial>
          </persName>
          <persName key="prima-2014-idm28656">
            <foreName>James</foreName>
            <surname>Crowley</surname>
            <initial>J.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="no" x-proceedings="no" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">Reconnaissance des Formes et l'Intelligence Artificielle, RFIA 2016</title>
        <loc>Clermont-Ferrand, France</loc>
        <imprint>
          <dateStruct>
            <month>June</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01393942" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01393942</ref>
        </imprint>
        <meeting id="cid54223">
          <title>Congrès Francophone de Reconnaissance des Formes et Intelligence Artificielle</title>
          <num>2016</num>
          <abbr type="sigle">RFIA</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid24" type="inproceedings" rend="year" n="cite:nieto:hal-01402528">
      <identifiant type="hal" value="hal-01402528"/>
      <analytic>
        <title level="a">Variational Image-Based Rendering with Gradient Constraints</title>
        <author>
          <persName key="prima-2014-idp109400">
            <foreName>Grégoire</foreName>
            <surname>Nieto</surname>
            <initial>G.</initial>
          </persName>
          <persName key="prima-2014-idp64856">
            <foreName>Frédéric</foreName>
            <surname>Devernay</surname>
            <initial>F.</initial>
          </persName>
          <persName key="prima-2014-idm28656">
            <foreName>James</foreName>
            <surname>Crowley</surname>
            <initial>J.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="no" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">IC3D - 2016 International Conference on 3D Imaging</title>
        <loc>Liège, France</loc>
        <imprint>
          <dateStruct>
            <month>December</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.archives-ouvertes.fr/hal-01402528" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>archives-ouvertes.<allowbreak/>fr/<allowbreak/>hal-01402528</ref>
        </imprint>
        <meeting id="cid623490">
          <title>International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission</title>
          <num>2016</num>
          <abbr type="sigle">3DIMPVT</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid2" type="inproceedings" rend="best" n="cite:schreck:hal-01333238">
      <identifiant type="hal" value="hal-01333238"/>
      <analytic>
        <title level="a">Real-time sound synthesis for paper material based on geometric analysis</title>
        <author>
          <persName key="imagine-2014-idp142424">
            <foreName>Camille</foreName>
            <surname>Schreck</surname>
            <initial>C.</initial>
          </persName>
          <persName key="imagine-2014-idp110512">
            <foreName>Damien</foreName>
            <surname>Rohmer</surname>
            <initial>D.</initial>
          </persName>
          <persName>
            <foreName>Doug L</foreName>
            <surname>James</surname>
            <initial>D. L.</initial>
          </persName>
          <persName key="imagine-2014-idp106136">
            <foreName>Stefanie</foreName>
            <surname>Hahmann</surname>
            <initial>S.</initial>
          </persName>
          <persName key="imagine-2014-idp101760">
            <foreName>Marie-Paule</foreName>
            <surname>Cani</surname>
            <initial>M.-P.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">Eurographics/ ACM SIGGRAPH Symposium on Computer Animation (2016)</title>
        <loc>Zürich, Switzerland</loc>
        <imprint>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01333238" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01333238</ref>
        </imprint>
        <meeting id="cid21225">
          <title>ACM SIGGRAPH Eurographics Symposium on Computer Animation</title>
          <num>2016</num>
          <abbr type="sigle">SCA</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid9" type="inproceedings" rend="year" n="cite:stanko:hal-01342487">
      <identifiant type="doi" value="10.2312/egsh.20161005"/>
      <identifiant type="hal" value="hal-01342487"/>
      <analytic>
        <title level="a">Smooth Interpolation of Curve Networks with Surface Normals</title>
        <author>
          <persName key="imagine-2014-idp143696">
            <foreName>Tibor</foreName>
            <surname>Stanko</surname>
            <initial>T.</initial>
          </persName>
          <persName key="imagine-2014-idp106136">
            <foreName>Stefanie</foreName>
            <surname>Hahmann</surname>
            <initial>S.</initial>
          </persName>
          <persName key="maverick-2014-idp109712">
            <foreName>Georges-Pierre</foreName>
            <surname>Bonneau</surname>
            <initial>G.-P.</initial>
          </persName>
          <persName>
            <foreName>Nathalie</foreName>
            <surname>Saguin-Sprynski</surname>
            <initial>N.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no" x-editorial-board="yes">
        <title level="m">Eurographics 2016 Short Papers</title>
        <loc>Lisbonne, Portugal</loc>
        <imprint>
          <dateStruct>
            <month>May</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01342487" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01342487</ref>
        </imprint>
        <meeting id="cid29028">
          <title>Annual Conference of the European Association for Computer Graphics</title>
          <num>37</num>
          <abbr type="sigle">EUROGRAPHICS</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid10" type="inproceedings" rend="year" n="cite:stanko:hal-01372958">
      <identifiant type="hal" value="hal-01372958"/>
      <analytic>
        <title level="a">Smooth interpolation of curve networks with surface normals</title>
        <author>
          <persName key="imagine-2014-idp143696">
            <foreName>Tibor</foreName>
            <surname>Stanko</surname>
            <initial>T.</initial>
          </persName>
          <persName key="imagine-2014-idp106136">
            <foreName>Stefanie</foreName>
            <surname>Hahmann</surname>
            <initial>S.</initial>
          </persName>
          <persName key="maverick-2014-idp109712">
            <foreName>Georges-Pierre</foreName>
            <surname>Bonneau</surname>
            <initial>G.-P.</initial>
          </persName>
          <persName>
            <foreName>Nathalie</foreName>
            <surname>Saguin-Sprynski</surname>
            <initial>N.</initial>
          </persName>
        </author>
      </analytic>
      <monogr x-scientific-popularization="no" x-international-audience="no" x-proceedings="yes" x-invited-conference="no" x-editorial-board="no">
        <title level="m">GTMG 2016 — Actes des Journées du Groupe de Travail en Modélisation Géométrique</title>
        <loc>Dijon, France, France</loc>
        <imprint>
          <dateStruct>
            <month>March</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01372958" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01372958</ref>
        </imprint>
        <meeting id="cid395841">
          <title>Journées du Groupe de Travail en Modélisation Géométrique</title>
          <num>2016</num>
          <abbr type="sigle">GTMG</abbr>
        </meeting>
      </monogr>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid25" type="unpublished" rend="year" n="cite:bregier:hal-01415027">
      <identifiant type="hal" value="hal-01415027"/>
      <monogr>
        <title level="m">Defining the Pose of any 3D Rigid Object and an Associated Metric</title>
        <author>
          <persName key="prima-2014-idp103120">
            <foreName>Romain</foreName>
            <surname>Brégier</surname>
            <initial>R.</initial>
          </persName>
          <persName key="prima-2014-idp64856">
            <foreName>Frédéric</foreName>
            <surname>Devernay</surname>
            <initial>F.</initial>
          </persName>
          <persName>
            <foreName>Laetitia</foreName>
            <surname>Leyrit</surname>
            <initial>L.</initial>
          </persName>
          <persName key="prima-2014-idm28656">
            <foreName>James</foreName>
            <surname>Crowley</surname>
            <initial>J.</initial>
          </persName>
        </author>
        <imprint>
          <dateStruct>
            <month>September</month>
            <year>2016</year>
          </dateStruct>
          <ref xlink:href="https://hal.inria.fr/hal-01415027" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01415027</ref>
        </imprint>
      </monogr>
      <note type="bnote">working paper or preprint</note>
    </biblStruct>
    
    <biblStruct id="imagine-2016-bid16" type="misc" rend="year" n="cite:entem:hal-01395321">
      <identifiant type="doi" value="10.1145/2945078.2945130"/>
      <identifiant type="hal" value="hal-01395321"/>
      <monogr x-scientific-popularization="no" x-editorial-board="yes" x-international-audience="yes" x-proceedings="yes" x-invited-conference="no">
        <title level="m">From Drawing to Animation-ready Vector Graphics</title>
        <title level="s">ACM SIGGRAPH 2016 Posters</title>
        <author>
          <persName key="imagine-2014-idp132208">
            <foreName>Even</foreName>
            <surname>Entem</surname>
            <initial>E.</initial>
          </persName>
          <persName key="manao-2015-idp95616">
            <foreName>Loïc</foreName>
            <surname>Barthe</surname>
            <initial>L.</initial>
          </persName>
          <persName key="imagine-2014-idp101760">
            <foreName>Marie-Paule</foreName>
            <surname>Cani</surname>
            <initial>M.-P.</initial>
          </persName>
          <persName>
            <foreName>Michiel</foreName>
            <surname>Van De Panne</surname>
            <initial>M.</initial>
          </persName>
        </author>
        <editor role="editor">
          <persName>
            <foreName/>
            <surname>ACM</surname>
            <initial/>
          </persName>
        </editor>
        <imprint>
          <biblScope type="number">52</biblScope>
          <dateStruct>
            <month>July</month>
            <year>2016</year>
          </dateStruct>
          <biblScope type="pages">2</biblScope>
          <ref xlink:href="https://hal.inria.fr/hal-01395321" location="extern" xlink:type="simple" xlink:show="replace" xlink:actuate="onRequest">https://<allowbreak/>hal.<allowbreak/>inria.<allowbreak/>fr/<allowbreak/>hal-01395321</ref>
        </imprint>
      </monogr>
      <note type="howpublished">SIGGRAPH '16</note>
      <note type="bnote">Poster</note>
    </biblStruct>
  </biblio>
</raweb>
